{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mental-astronomy",
   "metadata": {},
   "source": [
    "# E-GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "violent-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import from_networkx\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from dgl.data.utils import save_graphs\n",
    "\n",
    "#constante\n",
    "size_embedding = 152\n",
    "nb_batch = 5\n",
    "\n",
    "#Data\n",
    "nbclasses =  2\n",
    "\n",
    "# Accuracy --------------------------------------------------------------------\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------ Model Architecture -----------------------------------------------------------------\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        self.W_msg = nn.Linear(ndim_in + edims, ndim_out)\n",
    "        self.W_apply = nn.Linear(ndim_in + ndim_out, ndim_out)\n",
    "        self.activation = activation\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        x = th.cat([edges.src['h'], edges.data['h']], 2)\n",
    "        y = self.W_msg(x)\n",
    "        return {'m': y}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = nfeats\n",
    "            g.edata['h'] = efeats\n",
    "            # Line 4 of algorithm 1 : update all because we are using a full neighborhood sampling and not a k-hop neigh sampling\n",
    "            g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "            # Line 5 of algorithm 1\n",
    "            g.ndata['h'] = F.relu(self.W_apply(th.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "            return g.ndata['h']\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGELayer(ndim_in, edim, size_embedding, activation))\n",
    "        self.layers.append(SAGELayer(size_embedding, edim, size_embedding, activation)) ##\n",
    "        self.layers.append(SAGELayer(size_embedding, edim, ndim_out, activation))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                nfeats = self.dropout(nfeats)\n",
    "            nfeats = layer(g, nfeats, efeats)\n",
    "            # Save edge_embeddings\n",
    "            # nf = 'edge_embeddings'+str(i)+'.txt'\n",
    "            # sourceFile = open(nf, 'w')\n",
    "            # print(nfeats, file = sourceFile)\n",
    "        return nfeats.sum(1)\n",
    "        # Return a list of node features [[node1_feature1, node1_feature2, ...], [node2_feature1, node2_feature2, ...], ...]\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        v = th.cat([h_u, h_v], 1)\n",
    "        # if(pr == True):\n",
    "            # sourceFile = open(filename, 'w')\n",
    "            # if pr:\n",
    "                # print(v, file = sourceFile)\n",
    "            # sourceFile.close()\n",
    "        score = self.W(v)\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            # Update the features of the specified edges by the provided function\n",
    "            # DGLGraph.apply_edges(func, edges='__ALL__', etype=None, inplace=False)\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.gnn = SAGE(ndim_in, ndim_out, edim, activation, dropout)\n",
    "        self.pred = MLPPredictor(ndim_out, nbclasses)\n",
    "    def forward(self, g, nfeats, efeats, eweight = None):\n",
    "        if eweight != None:\n",
    "            # apply eweight on the graph\n",
    "            efe = []\n",
    "            for i, x in enumerate(eweight):\n",
    "                efe.append(list(th.Tensor.cpu(g.edata['h'][i][0]).detach().numpy() * th.Tensor.cpu(x).detach().numpy()))\n",
    "\n",
    "            efe = th.FloatTensor(efe).cuda()\n",
    "            efe = th.reshape(efe, (efe.shape[0], 1, efe.shape[1]))\n",
    "            g.edata['h'] = efe = efe\n",
    "\n",
    "        h = self.gnn(g, nfeats, efeats)\n",
    "        # h = list of node features [[node1_feature1, node1_feature2, ...], [node2_feature1, node2_feature2, ...], ...]\n",
    "        return self.pred(g, h)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-pursuit",
   "metadata": {},
   "source": [
    "## Graph + Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BENIGN': 0, 'Brute Force': 1, 'XSS': 2, 'Sql Injection': 3, 'Heartbleed': 4, 'DoS Hulk': 5, 'DDoS': 6, 'PortScan': 7, 'FTP-Patator': 8, 'Bot': 9, 'DoS slowloris': 10, 'DoS GoldenEye': 11, 'DoS Slowhttptest': 12, 'SSH-Patator': 13, 'Infiltration': 14}\n",
      "CIC-IDS-2017-Dataset4.csv ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nb total instances in the file :  460167\n",
      "++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\n",
      "\n",
      "labels freq after changing labels to binary\n",
      "{'CIC-IDS-2017-Dataset4.csv': [[0, 0.7582073464633492], [1, 0.24179265353665083]]}\n",
      "+++++++++++++++++ Batch 1 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  137195   -0.009681\n",
      "15919    -0.004203\n",
      "357294   -0.007855\n",
      "297601   -0.004203\n",
      "146767   -0.008768\n",
      "            ...   \n",
      "293476   -0.009681\n",
      "341997   -0.009681\n",
      "219677   -0.004203\n",
      "2982     -0.002377\n",
      "368084   -0.007855\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  137195    [-0.00968116605521554, -0.3602517831445359, -0...\n",
      "15919     [-0.0042028828454134005, -0.3602517831445359, ...\n",
      "357294    [-0.00785507165194816, -0.3602517831445359, -0...\n",
      "297601    [-0.0042028828454134005, 3.5745614590158805, -...\n",
      "146767    [-0.008768118853581851, -0.3602517831445359, -...\n",
      "                                ...                        \n",
      "293476    [-0.00968116605521554, -0.3602517831445359, -0...\n",
      "341997    [-0.00968116605521554, -0.3602517831445359, -0...\n",
      "219677    [-0.0042028828454134005, -0.3602517831445359, ...\n",
      "2982      [-0.002376788442146021, 3.534896002945715, -0....\n",
      "368084    [-0.00785507165194816, -0.3602517831445359, -0...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58935 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9853157997131348 tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.987768292427063 tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.98804771900177 tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9881563782691956 tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.988327145576477 tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9891653060913086 tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.989429235458374 tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9905933737754822 tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909659028053284 tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9910435713953091\n",
      "Precision :  0.9672943508424182\n",
      "Recall :  0.9968720076603894\n",
      "f1_score :  0.9818604797384388\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9150458574295044 tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9427533149719238 tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9531378149986267 tensor(0.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9552022814750671 tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9419151544570923 tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9571115374565125 tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9587569236755371 tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9664250016212463 tensor(0.0872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.964608907699585 tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9520357636247924\n",
      "Precision :  0.8405828503331347\n",
      "Recall :  0.9906160229811682\n",
      "f1_score :  0.909453202836547\n",
      "+++++++++++++++++ Batch 2 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  235326   -0.011253\n",
      "311173   -0.009856\n",
      "313828   -0.002869\n",
      "138273   -0.009856\n",
      "234997   -0.011253\n",
      "            ...   \n",
      "90158    -0.009856\n",
      "53499    -0.011253\n",
      "15721    -0.005664\n",
      "330952   -0.009856\n",
      "423319   -0.000074\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  235326    [-0.011253374590339172, -0.3580185310515318, -...\n",
      "311173    [-0.009855962198963283, -0.3580185310515318, -...\n",
      "313828    [-0.0028689002420838315, 3.591098780313893, -0...\n",
      "138273    [-0.009855962198963283, -0.3580185310515318, -...\n",
      "234997    [-0.011253374590339172, -0.3580185310515318, -...\n",
      "                                ...                        \n",
      "90158     [-0.009855962198963283, -0.3580185310515318, -...\n",
      "53499     [-0.011253374590339172, -0.3580185310515318, -...\n",
      "15721     [-0.0056637250248356115, -0.3580185310515318, ...\n",
      "330952    [-0.009855962198963283, -0.3580185310515318, -...\n",
      "423319    [-7.4075459332051e-05, 3.0343773743506133, -0....\n",
      "Name: h, Length: 64423, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial nx multigraph G1 :  MultiDiGraph with 58925 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9898793697357178 tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9900345802307129 tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9906244277954102 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9908262491226196 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9910125136375427 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9905623197555542 tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914005398750305 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991291880607605 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991260826587677 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9914161091535632\n",
      "Precision :  0.9674252844816806\n",
      "Recall :  0.9979361496291519\n",
      "f1_score :  0.9824438871075272\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9615354537963867 tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9647175669670105 tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9652453064918518 tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9665336608886719 tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9646399021148682 tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9671545624732971 tensor(0.0665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9690017104148865 tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9681790471076965 tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9671390056610107 tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9675271254055229\n",
      "Precision :  0.8875469517480497\n",
      "Recall :  0.9905836826830055\n",
      "f1_score :  0.9362389515391648\n",
      "+++++++++++++++++ Batch 3 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  237138   -0.060519\n",
      "284803   -0.060519\n",
      "49344    -0.090709\n",
      "93961    -0.060519\n",
      "447938   -0.090709\n",
      "            ...   \n",
      "46645    -0.090709\n",
      "238615    0.150808\n",
      "325197   -0.060519\n",
      "151722   -0.060519\n",
      "364615   -0.000140\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  237138    [-0.06051942979157977, -0.3572079777552217, -0...\n",
      "284803    [-0.06051942979157977, -0.3572079777552217, -0...\n",
      "49344     [-0.09070908657630193, -0.3572079777552217, -0...\n",
      "93961     [-0.06051942979157977, -0.3572079777552217, -0...\n",
      "447938    [-0.09070908657630193, -0.3572079777552217, -0...\n",
      "                                ...                        \n",
      "46645     [-0.09070908657630193, -0.3572079777552217, -0...\n",
      "238615    [0.15080816770147537, 0.03567240078974374, -0....\n",
      "325197    [-0.06051942979157977, -0.3572079777552217, -0...\n",
      "151722    [-0.06051942979157977, -0.3572079777552217, -0...\n",
      "364615    [-0.00014011622213544133, -0.3572079777552217,...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58822 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9886220693588257 tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9897551536560059 tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909038543701172 tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913074374198914 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914471507072449 tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914937019348145 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991540253162384 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916799664497375 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916644096374512 tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9917110348788476\n",
      "Precision :  0.9677023210119121\n",
      "Recall :  0.9994926433282597\n",
      "f1_score :  0.9833406127160417\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9576393365859985 tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9732703566551208 tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9741861820220947 tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9764214158058167 tensor(0.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9797587394714355 tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9809384346008301 tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9808763861656189 tensor(0.0452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9743414521217346 tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.979991614818573 tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9802710212191298\n",
      "Precision :  0.9345362987830466\n",
      "Recall :  0.9886478944698123\n",
      "f1_score :  0.9608308422447532\n",
      "+++++++++++++++++ Batch 4 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  370142   -0.036572\n",
      "87647    -0.029988\n",
      "217529   -0.043157\n",
      "459083    0.002935\n",
      "5284     -0.029988\n",
      "            ...   \n",
      "160844   -0.036572\n",
      "381668   -0.036572\n",
      "18955    -0.010234\n",
      "179506   -0.036572\n",
      "384223   -0.003650\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train_batched['h'] :  370142    [-0.03657232891882459, -0.3563427367803997, -0...\n",
      "87647     [-0.029987846108918553, -0.3563427367803997, -...\n",
      "217529    [-0.04315681172873062, -0.3563427367803997, -0...\n",
      "459083    [0.0029345679406116137, -0.3563427367803997, -...\n",
      "5284      [-0.029987846108918553, -0.3563427367803997, -...\n",
      "                                ...                        \n",
      "160844    [-0.03657232891882459, -0.3563427367803997, -0...\n",
      "381668    [-0.03657232891882459, -0.3563427367803997, -0...\n",
      "18955     [-0.010234397679200454, -0.11541276042716997, ...\n",
      "179506    [-0.03657232891882459, -0.3563427367803997, -0...\n",
      "384223    [-0.00364991486929442, 3.028349112102859, 0.00...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58896 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9889169931411743 tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9898483157157898 tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9907641410827637 tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9910280108451843 tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903760552406311 tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9912453293800354 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991322934627533 tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916954636573792 tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916644096374512 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9916644676590659\n",
      "Precision :  0.9674923566481562\n",
      "Recall :  0.9989692049993557\n",
      "f1_score :  0.9829788582839394\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9624202251434326 tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9747450351715088 tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9766232371330261 tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9792154431343079 tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9800847172737122 tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9628548622131348 tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9649969339370728 tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.972385585308075 tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9758005142211914 tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9800847523400028\n",
      "Precision :  0.9339835416031698\n",
      "Recall :  0.9871150624919469\n",
      "f1_score :  0.9598145770037898\n",
      "+++++++++++++++++ Batch 5 ++++++++++++++++\n",
      "nb Train instances :  64424\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  412498   -0.009560\n",
      "212178   -0.009560\n",
      "378075   -0.008482\n",
      "51887    -0.008482\n",
      "132352   -0.010637\n",
      "            ...   \n",
      "85028    -0.004170\n",
      "305431   -0.004170\n",
      "41938    -0.010637\n",
      "332036   -0.007404\n",
      "223961   -0.010637\n",
      "Name:  Total Backward Packets, Length: 64424, dtype: float64\n",
      "X1_train_batched['h'] :  412498    [-0.009559537942955366, -0.3560902364301288, -...\n",
      "212178    [-0.009559537942955366, -0.3560902364301288, -...\n",
      "378075    [-0.008481667920785958, -0.3560902364301288, -...\n",
      "51887     [-0.008481667920785958, -0.3560902364301288, -...\n",
      "132352    [-0.010637407965124773, -0.3560902364301288, -...\n",
      "                                ...                        \n",
      "85028     [-0.004170187832108329, 2.9933943485918224, -0...\n",
      "305431    [-0.004170187832108329, -0.11482891247584566, ...\n",
      "41938     [-0.010637407965124773, -0.3560902364301288, -...\n",
      "332036    [-0.007403797898616551, -0.3560902364301288, -...\n",
      "223961    [-0.010637407965124773, -0.3560902364301288, -...\n",
      "Name: h, Length: 64424, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 59102 nodes and 64424 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64424\n",
      "G1.edata['h'] after reshape :  64424\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128848 nodes and 64424 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64424\n",
      "G1_ab.edata['h'] after reshape :  64424\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9894759654998779 tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990826427936554 tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909350872039795 tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9908574819564819 tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909040331840515 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9905470013618469 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913231134414673 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991012692451477 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9915559887886047 tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9907022227741215\n",
      "Precision :  0.9629652760429678\n",
      "Recall :  0.999611021069692\n",
      "f1_score :  0.9809460190221714\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9636626243591309 tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9646404981613159 tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9652459025382996 tensor(0.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9660064578056335 tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9665808081626892 tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9671396017074585 tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9673569202423096 tensor(0.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9676052331924438 tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.966177225112915 tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9680398609213957\n",
      "Precision :  0.8891800605637084\n",
      "Recall :  0.9898865478119935\n",
      "f1_score :  0.9368346780378562\n",
      "++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Test instances :  138051\n",
      "\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138051\n",
      "Metrics : \n",
      "Accuracy :  0.9917204511376231\n",
      "Precision :  0.9773164736888863\n",
      "Recall :  0.9887058118633912\n",
      "f1_score :  0.9829781530625922\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138051\n",
      "Metrics : \n",
      "Accuracy :  0.9671932836415528\n",
      "Precision :  0.888921840877841\n",
      "Recall :  0.9877471539844218\n",
      "f1_score :  0.9357324289424018\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CIC-IDS-2017-Dataset1.csv ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nb total instances in the file :  460165\n",
      "++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\n",
      "\n",
      "labels freq after changing labels to binary\n",
      "{'CIC-IDS-2017-Dataset1.csv': [[0, 0.7577868807927591], [1, 0.24221311920724087]]}\n",
      "+++++++++++++++++ Batch 1 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  288789   -0.009611\n",
      "228934   -0.006509\n",
      "99396    -0.010386\n",
      "450164   -0.009611\n",
      "116518   -0.011162\n",
      "            ...   \n",
      "198583   -0.005733\n",
      "212806   -0.011162\n",
      "166432    0.031490\n",
      "48092    -0.009611\n",
      "451980   -0.010386\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  288789    [-0.009610950474780736, -0.3555712879660169, -...\n",
      "228934    [-0.00650898114077708, -0.3555712879660169, -0...\n",
      "99396     [-0.010386442808281651, -0.3555712879660169, -...\n",
      "450164    [-0.009610950474780736, -0.3555712879660169, -...\n",
      "116518    [-0.011161935141782564, -0.3555712879660169, -...\n",
      "                                ...                        \n",
      "198583    [-0.005733488807276165, 3.6458264261305713, -0...\n",
      "212806    [-0.011161935141782564, -0.3555712879660169, -...\n",
      "166432    [0.03149014320076771, -0.3555712879660169, 0.0...\n",
      "48092     [-0.009610950474780736, -0.3555712879660169, -...\n",
      "451980    [-0.010386442808281651, -0.3555712879660169, -...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58969 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9906865358352661 tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903140068054199 tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9900656342506409 tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903605580329895 tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9905468225479126 tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9906399846076965 tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990500271320343 tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9906244277954102 tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990189790725708 tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9905468543843038\n",
      "Precision :  0.9648593759615977\n",
      "Recall :  0.9975820819546959\n",
      "f1_score :  0.9809479117785078\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9661766290664673 tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9674649834632874 tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9747915863990784 tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9675891995429993 tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9687067866325378 tensor(0.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9684584140777588 tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9714077115058899 tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9713611006736755 tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.97269606590271 tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9740465361749686\n",
      "Precision :  0.9113167760074976\n",
      "Recall :  0.9899465512853143\n",
      "f1_score :  0.9490057338050506\n",
      "+++++++++++++++++ Batch 2 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  365018   -0.009396\n",
      "288820   -0.010906\n",
      "46583    -0.007130\n",
      "391919   -0.010906\n",
      "389051   -0.007130\n",
      "            ...   \n",
      "44078    -0.009396\n",
      "263969   -0.007885\n",
      "91369     0.002687\n",
      "316666   -0.010906\n",
      "333185   -0.010151\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  365018    [-0.009395760281682125, -0.35677138748936715, ...\n",
      "288820    [-0.01090605210767585, -0.35677138748936715, -...\n",
      "46583     [-0.00713032254269154, 3.0752166209629292, -0....\n",
      "391919    [-0.01090605210767585, -0.35677138748936715, -...\n",
      "389051    [-0.00713032254269154, 3.0671885788378948, -0....\n",
      "                                ...                        \n",
      "44078     [-0.009395760281682125, -0.35677138748936715, ...\n",
      "263969    [-0.007885468455688402, -0.35677138748936715, ...\n",
      "91369     [0.0026865743262676645, 0.048644739824880726, ...\n",
      "316666    [-0.01090605210767585, -0.35677138748936715, -...\n",
      "333185    [-0.010150906194678988, -0.35677138748936715, ...\n",
      "Name: h, Length: 64423, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial nx multigraph G1 :  MultiDiGraph with 58961 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.991509199142456 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919127821922302 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918817281723022 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9922077059745789 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921456575393677 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921456575393677 tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911832213401794 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909193515777588 tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921766519546509 tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.992021483010726\n",
      "Precision :  0.9688938658703496\n",
      "Recall :  0.9991018732358224\n",
      "f1_score :  0.9837660286779104\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9752417206764221 tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9760488867759705 tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9761731028556824 tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9766542911529541 tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9772441387176514 tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9770578742027283 tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9790291786193848 tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9781133532524109 tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9773682951927185 tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9786101237135806\n",
      "Precision :  0.926829268292683\n",
      "Recall :  0.9897356941236849\n",
      "f1_score :  0.9572501085810015\n",
      "+++++++++++++++++ Batch 3 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  221957   -0.003264\n",
      "26958     0.010389\n",
      "389183   -0.010090\n",
      "251923   -0.003264\n",
      "378566   -0.009407\n",
      "            ...   \n",
      "103119   -0.003264\n",
      "9649     -0.010090\n",
      "115167   -0.009407\n",
      "331479   -0.010773\n",
      "102313   -0.002581\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  221957    [-0.0032637949568030903, -0.15121653125686546,...\n",
      "26958     [0.01038861281026217, 0.03684084973161964, -0....\n",
      "389183    [-0.01008999884033572, -0.36015485407684594, -...\n",
      "251923    [-0.0032637949568030903, -0.36015485407684594,...\n",
      "378566    [-0.009407378451982458, -0.36015485407684594, ...\n",
      "                                ...                        \n",
      "103119    [-0.0032637949568030903, -0.06480378649469933,...\n",
      "9649      [-0.01008999884033572, -0.36015485407684594, -...\n",
      "115167    [-0.009407378451982458, -0.36015485407684594, ...\n",
      "331479    [-0.010772619228688983, -0.36015485407684594, ...\n",
      "102313    [-0.002581174568449827, 1.9424202280122547, -0...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58989 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9916954636573792 tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917575716972351 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916489124298096 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991571307182312 tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903450608253479 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916954636573792 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918817281723022 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914626479148865 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9920990467071533 tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9916179004392841\n",
      "Precision :  0.9681829480487198\n",
      "Recall :  0.9982060481804202\n",
      "f1_score :  0.9829652996845425\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9758005142211914 tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9762972593307495 tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9768405556678772 tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9767318964004517 tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9773527979850769 tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9774924516677856 tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9780978560447693 tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.978547990322113 tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9787032008171082 tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.977958182636636\n",
      "Precision :  0.9230677480916031\n",
      "Recall :  0.9916709379805229\n",
      "f1_score :  0.956140350877193\n",
      "+++++++++++++++++ Batch 4 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  228467   -0.010457\n",
      "234441   -0.009712\n",
      "160977   -0.010457\n",
      "142650   -0.009712\n",
      "124039   -0.010457\n",
      "            ...   \n",
      "64940     0.006672\n",
      "64133    -0.009712\n",
      "184237   -0.009712\n",
      "435002   -0.000776\n",
      "251659   -0.010457\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train_batched['h'] :  228467    [-0.010456992693339684, -0.3638101050394689, -...\n",
      "234441    [-0.009712266811991336, -0.3638101050394689, -...\n",
      "160977    [-0.010456992693339684, -0.3638101050394689, -...\n",
      "142650    [-0.009712266811991336, -0.3638101050394689, -...\n",
      "124039    [-0.010456992693339684, -0.3638101050394689, -...\n",
      "                                ...                        \n",
      "64940     [0.006671702577672364, 0.029707667181243888, -...\n",
      "64133     [-0.009712266811991336, -0.3638101050394689, -...\n",
      "184237    [-0.009712266811991336, -0.3638101050394689, -...\n",
      "435002    [-0.0007755562358111358, -0.3638101050394689, ...\n",
      "251659    [-0.010456992693339684, -0.3638101050394689, -...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58824 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9909814596176147 tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914160966873169 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.99160236120224 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917575716972351 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917730689048767 tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9915868043899536 tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991850733757019 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9920369982719421 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.992021483010726\n",
      "Precision :  0.9691285172992111\n",
      "Recall :  0.9989115820475063\n",
      "f1_score :  0.9837946907118986\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9754590392112732 tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9744035005569458 tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9750089049339294 tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9782220125198364 tensor(0.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9808453321456909 tensor(0.0518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9792154431343079 tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.978858470916748 tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9816679954528809 tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9808297753334045 tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9808608726696987\n",
      "Precision :  0.935569819547051\n",
      "Recall :  0.9891798450605033\n",
      "f1_score :  0.9616282326580152\n",
      "+++++++++++++++++ Batch 5 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  16581    -0.003950\n",
      "406251   -0.002783\n",
      "408962   -0.002783\n",
      "100903   -0.003950\n",
      "205384   -0.006283\n",
      "            ...   \n",
      "446550   -0.008616\n",
      "132760   -0.008616\n",
      "181843   -0.003950\n",
      "308871   -0.010950\n",
      "398511   -0.010950\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  16581     [-0.003949888577575234, 0.2802302690318937, -0...\n",
      "406251    [-0.0027832822507177757, 3.566135690446177, -0...\n",
      "408962    [-0.0027832822507177757, 2.959261299127865, -0...\n",
      "100903    [-0.003949888577575234, -0.3585848797242246, -...\n",
      "205384    [-0.006283101231290149, -0.3585848797242246, -...\n",
      "                                ...                        \n",
      "446550    [-0.008616313885005064, -0.3585848797242246, -...\n",
      "132760    [-0.008616313885005064, -0.3585848797242246, -...\n",
      "181843    [-0.003949888577575234, 3.5302023383286456, -0...\n",
      "308871    [-0.01094952653871998, -0.3585848797242246, -0...\n",
      "398511    [-0.01094952653871998, -0.3585848797242246, -0...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 59233 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9909969568252563 tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918041229248047 tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917110204696655 tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903295040130615 tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911056160926819 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9906865358352661 tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917420744895935 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916644096374512 tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917420744895935 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9900967045930801\n",
      "Precision :  0.9614117939476791\n",
      "Recall :  0.9989024468977984\n",
      "f1_score :  0.9797986194667848\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9760644435882568 tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9780202507972717 tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9793396592140198 tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9793862104415894 tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9802399277687073 tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9795880317687988 tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9792931079864502 tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9814041256904602 tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9795259237289429 tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9828632631203141\n",
      "Precision :  0.9456595823780903\n",
      "Recall :  0.9853444379882498\n",
      "f1_score :  0.9650942203111168\n",
      "++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Test instances :  138050\n",
      "\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9913437160449112\n",
      "Precision :  0.9682263076878395\n",
      "Recall :  0.9969794844189246\n",
      "f1_score :  0.9823925503543591\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9822745382107931\n",
      "Precision :  0.9445703629321475\n",
      "Recall :  0.9845983611460015\n",
      "f1_score :  0.9641690949292021\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CIC-IDS-2017-Dataset0.csv ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nb total instances in the file :  460165\n",
      "++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\n",
      "\n",
      "labels freq after changing labels to binary\n",
      "{'CIC-IDS-2017-Dataset0.csv': [[0, 0.7576130301087654], [1, 0.24238696989123468]]}\n",
      "+++++++++++++++++ Batch 1 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  307145   -0.003533\n",
      "416426   -0.009142\n",
      "28106    -0.010077\n",
      "380098   -0.005403\n",
      "133189   -0.004468\n",
      "            ...   \n",
      "341625   -0.009142\n",
      "446794   -0.009142\n",
      "200125   -0.008207\n",
      "312166   -0.009142\n",
      "408939   -0.008207\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  307145    [-0.003533315367368421, -0.15349263948140296, ...\n",
      "416426    [-0.009141912296767607, -0.35905396250072513, ...\n",
      "28106     [-0.010076678451667471, -0.35905396250072513, ...\n",
      "380098    [-0.005402847677168149, -0.08395577215636896, ...\n",
      "133189    [-0.0044680815222682855, 3.6673704192242784, -...\n",
      "                                ...                        \n",
      "341625    [-0.009141912296767607, -0.35905396250072513, ...\n",
      "446794    [-0.009141912296767607, -0.35905396250072513, ...\n",
      "200125    [-0.008207146141867743, -0.35905396250072513, ...\n",
      "312166    [-0.009141912296767607, -0.35905396250072513, ...\n",
      "408939    [-0.008207146141867743, -0.35905396250072513, ...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58937 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9902829527854919 tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913384914398193 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916799664497375 tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918041229248047 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9910125136375427 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917575716972351 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917110204696655 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917265176773071 tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9918817813513807\n",
      "Precision :  0.9701614938178148\n",
      "Recall :  0.9967593492773349\n",
      "f1_score :  0.9832805856590263\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9826459288597107 tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9827390313148499 tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9833133816719055 tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983173668384552 tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9836393594741821 tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9838566780090332 tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9841360449790955 tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9843844175338745 tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983235776424408 tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9846483398786148\n",
      "Precision :  0.9531191163549643\n",
      "Recall :  0.9843152505023008\n",
      "f1_score :  0.9684660268469215\n",
      "+++++++++++++++++ Batch 2 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  246770   -0.006498\n",
      "106728   -0.006498\n",
      "313166   -0.009220\n",
      "29341     0.249322\n",
      "274902   -0.009900\n",
      "            ...   \n",
      "105759   -0.009900\n",
      "192886   -0.009220\n",
      "82033    -0.009220\n",
      "82688    -0.005137\n",
      "360305   -0.009220\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  246770    [-0.006498142763417493, -0.35841960482788376, ...\n",
      "106728    [-0.006498142763417493, 3.632559910823396, -0....\n",
      "313166    [-0.009219633113559425, -0.35841960482788376, ...\n",
      "29341     [0.24932195014992414, -0.14327404888708314, 0....\n",
      "274902    [-0.009900005701094908, -0.35841960482788376, ...\n",
      "                                ...                        \n",
      "105759    [-0.009900005701094908, -0.35841960482788376, ...\n",
      "192886    [-0.009219633113559425, -0.14180541636501737, ...\n",
      "82033     [-0.009219633113559425, -0.35841960482788376, ...\n",
      "82688     [-0.005137397588346526, -0.35841960482788376, ...\n",
      "360305    [-0.009219633113559425, -0.35841960482788376, ...\n",
      "Name: h, Length: 64423, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial nx multigraph G1 :  MultiDiGraph with 58868 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.991291880607605 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911056160926819 tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9910901188850403 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911677241325378 tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913539886474609 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914937019348145 tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913850426673889 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913384914398193 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914781451225281 tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9916489452524719\n",
      "Precision :  0.9674033831337202\n",
      "Recall :  0.9993622448979592\n",
      "f1_score :  0.9831231570362005\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9825372695922852 tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9828476905822754 tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9829563498497009 tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830339550971985 tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830960631370544 tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9834685921669006 tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9832512736320496 tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9833754897117615 tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9834685921669006 tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9835772938236345\n",
      "Precision :  0.9426080639302579\n",
      "Recall :  0.9929846938775511\n",
      "f1_score :  0.9671408161997639\n",
      "+++++++++++++++++ Batch 3 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  347288    0.008412\n",
      "228000    0.008412\n",
      "292674   -0.012026\n",
      "328969   -0.052903\n",
      "336125    0.090166\n",
      "            ...   \n",
      "315858   -0.063122\n",
      "326884   -0.042684\n",
      "127912   -0.052903\n",
      "322342   -0.052903\n",
      "112400   -0.052903\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  347288    [0.008412324577302508, -0.136192765921883, -0....\n",
      "228000    [0.008412324577302508, 3.6216240423567734, 0.0...\n",
      "292674    [-0.012026172414836547, 2.816839677076587, 0.0...\n",
      "328969    [-0.05290316639911466, -0.3584728928655352, -0...\n",
      "336125    [0.09016631254585873, 0.030146520905472245, -0...\n",
      "                                ...                        \n",
      "315858    [-0.06312241489518419, -0.3584728928655352, -0...\n",
      "326884    [-0.042683917903045134, -0.3584728928655352, -...\n",
      "127912    [-0.05290316639911466, -0.3584728928655352, -0...\n",
      "322342    [-0.05290316639911466, -0.3584728928655352, -0...\n",
      "112400    [-0.05290316639911466, -0.3584728928655352, -0...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58700 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.992362916469574 tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991322934627533 tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9913694858551025 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991509199142456 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917886257171631 tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917886257171631 tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918351769447327 tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918351769447327 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9916489452524719\n",
      "Precision :  0.9674706929356165\n",
      "Recall :  0.9994927398389449\n",
      "f1_score :  0.9832210578842315\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9784703850746155 tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.979960560798645 tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9815127849578857 tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9819939732551575 tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9818387627601624 tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9819629192352295 tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9820560812950134 tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9824286103248596 tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9822578430175781 tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9822889340763392\n",
      "Precision :  0.9399206158287227\n",
      "Recall :  0.9909961321412719\n",
      "f1_score :  0.9647828636686316\n",
      "+++++++++++++++++ Batch 4 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  216518   -0.007926\n",
      "183681   -0.008856\n",
      "414029   -0.006067\n",
      "3819     -0.007926\n",
      "273049    0.254301\n",
      "            ...   \n",
      "57773    -0.008856\n",
      "151187   -0.004207\n",
      "355422   -0.004207\n",
      "6818     -0.007926\n",
      "228212   -0.007926\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train_batched['h'] :  216518    [-0.007926313892727596, 1.5613692293410455, -0...\n",
      "183681    [-0.008856198657835199, -0.35681623308951127, ...\n",
      "414029    [-0.0060665443625123865, 0.04270989585940479, ...\n",
      "3819      [-0.007926313892727596, -0.35681623308951127, ...\n",
      "273049    [0.25430118986761685, -0.11727600146998897, 0....\n",
      "                                ...                        \n",
      "57773     [-0.008856198657835199, -0.35681623308951127, ...\n",
      "151187    [-0.004206774832297177, -0.13723917557030965, ...\n",
      "355422    [-0.004206774832297177, -0.35681623308951127, ...\n",
      "6818      [-0.007926313892727596, -0.35681623308951127, ...\n",
      "228212    [-0.007926313892727596, -0.35681623308951127, ...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58893 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9893205761909485 tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9904071092605591 tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9899414777755737 tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9907175898551941 tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9907951951026917 tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.99015873670578 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9899414777755737 tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911056160926819 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903916120529175 tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9908728249227761\n",
      "Precision :  0.9646942434922402\n",
      "Recall :  0.9989115820475063\n",
      "f1_score :  0.9815047810770006\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9612870812416077 tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.96429842710495 tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9657419919967651 tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9671545624732971 tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9672321677207947 tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9690327644348145 tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9701504111289978 tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9719975590705872 tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9743103981018066 tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9749778805706036\n",
      "Precision :  0.9152190668168614\n",
      "Recall :  0.9883475254497727\n",
      "f1_score :  0.9503786246383057\n",
      "+++++++++++++++++ Batch 5 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  274780   -0.004455\n",
      "50694    -0.010534\n",
      "126071    0.007704\n",
      "173522   -0.010534\n",
      "414853   -0.010534\n",
      "            ...   \n",
      "193989   -0.011750\n",
      "84383    -0.006886\n",
      "221887   -0.009318\n",
      "156806   -0.002023\n",
      "100299   -0.005671\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  274780    [-0.004454638627294411, -0.14815818285229523, ...\n",
      "50694     [-0.010534155968532084, -0.3615581377751653, -...\n",
      "126071    [0.007704396055180936, 0.035770011567146286, -...\n",
      "173522    [-0.010534155968532084, -0.07326052401196181, ...\n",
      "414853    [-0.010534155968532084, -0.3615581377751653, -...\n",
      "                                ...                        \n",
      "193989    [-0.01175005943677962, -0.3615581377751653, -0...\n",
      "84383     [-0.006886445563789481, 0.028006307663952974, ...\n",
      "221887    [-0.00931825250028455, -0.3615581377751653, -0...\n",
      "156806    [-0.002022831690799342, -0.3615581377751653, -...\n",
      "100299    [-0.005670542095541946, -0.3615581377751653, -...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58531 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9916799664497375 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917886257171631 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917886257171631 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9912453293800354 tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9910590648651123 tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991633415222168 tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919438362121582 tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.99160236120224 tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9911056610216848\n",
      "Precision :  0.9653846153846154\n",
      "Recall :  0.9990370417923862\n",
      "f1_score :  0.9819225794239204\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9674339890480042 tensor(0.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9709575176239014 tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9714077115058899 tensor(0.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.971842348575592 tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9730375409126282 tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9741396307945251 tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9733945727348328 tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9763593673706055 tensor(0.0541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9757074117660522 tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9770734054607826\n",
      "Precision :  0.9218020820868733\n",
      "Recall :  0.9890864736470437\n",
      "f1_score :  0.9542597008454369\n",
      "++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Test instances :  138050\n",
      "\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.991901484969214\n",
      "Precision :  0.9688895331980284\n",
      "Recall :  0.9986551909628832\n",
      "f1_score :  0.9835472097951495\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9749366171676929\n",
      "Precision :  0.9163937156498084\n",
      "Recall :  0.9866116789193712\n",
      "f1_score :  0.950207230025328\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CIC-IDS-2017-Dataset2.csv ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nb total instances in the file :  460167\n",
      "++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\n",
      "\n",
      "labels freq after changing labels to binary\n",
      "{'CIC-IDS-2017-Dataset2.csv': [[0, 0.7570208207020495], [1, 0.24297917929795051]]}\n",
      "+++++++++++++++++ Batch 1 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  327927   -0.091723\n",
      "39       -0.061261\n",
      "137961    0.075820\n",
      "8596      0.197669\n",
      "68252    -0.061261\n",
      "            ...   \n",
      "80365    -0.015567\n",
      "169822   -0.076492\n",
      "265647   -0.076492\n",
      "441693   -0.091723\n",
      "139393   -0.061261\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  327927    [-0.09172296011018856, -0.35920350112499405, -...\n",
      "39        [-0.06126062641421204, -0.35920350112499405, -...\n",
      "137961    [0.0758198752176823, -0.14675784145318138, -0....\n",
      "8596      [0.19766921000158838, 0.04075858424489984, 0.0...\n",
      "68252     [-0.06126062641421204, -0.35920350112499405, -...\n",
      "                                ...                        \n",
      "80365     [-0.01556712587024726, 3.5645877860712125, 0.0...\n",
      "169822    [-0.0764917932622003, -0.35920350112499405, -0...\n",
      "265647    [-0.0764917932622003, -0.35920350112499405, -0...\n",
      "441693    [-0.09172296011018856, -0.35920350112499405, -...\n",
      "139393    [-0.06126062641421204, -0.35920350112499405, -...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 59056 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9919127821922302 tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919593334197998 tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919593334197998 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919283390045166 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919127821922302 tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919127821922302 tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919593334197998 tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919593334197998 tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919438362121582 tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9919749157909442\n",
      "Precision :  0.9681552431894515\n",
      "Recall :  0.9996788902446856\n",
      "f1_score :  0.9836645707605296\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9771820306777954 tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9805037975311279 tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9804883003234863 tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9813265204429626 tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9814041256904602 tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9813420176506042 tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9811868071556091 tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9819939732551575 tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9814972877502441 tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9821337100104001\n",
      "Precision :  0.938671209540034\n",
      "Recall :  0.9908162609980091\n",
      "f1_score :  0.964039116443278\n",
      "+++++++++++++++++ Batch 2 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  387299   -0.007749\n",
      "399399   -0.007749\n",
      "406895   -0.004002\n",
      "291151   -0.007749\n",
      "20970    -0.003065\n",
      "            ...   \n",
      "410502   -0.008686\n",
      "48679    -0.007749\n",
      "215158   -0.009623\n",
      "328212   -0.009623\n",
      "334287   -0.007749\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  387299    [-0.007749371592672693, -0.36002373065288434, ...\n",
      "399399    [-0.007749371592672693, -0.36002373065288434, ...\n",
      "406895    [-0.0040020858340979884, -0.36002373065288434,...\n",
      "291151    [-0.007749371592672693, -0.36002373065288434, ...\n",
      "20970     [-0.003065264394454312, 3.5451198420886203, -0...\n",
      "                                ...                        \n",
      "410502    [-0.008686193032316368, -0.36002373065288434, ...\n",
      "48679     [-0.007749371592672693, -0.36002373065288434, ...\n",
      "215158    [-0.009623014471960045, -0.36002373065288434, ...\n",
      "328212    [-0.009623014471960045, -0.36002373065288434, ...\n",
      "334287    [-0.007749371592672693, -0.36002373065288434, ...\n",
      "Name: h, Length: 64423, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial nx multigraph G1 :  MultiDiGraph with 58870 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9905623197555542 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911677241325378 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991850733757019 tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9915247559547424 tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9924095273017883 tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9923008680343628 tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9920524954795837 tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921611547470093 tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9920524954795837 tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9913850643403753\n",
      "Precision :  0.9669020571077679\n",
      "Recall :  0.9989849003933511\n",
      "f1_score :  0.9826816862732861\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9727426171302795 tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.97480708360672 tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9759712815284729 tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9765145778656006 tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9764214158058167 tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.979712188243866 tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.979991614818573 tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.980783224105835 tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9812954664230347 tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9820095307576486\n",
      "Precision :  0.9403003075438703\n",
      "Recall :  0.9892780104047709\n",
      "f1_score :  0.9641675684031535\n",
      "+++++++++++++++++ Batch 3 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  121582   -0.010666\n",
      "445602   -0.011960\n",
      "297676   -0.004195\n",
      "420136   -0.004195\n",
      "110805   -0.009372\n",
      "            ...   \n",
      "43952    -0.009372\n",
      "338207   -0.009372\n",
      "116794   -0.011960\n",
      "140810   -0.010666\n",
      "149802   -0.011960\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n",
      "X1_train_batched['h'] :  121582    [-0.01066607266523396, -0.3586584001537264, -0...\n",
      "445602    [-0.011960312495778499, 0.5166234864859072, -0...\n",
      "297676    [-0.004194873512511269, -0.3586584001537264, -...\n",
      "420136    [-0.004194873512511269, -0.3586584001537264, -...\n",
      "110805    [-0.009371832834689422, -0.3586584001537264, -...\n",
      "                                ...                        \n",
      "43952     [-0.009371832834689422, -0.3586584001537264, -...\n",
      "338207    [-0.009371832834689422, -0.3586584001537264, -...\n",
      "116794    [-0.011960312495778499, -0.3586584001537264, -...\n",
      "140810    [-0.01066607266523396, -0.3586584001537264, -0...\n",
      "149802    [-0.011960312495778499, -0.3586584001537264, -...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58988 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.991260826587677 tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991540253162384 tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914781451225281 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9917420744895935 tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918972849845886 tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918041229248047 tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918196797370911 tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9917576020986294\n",
      "Precision :  0.9673946668316525\n",
      "Recall :  0.9997442455242966\n",
      "f1_score :  0.983303461937553\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9802399277687073 tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9808297753334045 tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9819318652153015 tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9816524982452393 tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.981823205947876 tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.982071578502655 tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9822112917900085 tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9823975563049316 tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9824130535125732 tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9824752029554662\n",
      "Precision :  0.9400739976951538\n",
      "Recall :  0.9909846547314578\n",
      "f1_score :  0.9648582189435677\n",
      "+++++++++++++++++ Batch 4 ++++++++++++++++\n",
      "nb Train instances :  64423\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  9506     -0.011971\n",
      "114260    0.002603\n",
      "7722     -0.004684\n",
      "163070   -0.026546\n",
      "390407   -0.019259\n",
      "            ...   \n",
      "106510   -0.026546\n",
      "429722   -0.019259\n",
      "384059   -0.008328\n",
      "277526   -0.019259\n",
      "215026   -0.001040\n",
      "Name:  Total Backward Packets, Length: 64423, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train_batched['h'] :  9506      [-0.011971442923664196, -0.35423631434153063, ...\n",
      "114260    [0.0026034909086661544, -0.35423631434153063, ...\n",
      "7722      [-0.004683976007499021, 0.05876350311079469, -...\n",
      "163070    [-0.026546376755994548, -0.35423631434153063, ...\n",
      "390407    [-0.01925890983982937, -0.35423631434153063, -...\n",
      "                                ...                        \n",
      "106510    [-0.026546376755994548, -0.35423631434153063, ...\n",
      "429722    [-0.01925890983982937, -0.35423631434153063, -...\n",
      "384059    [-0.008327709465581609, -0.35423631434153063, ...\n",
      "277526    [-0.01925890983982937, -0.35423631434153063, -...\n",
      "215026    [-0.0010402425494164334, -0.35423631434153063,...\n",
      "Name: h, Length: 64423, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58916 nodes and 64423 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1.edata['h'] after reshape :  64423\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128846 nodes and 64423 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64423\n",
      "G1_ab.edata['h'] after reshape :  64423\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9918662309646606 tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.992580235004425 tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9925647377967834 tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.992580235004425 tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.992611289024353 tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9925957918167114 tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9926268458366394 tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.992580235004425 tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.992642343044281 tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9926113344612949\n",
      "Precision :  0.970639246778989\n",
      "Recall :  0.9998723838693211\n",
      "f1_score :  0.9850389741010812\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9817922115325928 tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9825062155723572 tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983142614364624 tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9827856421470642 tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9829097986221313 tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983173668384552 tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9831581711769104 tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9833909869194031 tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983142614364624 tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9834996817906648\n",
      "Precision :  0.9435302689902241\n",
      "Recall :  0.991513527309852\n",
      "f1_score :  0.9669269780031736\n",
      "+++++++++++++++++ Batch 5 ++++++++++++++++\n",
      "nb Train instances :  64424\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  25507    -0.004070\n",
      "199830   -0.010117\n",
      "68091     0.012054\n",
      "219890   -0.009109\n",
      "247326    0.005000\n",
      "            ...   \n",
      "125119   -0.008101\n",
      "89053    -0.009109\n",
      "321006   -0.010117\n",
      "358161   -0.010117\n",
      "153740   -0.005078\n",
      "Name:  Total Backward Packets, Length: 64424, dtype: float64\n",
      "X1_train_batched['h'] :  25507     [-0.0040703209961957644, -0.3591831423223757, ...\n",
      "199830    [-0.010116884536582823, -0.3591831423223757, -...\n",
      "68091     [0.012053848444836392, -0.14136696824530418, -...\n",
      "219890    [-0.009109123946518314, -0.3591831423223757, -...\n",
      "247326    [0.004999524314384824, -0.12625593379245556, -...\n",
      "                                ...                        \n",
      "125119    [-0.008101363356453803, -0.10285523488903267, ...\n",
      "89053     [-0.009109123946518314, -0.3591831423223757, -...\n",
      "321006    [-0.010116884536582823, -0.3591831423223757, -...\n",
      "358161    [-0.010116884536582823, -0.3591831423223757, -...\n",
      "153740    [-0.005078081586260274, -0.3591831423223757, -...\n",
      "Name: h, Length: 64424, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58881 nodes and 64424 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64424\n",
      "G1.edata['h'] after reshape :  64424\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128848 nodes and 64424 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64424\n",
      "G1_ab.edata['h'] after reshape :  64424\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9891965985298157 tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914162755012512 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.991835355758667 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9916490912437439 tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919285178184509 tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919750690460205 tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9918819069862366 tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919129610061646 tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9919440150260925 tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9919905625232832\n",
      "Precision :  0.9684321508310593\n",
      "Recall :  0.9995519139674818\n",
      "f1_score :  0.9837459837459837\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9792934656143188 tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9827083349227905 tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830963611602783 tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9831584692001343 tensor(0.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9832826256752014 tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9834688901901245 tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9836241602897644 tensor(0.0363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983391284942627 tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9837328195571899 tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9837172482304731\n",
      "Precision :  0.9433526011560693\n",
      "Recall :  0.9924465497375496\n",
      "f1_score :  0.9672770377764607\n",
      "++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Test instances :  138051\n",
      "\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138051\n",
      "Metrics : \n",
      "Accuracy :  0.9910395433571652\n",
      "Precision :  0.9674180387163981\n",
      "Recall :  0.9966909134271404\n",
      "f1_score :  0.9818363361379087\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138051\n",
      "Metrics : \n",
      "Accuracy :  0.9829628180889671\n",
      "Precision :  0.942515038020656\n",
      "Recall :  0.9902814214166468\n",
      "f1_score :  0.9658079897656568\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "CIC-IDS-2017-Dataset3.csv ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nb total instances in the file :  460164\n",
      "++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\n",
      "\n",
      "labels freq after changing labels to binary\n",
      "{'CIC-IDS-2017-Dataset3.csv': [[0, 0.757532097252284], [1, 0.24246790274771604]]}\n",
      "+++++++++++++++++ Batch 1 ++++++++++++++++\n",
      "nb Train instances :  64422\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  238145    0.003508\n",
      "244011   -0.010414\n",
      "294783   -0.005773\n",
      "457788   -0.012735\n",
      "287921   -0.012735\n",
      "            ...   \n",
      "389758   -0.004613\n",
      "68893    -0.012735\n",
      "346646   -0.002293\n",
      "293196   -0.010414\n",
      "329340   -0.010414\n",
      "Name:  Total Backward Packets, Length: 64422, dtype: float64\n",
      "X1_train_batched['h'] :  238145    [0.0035084563255902827, 0.030874458564222964, ...\n",
      "244011    [-0.010414355898231888, -0.3637937842823298, -...\n",
      "294783    [-0.005773418490291164, 0.030774449631485647, ...\n",
      "457788    [-0.01273482460220225, -0.3637937842823298, -0...\n",
      "287921    [-0.01273482460220225, -0.3637937842823298, -0...\n",
      "                                ...                        \n",
      "389758    [-0.004613184138305983, -0.3637937842823298, -...\n",
      "68893     [-0.01273482460220225, -0.3637937842823298, -0...\n",
      "346646    [-0.0022927154343356216, -0.1485625236502179, ...\n",
      "293196    [-0.010414355898231888, -0.3637937842823298, -...\n",
      "329340    [-0.010414355898231888, -0.3637937842823298, -...\n",
      "Name: h, Length: 64422, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58711 nodes and 64422 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1.edata['h'] after reshape :  64422\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128844 nodes and 64422 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1_ab.edata['h'] after reshape :  64422\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9903759956359863 tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9904536008834839 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9905933141708374 tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9902517795562744 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9908416867256165 tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990670919418335 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9911055564880371 tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9912452697753906 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9909968972206116 tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9910123870727391\n",
      "Precision :  0.9651262564354008\n",
      "Recall :  0.9993653614266675\n",
      "f1_score :  0.9819474324197924\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9741082787513733 tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.97572261095047 tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9765142798423767 tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9769178628921509 tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9778336882591248 tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9800379276275635 tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830803275108337 tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9837167859077454 tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9835305213928223 tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9834062897767843\n",
      "Precision :  0.9433711663849311\n",
      "Recall :  0.9916862346893445\n",
      "f1_score :  0.9669255282942978\n",
      "+++++++++++++++++ Batch 2 ++++++++++++++++\n",
      "nb Train instances :  64422\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  36687    -0.007937\n",
      "95964    -0.007937\n",
      "102389   -0.003415\n",
      "443285   -0.007937\n",
      "7214     -0.005353\n",
      "            ...   \n",
      "335388   -0.009229\n",
      "252764   -0.007937\n",
      "123232   -0.007937\n",
      "281036   -0.008583\n",
      "231541    0.001107\n",
      "Name:  Total Backward Packets, Length: 64422, dtype: float64\n",
      "X1_train_batched['h'] :  36687     [-0.007937303205266583, -0.36006097139564547, ...\n",
      "95964     [-0.007937303205266583, -0.36006097139564547, ...\n",
      "102389    [-0.003415176022756218, 0.7934248609838402, -0...\n",
      "443285    [-0.007937303205266583, -0.36006097139564547, ...\n",
      "7214      [-0.005353230529546374, -0.36006097139564547, ...\n",
      "                                ...                        \n",
      "335388    [-0.009229339543126687, -0.36006097139564547, ...\n",
      "252764    [-0.007937303205266583, -0.36006097139564547, ...\n",
      "123232    [-0.007937303205266583, -0.36006097139564547, ...\n",
      "281036    [-0.008583321374196635, -0.36006097139564547, ...\n",
      "231541    [0.0011069511597541469, -0.36006097139564547, ...\n",
      "Name: h, Length: 64422, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial nx multigraph G1 :  MultiDiGraph with 59083 nodes and 64422 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1.edata['h'] after reshape :  64422\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128844 nodes and 64422 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1_ab.edata['h'] after reshape :  64422\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9897861480712891 tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9899103045463562 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9901276230812073 tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9907019734382629 tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9900189638137817 tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9900965690612793 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903294444084167 tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990950345993042 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903914928436279 tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9901275961628015\n",
      "Precision :  0.9612667327714427\n",
      "Recall :  0.999291328437057\n",
      "f1_score :  0.9799102912376018\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9687684774398804 tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9691875576972961 tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9690168499946594 tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9705225229263306 tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9731147885322571 tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9745118618011475 tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9744652509689331 tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.97572261095047 tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9761883020401001 tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9774611157679054\n",
      "Precision :  0.9205523672883787\n",
      "Recall :  0.9920757634325473\n",
      "f1_score :  0.9549767441860465\n",
      "+++++++++++++++++ Batch 3 ++++++++++++++++\n",
      "nb Train instances :  64422\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  459538   -0.011605\n",
      "308773   -0.010146\n",
      "239606   -0.013064\n",
      "25288    -0.011605\n",
      "453925   -0.011605\n",
      "            ...   \n",
      "210216   -0.011605\n",
      "253665   -0.011605\n",
      "133374   -0.002851\n",
      "125243    0.055506\n",
      "135144   -0.013064\n",
      "Name:  Total Backward Packets, Length: 64422, dtype: float64\n",
      "X1_train_batched['h'] :  459538    [-0.011604713034167904, -0.35847407149527566, ...\n",
      "308773    [-0.01014577866077854, -0.35847407149527566, -...\n",
      "239606    [-0.013063647407557267, -0.35847407149527566, ...\n",
      "25288     [-0.011604713034167904, -0.35847407149527566, ...\n",
      "453925    [-0.011604713034167904, -0.35847407149527566, ...\n",
      "                                ...                        \n",
      "210216    [-0.011604713034167904, -0.35847407149527566, ...\n",
      "253665    [-0.011604713034167904, -0.35847407149527566, ...\n",
      "133374    [-0.002851106793831723, 3.5184884856125427, -0...\n",
      "125243    [0.055506268141742816, -0.35847407149527566, 0...\n",
      "135144    [-0.013063647407557267, -0.35847407149527566, ...\n",
      "Name: h, Length: 64422, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 59005 nodes and 64422 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1.edata['h'] after reshape :  64422\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128844 nodes and 64422 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1_ab.edata['h'] after reshape :  64422\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9927354454994202 tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928596019744873 tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928285479545593 tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928751587867737 tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928751587867737 tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9929217100143433 tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928906559944153 tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9929061532020569 tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9928906559944153 tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9929061500729565\n",
      "Precision :  0.9718283465550628\n",
      "Recall :  0.9996144949884348\n",
      "f1_score :  0.9855256073227123\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9830337762832642 tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.982909619808197 tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9832510948181152 tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9836702346801758 tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9832045435905457 tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9835149645805359 tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9834684133529663 tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830027222633362 tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.983701229095459 tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9842445127440936\n",
      "Precision :  0.9460967682590299\n",
      "Recall :  0.9912618864045233\n",
      "f1_score :  0.9681528662420382\n",
      "+++++++++++++++++ Batch 4 ++++++++++++++++\n",
      "nb Train instances :  64422\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  215916   -0.029446\n",
      "279183   -0.005770\n",
      "416113   -0.029446\n",
      "129087   -0.041283\n",
      "20894    -0.029446\n",
      "            ...   \n",
      "431625   -0.029446\n",
      "289322   -0.035365\n",
      "447925   -0.029446\n",
      "117087   -0.029446\n",
      "52662     0.000149\n",
      "Name:  Total Backward Packets, Length: 64422, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train_batched['h'] :  215916    [-0.029445652666745474, -0.3578530493299633, -...\n",
      "279183    [-0.0057702057152199835, 3.0525457885894047, 0...\n",
      "416113    [-0.029445652666745474, -0.3578530493299633, -...\n",
      "129087    [-0.041283376142508224, 0.4997560591479976, -0...\n",
      "20894     [-0.029445652666745474, -0.3578530493299633, -...\n",
      "                                ...                        \n",
      "431625    [-0.029445652666745474, -0.3578530493299633, -...\n",
      "289322    [-0.035364514404626846, -0.3578530493299633, -...\n",
      "447925    [-0.029445652666745474, -0.3578530493299633, -...\n",
      "117087    [-0.029445652666745474, -0.3578530493299633, -...\n",
      "52662     [0.00014865602266138936, 0.8444027102185799, -...\n",
      "Name: h, Length: 64422, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58861 nodes and 64422 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1.edata['h'] after reshape :  64422\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128844 nodes and 64422 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64422\n",
      "G1_ab.edata['h'] after reshape :  64422\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9916177988052368 tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9914936423301697 tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921455979347229 tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921765923500061 tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921455979347229 tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921610951423645 tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921610951423645 tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921765923500061 tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9921610951423645 tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9921610629909037\n",
      "Precision :  0.9691285172992111\n",
      "Recall :  0.9994875080076874\n",
      "f1_score :  0.9840739222302817\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9795256853103638 tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9789978861808777 tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.978702962398529 tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9796032905578613 tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9786719083786011 tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9790910482406616 tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9792462587356567 tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9798826575279236 tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9791841506958008 tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9799136940796622\n",
      "Precision :  0.9284688135999042\n",
      "Recall :  0.9936579115951313\n",
      "f1_score :  0.9599579155836117\n",
      "+++++++++++++++++ Batch 5 ++++++++++++++++\n",
      "nb Train instances :  64426\n",
      "cols_to_norm1 :  [' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "cols_to_norm1[0] :   Total Backward Packets\n",
      "X1_train_batched[cols_to_norm1[0]] :  353533   -0.008773\n",
      "13584    -0.007825\n",
      "302552   -0.004981\n",
      "155963   -0.007825\n",
      "45585    -0.005929\n",
      "            ...   \n",
      "370369   -0.008773\n",
      "396053   -0.009721\n",
      "330895   -0.002137\n",
      "358593   -0.008773\n",
      "177270   -0.008773\n",
      "Name:  Total Backward Packets, Length: 64426, dtype: float64\n",
      "X1_train_batched['h'] :  353533    [-0.008772823046788877, -0.3602062997303678, -...\n",
      "13584     [-0.007824876606947438, -0.3602062997303678, -...\n",
      "302552    [-0.004981037287423123, 3.544823368504752, -0....\n",
      "155963    [-0.007824876606947438, -0.3602062997303678, -...\n",
      "45585     [-0.005928983727264562, -0.3602062997303678, -...\n",
      "                                ...                        \n",
      "370369    [-0.008772823046788877, -0.3602062997303678, -...\n",
      "396053    [-0.009720769486630317, -0.3602062997303678, -...\n",
      "330895    [-0.002137197967898808, 3.5289492641623332, -0...\n",
      "358593    [-0.008772823046788877, -0.3602062997303678, -...\n",
      "177270    [-0.008772823046788877, -0.3602062997303678, -...\n",
      "Name: h, Length: 64426, dtype: object\n",
      "initial nx multigraph G1 :  MultiDiGraph with 58854 nodes and 64426 edges\n",
      "G1.edata['h'] after converting it to a dgl graph :  64426\n",
      "G1.edata['h'] after reshape :  64426\n",
      "\n",
      "initial nx multigraph G1_ab :  MultiDiGraph with 128852 nodes and 64426 edges\n",
      "G1_ab.edata['h'] after converting it to a dgl graph :  64426\n",
      "G1_ab.edata['h'] after reshape :  64426\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9897712469100952 tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903610348701477 tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9903144836425781 tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9897401928901672 tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9899574518203735 tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9908266663551331 tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9899885058403015 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.990128219127655 tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9897246360778809 tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9913389004439201\n",
      "Precision :  0.9664914992272025\n",
      "Recall :  0.998977570451786\n",
      "f1_score :  0.9824660633484162\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Training acc: 0.9811567068099976 tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9821966290473938 tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9825846552848816 tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830037951469421 tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9832055568695068 tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9831123948097229 tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9830347895622253 tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9831590056419373 tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9836246371269226 tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Train metrics :\n",
      "Accuracy :  0.9843230993698197\n",
      "Precision :  0.9475389789055335\n",
      "Recall :  0.9902869192919675\n",
      "f1_score :  0.9684414448193976\n",
      "++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Test instances :  138050\n",
      "\n",
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9908294096341905\n",
      "Precision :  0.9682475066151028\n",
      "Recall :  0.9948017805395394\n",
      "f1_score :  0.981345043027231\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9835132198478812\n",
      "Precision :  0.9456841624046401\n",
      "Recall :  0.9887969408179726\n",
      "f1_score :  0.9667601355298515\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------- MAIN -----------------------------------------------------------\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "# Model *******************************************************************************************\n",
    "# G1.ndata['h'].shape[2] = sizeh = 76 dans ANIDS\n",
    "# model1 = Model(G1.ndata['h'].shape[2], size_embedding, G1.ndata['h'].shape[2], F.relu, 0.2).cuda()\n",
    "model1 = Model(76, size_embedding, 76, F.relu, 0.2).cuda()\n",
    "opt = th.optim.Adam(model1.parameters())\n",
    "\n",
    "model1_ab = Model(76, size_embedding, 76, F.relu, 0.2).cuda()\n",
    "opt_ab = th.optim.Adam(model1_ab.parameters())\n",
    "\n",
    "\n",
    "# Classes\n",
    "clss = ['BENIGN', 'Brute Force', 'XSS', 'Sql Injection', 'Heartbleed', 'DoS Hulk', 'DDoS', 'PortScan', 'FTP-Patator', 'Bot', 'DoS slowloris', 'DoS GoldenEye', 'DoS Slowhttptest', 'SSH-Patator', 'Infiltration']\n",
    "# Classes mpping\n",
    "clss_mpping = {}\n",
    "cpt = 0\n",
    "for x in clss:\n",
    "    clss_mpping[x] = cpt\n",
    "    cpt += 1\n",
    "print(clss_mpping)\n",
    "\n",
    "\n",
    "\n",
    "path, dirs, files = next(os.walk(\"/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/input/Dataset/GlobalDataset/Splitted/\"))\n",
    "file_count = len(files)\n",
    "\n",
    "\n",
    "for nb_files in range(file_count):\n",
    "    data1 = pd.read_csv(f'{path}{files[nb_files]}', encoding=\"ISO-88591\", dtype = str)\n",
    "\n",
    "    print(f'{files[nb_files]} ++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print(\"nb total instances in the file : \", len(data1.values))\n",
    "\n",
    "    print(\"++++++++++++++++++++++++++++ Train ++++++++++++++++++++++++++++++++\")\n",
    "    \n",
    "    # Delete two columns (U and V in the excel)\n",
    "    cols = list(set(list(data1.columns )) - set(list(['Flow Bytes/s',' Flow Packets/s'])) )\n",
    "    data1 = data1[cols]\n",
    "\n",
    "    # Mise en forme des noeuds\n",
    "    data1[' Source IP'] = data1[' Source IP'].apply(str)\n",
    "    data1[' Source Port'] = data1[' Source Port'].apply(str)\n",
    "    data1[' Destination IP'] = data1[' Destination IP'].apply(str)\n",
    "    data1[' Destination Port'] = data1[' Destination Port'].apply(str)\n",
    "    data1[' Source IP'] = data1[' Source IP'] + ':' + data1[' Source Port']\n",
    "    data1[' Destination IP'] = data1[' Destination IP'] + ':' + data1[' Destination Port']\n",
    "\n",
    "    data1.drop(columns=['Flow ID',' Source Port',' Destination Port',' Timestamp'], inplace=True)\n",
    "    \n",
    "    data1['DetailedLabel'] = data1[' Label']\n",
    "    data1['DetailedLabel'] = data1['DetailedLabel'].apply(str)\n",
    "    # Classes mpping for the DetailedLabel\n",
    "    data1 = data1.replace({'DetailedLabel': clss_mpping})\n",
    "\n",
    "    # -------------------- ????????????????????????????????????????? --------------------\n",
    "    # simply do : nom = list(data1[' Label'].unique())\n",
    "    nom = []\n",
    "    nom = nom + [data1[' Label'].unique()[0]]\n",
    "    for i in range(1, len(data1[' Label'].unique())):\n",
    "        nom = nom + [data1[' Label'].unique()[i]]\n",
    "    \n",
    "    nom.insert(0, nom.pop(nom.index('BENIGN')))\n",
    "\n",
    "    # Naming the two classes BENIGN {0} / Any Intrusion {1}\n",
    "    data1[' Label'].replace(nom[0], 0,inplace = True)\n",
    "    for i in range(1,len(data1[' Label'].unique())):\n",
    "        data1[' Label'].replace(nom[i], 1,inplace = True)\n",
    "    \n",
    "    ##################### LABELS FREQ #######################################\n",
    "    print()\n",
    "    print(\"labels freq after changing labels to binary\")\n",
    "    counts = list(data1[' Label'].value_counts().to_dict().items())\n",
    "    for j, x in enumerate(counts):\n",
    "        x = list(x)\n",
    "        x[1] = x[1] / len(data1)\n",
    "        counts[j] = x\n",
    "    print({f'{files[nb_files]}' : counts})\n",
    "    ##############################################################################\n",
    "\n",
    "    data1.rename(columns={\" Label\": \"label\"},inplace = True)\n",
    "    label1 = data1.label\n",
    "    data1.drop(columns=['label'],inplace = True)\n",
    "\n",
    "    # ******** At this step data1 contains only the data without label column\n",
    "    # ******** The label column is stored in the label variale \n",
    "\n",
    "    # split train and test\n",
    "    data1 =  pd.concat([data1, label1], axis=1) # ??????? WHY ?\n",
    "        \n",
    "\n",
    "    # Split\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(data1, label1, test_size=0.3, random_state=123, stratify= label1)\n",
    "\n",
    "    \n",
    "    # Create mini batches on the Train set\n",
    "    X1_train = shuffle(X1_train)\n",
    "    a = b = mean_macro_f1 = 0\n",
    "    for batch in range(1, nb_batch + 1):\n",
    "        print(f\"+++++++++++++++++ Batch {batch} ++++++++++++++++\")\n",
    "        a = b\n",
    "        b = int(len(X1_train) / nb_batch) * batch\n",
    "        if batch == nb_batch :\n",
    "            b = len(X1_train)\n",
    "        # The batch :\n",
    "        X1_train_batched = X1_train.iloc[a:b]\n",
    "        # y1_train_batched = y1_train.iloc[a:b]\n",
    "        y1_train_batched = X1_train_batched['label']        \n",
    "        \n",
    "        print(\"nb Train instances : \", len(X1_train_batched.values))\n",
    "\n",
    "        # for non numerical attributes (categorical data)\n",
    "        # Since we have a binary classification, the category values willl be replaced with the posterior probability (p(target = Ti | category = Cj))\n",
    "        # TargetEncoding is also called MeanEncoding, cuz it simply replace each value with (target_i_count_on_category_j) / (total_occurences_of_category_j)\n",
    "        encoder1 = ce.TargetEncoder(cols=[' Protocol',  'Fwd PSH Flags', ' Fwd URG Flags', ' Bwd PSH Flags', ' Bwd URG Flags'])\n",
    "        encoder1.fit(X1_train_batched, y1_train_batched)\n",
    "        X1_train_batched = encoder1.transform(X1_train_batched)\n",
    "\n",
    "        # scaler (normalization)\n",
    "        scaler1 = StandardScaler()\n",
    "\n",
    "        # Manipulate flow content (all columns except : label, Source IP & Destination IP)\n",
    "        cols_to_norm1 = list(set(list(X1_train_batched.iloc[:, :].columns )) - set(list(['label', ' Source IP', ' Destination IP', 'DetailedLabel'])) )\n",
    "        X1_train_batched[cols_to_norm1] = scaler1.fit_transform(X1_train_batched[cols_to_norm1])\n",
    "        \n",
    "        print(\"cols_to_norm1 : \", cols_to_norm1)\n",
    "        print(\"cols_to_norm1[0] : \", cols_to_norm1[0])\n",
    "        print(\"X1_train_batched[cols_to_norm1[0]] : \", X1_train_batched[cols_to_norm1[0]])\n",
    "\n",
    "        ## Create the h attribute that will contain the content of our flows\n",
    "        X1_train_batched['h'] = X1_train_batched[ cols_to_norm1 ].values.tolist()\n",
    "        print(\"X1_train_batched['h'] : \", X1_train_batched['h'])\n",
    "        # size of the list containig the content of our flows\n",
    "        sizeh = len(cols_to_norm1)\n",
    "\n",
    "\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # Before training the data :\n",
    "        # We need to delete all the attributes (cols_to_norm1) to have the {Source IP, Destination IP, label, h} representation\n",
    "        X1_train_batched.drop(columns = cols_to_norm1, inplace = True)\n",
    "        \n",
    "        # Edge index\n",
    "        X1_train_batched['Edge_indx'] = list(range(len(X1_train_batched.values)))\n",
    "\n",
    "        # Then we need to Swap {label, h} Columns to have the {Source IP, Destination IP, h, label} representation\n",
    "        columns_titles = [' Source IP', ' Destination IP', 'h', 'label', 'Edge_indx', 'DetailedLabel']\n",
    "        X1_train_batched = X1_train_batched.reindex(columns=columns_titles)\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # ------------------------------------------- Creating the Graph Representation -------------------------------------------------------------\n",
    "        # Create our Multigraph\n",
    "        G1 = nx.from_pandas_edgelist(X1_train_batched, \" Source IP\", \" Destination IP\", ['h','label', 'Edge_indx', 'DetailedLabel'], create_using=nx.MultiDiGraph())\n",
    "        print(\"initial nx multigraph G1 : \", G1)\n",
    "\n",
    "        G1 = from_networkx(G1, edge_attrs=['h','label', 'Edge_indx', 'DetailedLabel'] )\n",
    "        print(\"G1.edata['h'] after converting it to a dgl graph : \", len(G1.edata['h']))\n",
    "\n",
    "        # nodes data // G1.edata['h'].shape[1] : sizeh = number of attributes in a flow\n",
    "        G1.ndata['h'] = th.ones(G1.num_nodes(), G1.edata['h'].shape[1])\n",
    "        # edges data // we create a tensor bool array that will represent the train mask\n",
    "        G1.edata['train_mask'] = th.ones(len(G1.edata['h']), dtype=th.bool)\n",
    "\n",
    "        # Reshape both tensor lists to a single value in each element for both axis\n",
    "        G1.ndata['h'] = th.reshape(G1.ndata['h'], (G1.ndata['h'].shape[0], 1, G1.ndata['h'].shape[1]))\n",
    "        G1.edata['h'] = th.reshape(G1.edata['h'], (G1.edata['h'].shape[0], 1, G1.edata['h'].shape[1]))\n",
    "        print(\"G1.edata['h'] after reshape : \", len(G1.edata['h']))\n",
    "        # ------------------------------------------- --------------------------------- -------------------------------------------------------------\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # Ablation *************************************************************************\n",
    "        X1_train_ab = copy.deepcopy(X1_train_batched)\n",
    "\n",
    "        # print(\"data IP Addr before changing them : \")\n",
    "        # print(X1_train_ab[[' Source IP', ' Destination IP']])\n",
    "\n",
    "        X1_train_ab = X1_train_ab.drop(' Source IP', axis=1)\n",
    "        X1_train_ab = X1_train_ab.drop(' Destination IP', axis=1)\n",
    "        \n",
    "        X1_train_ab[' Source IP'] = list(range(len(X1_train_ab.values)))\n",
    "        X1_train_ab[' Destination IP'] = list(range(len(X1_train_ab.values), 2 * len(X1_train_ab.values)))\n",
    "\n",
    "        print()\n",
    "        # print(\"data IP Addr after changing them : \")\n",
    "        # print(X1_train_ab[[' Source IP', ' Destination IP']])\n",
    "        \n",
    "        # ------------------------------------------- Creating the Graph Representation -------------------------------------------------------------\n",
    "        # Create our Ablation Multigraph\n",
    "        G1_ab = nx.from_pandas_edgelist(X1_train_ab, \" Source IP\", \" Destination IP\", ['h','label', 'Edge_indx', 'DetailedLabel'], create_using=nx.MultiDiGraph())\n",
    "        print(\"initial nx multigraph G1_ab : \", G1_ab)\n",
    "\n",
    "        G1_ab = from_networkx(G1_ab, edge_attrs=['h','label', 'Edge_indx', 'DetailedLabel'] )\n",
    "        print(\"G1_ab.edata['h'] after converting it to a dgl graph : \", len(G1_ab.edata['h']))\n",
    "\n",
    "        # nodes data // G1_ab.edata['h'].shape[1] : sizeh = number of attributes in a flow\n",
    "        G1_ab.ndata['h'] = th.ones(G1_ab.num_nodes(), G1_ab.edata['h'].shape[1])\n",
    "        # edges data // we create a tensor bool array that will represent the train mask\n",
    "        G1_ab.edata['train_mask'] = th.ones(len(G1_ab.edata['h']), dtype=th.bool)\n",
    "\n",
    "        # Reshape both tensor lists to a single value in each element for both axis\n",
    "        G1_ab.ndata['h'] = th.reshape(G1_ab.ndata['h'], (G1_ab.ndata['h'].shape[0], 1, G1_ab.ndata['h'].shape[1]))\n",
    "        G1_ab.edata['h'] = th.reshape(G1_ab.edata['h'], (G1_ab.edata['h'].shape[0], 1, G1_ab.edata['h'].shape[1]))\n",
    "        print(\"G1_ab.edata['h'] after reshape : \", len(G1_ab.edata['h']))\n",
    "        # ------------------------------------------- --------------------------------- -------------------------------------------------------------\n",
    "        \n",
    "        # ***********************************************************************************\n",
    "        \n",
    "        \n",
    "        # ------------------------------------------- Model -----------------------------------------------------------------------------------------\n",
    "        ## use of model\n",
    "        from sklearn.utils import class_weight\n",
    "        class_weights1 = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                        classes = np.unique(G1.edata['label'].cpu().numpy()),\n",
    "                                                        y = G1.edata['label'].cpu().numpy())\n",
    "        class_weights1 = th.FloatTensor(class_weights1).cuda()\n",
    "        criterion1 = nn.CrossEntropyLoss(weight = class_weights1)\n",
    "        G1 = G1.to('cuda:0')\n",
    "\n",
    "        node_features1 = G1.ndata['h']\n",
    "        edge_features1 = G1.edata['h']\n",
    "\n",
    "        edge_label1 = G1.edata['label']\n",
    "        train_mask1 = G1.edata['train_mask']\n",
    "\n",
    "\n",
    "        # to print\n",
    "        pr = True\n",
    "        # True if you want to print the embedding vectors\n",
    "        # the name of the file where the vectors are printed\n",
    "        filename = './models/M1_weights.txt'\n",
    "        \n",
    "        print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "        for epoch in range(1, 1000):\n",
    "            pred = model1(G1, node_features1, edge_features1).cuda()\n",
    "            loss = criterion1(pred[train_mask1], edge_label1[train_mask1])\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Training acc:', compute_accuracy(pred[train_mask1], edge_label1[train_mask1]), loss)\n",
    "\n",
    "        pred1 = model1(G1, node_features1, edge_features1).cuda()\n",
    "        pred1 = pred1.argmax(1)\n",
    "        pred1 = th.Tensor.cpu(pred1).detach().numpy()\n",
    "        edge_label1 = th.Tensor.cpu(edge_label1).detach().numpy()\n",
    "\n",
    "        print('Train metrics :')\n",
    "        print(\"Accuracy : \", sklearn.metrics.accuracy_score(edge_label1, pred1))\n",
    "        print(\"Precision : \", sklearn.metrics.precision_score(edge_label1, pred1, labels = [0,1]))\n",
    "        print(\"Recall : \", sklearn.metrics.recall_score(edge_label1, pred1, labels = [0,1]))\n",
    "        print(\"f1_score : \", sklearn.metrics.f1_score(edge_label1, pred1, labels=[0,1]))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # ------------------------------------------- AB Model -----------------------------------------------------------------------------------------\n",
    "        ## use of model\n",
    "        from sklearn.utils import class_weight\n",
    "        class_weights1_ab = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                        classes = np.unique(G1_ab.edata['label'].cpu().numpy()),\n",
    "                                                        y = G1_ab.edata['label'].cpu().numpy())\n",
    "        class_weights1_ab = th.FloatTensor(class_weights1_ab).cuda()\n",
    "        criterion1_ab = nn.CrossEntropyLoss(weight = class_weights1_ab)\n",
    "        G1_ab = G1_ab.to('cuda:0')\n",
    "\n",
    "        node_features1_ab = G1_ab.ndata['h']\n",
    "        edge_features1_ab = G1_ab.edata['h']\n",
    "\n",
    "        edge_label1_ab = G1_ab.edata['label']\n",
    "        train_mask1_ab = G1_ab.edata['train_mask']\n",
    "        \n",
    "        print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "        \n",
    "        for epoch in range(1, 1000):\n",
    "            pred_ab = model1_ab(G1_ab, node_features1_ab, edge_features1_ab).cuda()\n",
    "            loss_ab = criterion1_ab(pred_ab[train_mask1], edge_label1_ab[train_mask1])\n",
    "            opt_ab.zero_grad()\n",
    "            loss_ab.backward()\n",
    "            opt_ab.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Training acc:', compute_accuracy(pred_ab[train_mask1], edge_label1_ab[train_mask1]), loss_ab)\n",
    "\n",
    "        pred1_ab = model1_ab(G1_ab, node_features1_ab, edge_features1_ab).cuda()\n",
    "        pred1_ab = pred1_ab.argmax(1)\n",
    "        pred1_ab = th.Tensor.cpu(pred1_ab).detach().numpy()\n",
    "        edge_label1_ab = th.Tensor.cpu(edge_label1_ab).detach().numpy()\n",
    "\n",
    "        print('Train metrics :')\n",
    "        print(\"Accuracy : \", sklearn.metrics.accuracy_score(edge_label1_ab, pred1_ab))\n",
    "        print(\"Precision : \", sklearn.metrics.precision_score(edge_label1_ab, pred1_ab, labels = [0,1]))\n",
    "        print(\"Recall : \", sklearn.metrics.recall_score(edge_label1_ab, pred1_ab, labels = [0,1]))\n",
    "        print(\"f1_score : \", sklearn.metrics.f1_score(edge_label1_ab, pred1_ab, labels=[0,1]))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------ Test ---------------------------------------------------------------------\n",
    "    print(\"++++++++++++++++++++++++++++ Test ++++++++++++++++++++++++++++++++\")\n",
    "    print(\"nb Test instances : \", len(X1_test.values))\n",
    "    X1_test = encoder1.transform(X1_test)\n",
    "    X1_test[cols_to_norm1] = scaler1.transform(X1_test[cols_to_norm1])\n",
    "\n",
    "    # Save X1_test for XAI\n",
    "    X1_test.to_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/input/Dataset/XAI/X_test{nb_files}.csv', sep=',', index = False)\n",
    "\n",
    "    X1_test['h'] = X1_test[ cols_to_norm1 ].values.tolist()\n",
    "\n",
    "    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # Before training the data :\n",
    "    # We need to delete all the attributes (cols_to_norm1) to have the {Source IP, Destination IP, label, h} representation\n",
    "    X1_test.drop(columns = cols_to_norm1, inplace = True)\n",
    "    \n",
    "    # Edge index\n",
    "    X1_test['Edge_indx'] = list(range(len(X1_test.values)))\n",
    "\n",
    "    # Then we need to Swap {label, h} Columns to have the {Source IP, Destination IP, h, label} representation\n",
    "    columns_titles = [' Source IP', ' Destination IP', 'h', 'label', 'Edge_indx', 'DetailedLabel']\n",
    "    X1_test = X1_test.reindex(columns=columns_titles)\n",
    "    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "    # Graph Construction\n",
    "    G1_test = nx.from_pandas_edgelist(X1_test, \" Source IP\", \" Destination IP\", ['h','label', 'Edge_indx', 'DetailedLabel'],create_using=nx.MultiDiGraph())\n",
    "    # G1_test = G1_test.to_directed()\n",
    "    G1_test = from_networkx(G1_test,edge_attrs=['h','label', 'Edge_indx', 'DetailedLabel'] )\n",
    "    # actual1 = G1_test.edata.pop('label')\n",
    "    actual1 = G1_test.edata['label']\n",
    "    G1_test.ndata['feature'] = th.ones(G1_test.num_nodes(), G1.ndata['h'].shape[2])\n",
    "    G1_test.ndata['feature'] = th.reshape(G1_test.ndata['feature'], (G1_test.ndata['feature'].shape[0], 1, G1_test.ndata['feature'].shape[1]))\n",
    "    G1_test.edata['h'] = th.reshape(G1_test.edata['h'], (G1_test.edata['h'].shape[0], 1, G1_test.edata['h'].shape[1]))\n",
    "    G1_test = G1_test.to('cuda:0')\n",
    "    node_features_test1 = G1_test.ndata['feature']\n",
    "    edge_features_test1 = G1_test.edata['h']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Ablation *************************************************************************\n",
    "    X1_test_ab = copy.deepcopy(X1_test)\n",
    "\n",
    "    # print(\"data IP Addr before changing them : \")\n",
    "    # print(X1_test_ab[[' Source IP', ' Destination IP']])\n",
    "\n",
    "    X1_test_ab = X1_test_ab.drop(' Source IP', axis=1)\n",
    "    X1_test_ab = X1_test_ab.drop(' Destination IP', axis=1)\n",
    "\n",
    "    X1_test_ab[' Source IP'] = list(range(len(X1_test_ab.values)))\n",
    "    X1_test_ab[' Destination IP'] = list(range(len(X1_test_ab.values), 2 * len(X1_test_ab.values)))\n",
    "\n",
    "    print()\n",
    "    # print(\"data IP Addr after changing them : \")\n",
    "    # print(X1_test_ab[[' Source IP', ' Destination IP']])\n",
    "    \n",
    "    # Graph Construction\n",
    "    G1_test_ab = nx.from_pandas_edgelist(X1_test_ab, \" Source IP\", \" Destination IP\", ['h','label', 'Edge_indx', 'DetailedLabel'],create_using=nx.MultiDiGraph())\n",
    "    G1_test_ab = from_networkx(G1_test_ab, edge_attrs=['h','label', 'Edge_indx', 'DetailedLabel'] )\n",
    "    actual1_ab = G1_test_ab.edata['label']\n",
    "    G1_test_ab.ndata['feature'] = th.ones(G1_test_ab.num_nodes(), G1_ab.ndata['h'].shape[2])\n",
    "    G1_test_ab.ndata['feature'] = th.reshape(G1_test_ab.ndata['feature'], (G1_test_ab.ndata['feature'].shape[0], 1, G1_test_ab.ndata['feature'].shape[1]))\n",
    "    G1_test_ab.edata['h'] = th.reshape(G1_test_ab.edata['h'], (G1_test_ab.edata['h'].shape[0], 1, G1_test_ab.edata['h'].shape[1]))\n",
    "    G1_test_ab = G1_test_ab.to('cuda:0')\n",
    "    node_features_test1_ab = G1_test_ab.ndata['feature']\n",
    "    edge_features_test1_ab = G1_test_ab.edata['h']\n",
    "    \n",
    "    # ***********************************************************************************\n",
    "\n",
    "    print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    print(\"nb instances : \", len(X1_test.values))\n",
    "\n",
    "    test_pred1 = model1(G1_test, node_features_test1, edge_features_test1).cuda()\n",
    "    test_pred1 = test_pred1.argmax(1)\n",
    "    test_pred1 = th.Tensor.cpu(test_pred1).detach().numpy()\n",
    "\n",
    "    print('Metrics : ')\n",
    "    print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1, test_pred1))\n",
    "    print(\"Precision : \", sklearn.metrics.precision_score(actual1, test_pred1, labels = [0,1]))\n",
    "    print(\"Recall : \", sklearn.metrics.recall_score(actual1, test_pred1, labels = [0,1]))\n",
    "    print(\"f1_score : \", sklearn.metrics.f1_score(actual1, test_pred1, labels = [0,1]))\n",
    "    \n",
    "    \n",
    "    print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "    print(\"nb instances : \", len(X1_test_ab.values))\n",
    "\n",
    "    test_pred1_ab = model1_ab(G1_test_ab, node_features_test1_ab, edge_features_test1_ab).cuda()\n",
    "    test_pred1_ab = test_pred1_ab.argmax(1)\n",
    "    test_pred1_ab = th.Tensor.cpu(test_pred1_ab).detach().numpy()\n",
    "\n",
    "    print('Metrics : ')\n",
    "    print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1_ab, test_pred1_ab))\n",
    "    print(\"Precision : \", sklearn.metrics.precision_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "    print(\"Recall : \", sklearn.metrics.recall_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "    print(\"f1_score : \", sklearn.metrics.f1_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-stomach",
   "metadata": {},
   "source": [
    "### ACC + F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closed-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9910032596885187\n",
      "Precision :  0.968351303438054\n",
      "Recall :  0.9954291518537328\n",
      "f1_score :  0.9817035443858461\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "nb instances :  138050\n",
      "Metrics : \n",
      "Accuracy :  0.9836001448750453\n",
      "Precision :  0.9458301191394531\n",
      "Recall :  0.9890060645893706\n",
      "f1_score :  0.9669363554049712\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "print(\"nb instances : \", len(X1_test.values))\n",
    "\n",
    "test_pred1 = model1(G1_test, node_features_test1, edge_features_test1).cuda()\n",
    "test_pred1 = test_pred1.argmax(1)\n",
    "test_pred1 = th.Tensor.cpu(test_pred1).detach().numpy()\n",
    "\n",
    "print('Metrics : ')\n",
    "print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1, test_pred1))\n",
    "print(\"Precision : \", sklearn.metrics.precision_score(actual1, test_pred1, labels = [0,1]))\n",
    "print(\"Recall : \", sklearn.metrics.recall_score(actual1, test_pred1, labels = [0,1]))\n",
    "print(\"f1_score : \", sklearn.metrics.f1_score(actual1, test_pred1, labels = [0,1]))\n",
    "\n",
    "\n",
    "print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "print(\"nb instances : \", len(X1_test_ab.values))\n",
    "\n",
    "test_pred1_ab = model1_ab(G1_test_ab, node_features_test1_ab, edge_features_test1_ab).cuda()\n",
    "test_pred1_ab = test_pred1_ab.argmax(1)\n",
    "test_pred1_ab = th.Tensor.cpu(test_pred1_ab).detach().numpy()\n",
    "\n",
    "print('Metrics : ')\n",
    "print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1_ab, test_pred1_ab))\n",
    "print(\"Precision : \", sklearn.metrics.precision_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "print(\"Recall : \", sklearn.metrics.recall_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "print(\"f1_score : \", sklearn.metrics.f1_score(actual1_ab, test_pred1_ab, labels = [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-rates",
   "metadata": {},
   "source": [
    "### Save X_Test + Models + Graphs + Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capital-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test.to_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Pandas_X_Test_DetailedLabel.csv', sep=',', index = False)\n",
    "\n",
    "# Models\n",
    "th.save(model1.state_dict(), '/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_GNN_DetailedLabel.pt')\n",
    "th.save(model1_ab.state_dict(), '/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_GNN_ab_DetailedLabel.pt')\n",
    "\n",
    "# Graphs\n",
    "from dgl.data.utils import save_graphs\n",
    "save_graphs(\"/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_G1_test_DetailedLabel.bin\", [G1_test])\n",
    "save_graphs(\"/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_G1_test_ab_DetailedLabel.bin\", [G1_test_ab])\n",
    "\n",
    "np.savetxt('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_test_pred1_DetailedLabel.txt', test_pred1, fmt='%d')\n",
    "np.savetxt('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_test_pred1_ab_DetailedLabel.txt', test_pred1_ab, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-sequence",
   "metadata": {},
   "source": [
    "### Load graphs and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affiliated-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 0, 0, 0])\n",
      "tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "(array([     1,      9,     14, ..., 138035, 138036, 138040]),)\n",
      "[1 1 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 1 0]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ True False  True ...  True False  True]\n",
      "(array([     1,      9,     14, ..., 138036, 138040, 138048]),)\n",
      "Graph(num_nodes=104640, num_edges=138050,\n",
      "      ndata_schemes={'feature': Scheme(shape=(1, 76), dtype=torch.float32)}\n",
      "      edata_schemes={'DetailedLabel': Scheme(shape=(), dtype=torch.int64), 'Edge_indx': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1, 76), dtype=torch.float32)})\n",
      "Graph(num_nodes=276100, num_edges=138050,\n",
      "      ndata_schemes={'feature': Scheme(shape=(1, 76), dtype=torch.float32)}\n",
      "      edata_schemes={'DetailedLabel': Scheme(shape=(), dtype=torch.int64), 'Edge_indx': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1, 76), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "# loading Graphs and Predictions\n",
    "from dgl.data.utils import load_graphs\n",
    "import numpy as np\n",
    "\n",
    "Test_Graph = load_graphs(\"/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_G1_test_DetailedLabel.bin\")\n",
    "Test_Graph = Test_Graph[0][0]\n",
    "Test_Graph_ab = load_graphs(\"/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_G1_test_ab_DetailedLabel.bin\")\n",
    "Test_Graph_ab = Test_Graph_ab[0][0]\n",
    "\n",
    "Test_pred_Graph = np.loadtxt('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_test_pred1_DetailedLabel.txt', dtype=int)\n",
    "Test_pred_Graph_ab = np.loadtxt('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_test_pred1_ab_DetailedLabel.txt', dtype=int)\n",
    "\n",
    "\n",
    "actual1 = Test_Graph.edata['label']\n",
    "actual1_ab = Test_Graph_ab.edata['label']\n",
    "\n",
    "\n",
    "# Test the loading\n",
    "print(actual1)\n",
    "print(actual1_ab)\n",
    "aa = actual1 == actual1_ab\n",
    "aa = aa.numpy()\n",
    "print(np.where(aa == False))\n",
    "\n",
    "print(Test_pred_Graph)\n",
    "print(Test_pred_Graph_ab)\n",
    "aa = Test_pred_Graph == Test_pred_Graph_ab\n",
    "\n",
    "print(type(Test_pred_Graph))\n",
    "print(type(Test_pred_Graph_ab))\n",
    "print(type(aa))\n",
    "\n",
    "print(aa)\n",
    "print(np.where(aa == False))\n",
    "\n",
    "print(Test_Graph)\n",
    "print(Test_Graph_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-reducing",
   "metadata": {},
   "source": [
    "### Models testing on the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "curious-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\n",
      "Metrics : \n",
      "Accuracy :  0.9907642158638175\n",
      "Precision :  0.9673149492017417\n",
      "Recall :  0.9955486511516745\n",
      "f1_score :  0.9812287443134137\n",
      "\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\n",
      "Metrics : \n",
      "Accuracy :  0.9833973198116625\n",
      "Precision :  0.9463483065647457\n",
      "Recall :  0.9875123233651002\n",
      "f1_score :  0.9664922078301804\n"
     ]
    }
   ],
   "source": [
    "model1_test = Model(76, size_embedding, 76, F.relu, 0.2).cuda()\n",
    "model1_test.load_state_dict(th.load('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_GNN_DetailedLabel.pt'))\n",
    "model1_test.eval()\n",
    "\n",
    "model1_test_ab = Model(76, size_embedding, 76, F.relu, 0.2).cuda()\n",
    "model1_test_ab.load_state_dict(th.load('/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Pandas_GNN_ab_DetailedLabel.pt'))\n",
    "model1_test_ab.eval()\n",
    "\n",
    "\n",
    "print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ NORMAL \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "Test_Graph1 = Test_Graph.to('cuda:0')\n",
    "node_features_test1 = Test_Graph1.ndata['feature']\n",
    "edge_features_test1 = Test_Graph1.edata['h']\n",
    "\n",
    "test_pred1 = model1_test(Test_Graph1, node_features_test1, edge_features_test1).cuda()\n",
    "test_pred1 = test_pred1.argmax(1)\n",
    "test_pred1 = th.Tensor.cpu(test_pred1).detach().numpy()\n",
    "\n",
    "print('Metrics : ')\n",
    "print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1, test_pred1))\n",
    "print(\"Precision : \", sklearn.metrics.precision_score(actual1, test_pred1, labels = [0,1]))\n",
    "print(\"Recall : \", sklearn.metrics.recall_score(actual1, test_pred1, labels = [0,1]))\n",
    "print(\"f1_score : \", sklearn.metrics.f1_score(actual1, test_pred1, labels = [0,1]))\n",
    "\n",
    "\n",
    "print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ABLATION \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "Test_Graph_ab1 = Test_Graph_ab.to('cuda:0')\n",
    "node_features_test1_ab = Test_Graph_ab1.ndata['feature']\n",
    "edge_features_test1_ab = Test_Graph_ab1.edata['h']\n",
    "\n",
    "test_pred1_ab = model1_test_ab(Test_Graph_ab1, node_features_test1_ab, edge_features_test1_ab).cuda()\n",
    "test_pred1_ab = test_pred1_ab.argmax(1)\n",
    "test_pred1_ab = th.Tensor.cpu(test_pred1_ab).detach().numpy()\n",
    "\n",
    "print('Metrics : ')\n",
    "print(\"Accuracy : \", sklearn.metrics.accuracy_score(actual1_ab, test_pred1_ab))\n",
    "print(\"Precision : \", sklearn.metrics.precision_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "print(\"Recall : \", sklearn.metrics.recall_score(actual1_ab, test_pred1_ab, labels = [0,1]))\n",
    "print(\"f1_score : \", sklearn.metrics.f1_score(actual1_ab, test_pred1_ab, labels = [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-stranger",
   "metadata": {},
   "source": [
    "### Extract the 3% of difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enormous-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,  71207,     22,  ..., 138044, 138045, 138046])\n",
      "tensor([     0,      1,      2,  ..., 138047, 138048, 138049])\n"
     ]
    }
   ],
   "source": [
    "print(Test_Graph.edata['Edge_indx'])\n",
    "print(Test_Graph_ab.edata['Edge_indx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "respiratory-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3288   3495   3825 ... 137915 137984 137995]\n",
      "[   107    165    253 ... 138011 138038 138048]\n"
     ]
    }
   ],
   "source": [
    "actual1_np = actual1.numpy()\n",
    "aa = actual1_np == Test_pred_Graph\n",
    "wrong_preds = np.where(aa == False)[0]\n",
    "print(wrong_preds)\n",
    "\n",
    "actual1_ab_np = actual1_ab.numpy()\n",
    "bb = actual1_ab_np == Test_pred_Graph_ab\n",
    "wrong_preds_ab = np.where(bb == False)[0]\n",
    "print(wrong_preds_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "downtown-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 69962,     76,  87306,  ..., 137736, 137871, 137893])\n",
      "tensor([   107,    165,    253,  ..., 138011, 138038, 138048])\n",
      "2867\n",
      "{65536, 8194, 122884, 49158, 81936, 49170, 49171, 49174, 65560, 98334, 73758, 24609, 98343, 73768, 90152, 131111, 98349, 81968, 73786, 65595, 106556, 98369, 57412, 16453, 8262, 8263, 41030, 81990, 90181, 16459, 49233, 65620, 90201, 41056, 57440, 90209, 32868, 24678, 107, 57451, 41070, 24689, 73842, 106623, 98432, 24705, 106626, 57471, 123014, 41100, 8334, 98456, 106649, 8346, 24736, 114850, 165, 98469, 106662, 98477, 123055, 41138, 131250, 114870, 16569, 106688, 16580, 49348, 65734, 57540, 114891, 65742, 24787, 131287, 49376, 24804, 90341, 106724, 41191, 106725, 106726, 106739, 82166, 41207, 123131, 253, 57597, 16641, 33025, 33027, 123140, 8453, 49415, 98567, 16649, 8459, 123156, 57625, 49434, 8475, 33056, 33063, 82218, 24883, 65843, 8501, 16700, 106816, 57665, 106824, 41289, 41295, 8529, 339, 115030, 41310, 131432, 57707, 82285, 123246, 65904, 131443, 49524, 123252, 131447, 49529, 98691, 396, 8588, 98705, 123282, 33175, 115095, 123289, 98715, 74157, 25006, 16816, 41393, 33202, 131505, 98750, 106946, 131523, 41412, 16840, 82376, 458, 98763, 57809, 33235, 25045, 106966, 98778, 8667, 16859, 131549, 115170, 486, 490, 131564, 8691, 131575, 33276, 8705, 16897, 131587, 8709, 519, 115210, 49676, 8718, 49679, 98832, 74258, 25114, 49693, 66080, 57891, 66083, 98853, 33318, 554, 82479, 82483, 131637, 567, 82488, 25146, 49724, 82492, 107068, 8767, 16962, 16971, 57932, 107087, 90706, 16984, 41561, 602, 57948, 66140, 8810, 107115, 74348, 115306, 107118, 66159, 25201, 8818, 49779, 17013, 630, 90741, 49785, 17022, 107134, 115327, 41601, 642, 49795, 33412, 8837, 98945, 651, 17045, 82584, 66203, 74403, 131747, 33446, 8874, 33451, 17068, 8877, 33454, 74410, 25264, 107184, 131758, 692, 33462, 107190, 49853, 58046, 33471, 115390, 107204, 99014, 82631, 49867, 49871, 58064, 49873, 41682, 66256, 8917, 41688, 41692, 123612, 17118, 115425, 17122, 8931, 8932, 24570, 33510, 131819, 115436, 49905, 66310, 41735, 82694, 123654, 123656, 33549, 782, 17167, 82707, 99092, 123667, 58134, 25367, 792, 25368, 99102, 803, 8995, 808, 66348, 25395, 123700, 25397, 74549, 107319, 49975, 82743, 9017, 25401, 49979, 17213, 107322, 831, 131900, 115522, 99146, 58192, 123728, 852, 33621, 58196, 74583, 131925, 33625, 25434, 17243, 41820, 50010, 866, 107362, 107375, 82801, 131954, 17267, 17271, 9081, 131969, 123779, 131972, 91020, 17293, 99214, 74642, 33683, 123797, 115607, 115614, 91039, 74665, 33706, 25515, 74668, 33709, 99247, 9136, 123823, 132016, 82868, 949, 115639, 41915, 33725, 66495, 960, 50112, 50119, 17352, 66503, 33738, 66504, 82889, 41933, 115664, 66515, 25558, 25559, 50135, 50136, 123862, 115675, 41949, 993, 41953, 82913, 58347, 66540, 33773, 25584, 66544, 66552, 50172, 33793, 74754, 41987, 74756, 123918, 1039, 66578, 42004, 33821, 107552, 66596, 123941, 42022, 91183, 82993, 66611, 132147, 17463, 9272, 9273, 58426, 42051, 50243, 99398, 123975, 66635, 132174, 115791, 33872, 132177, 74840, 33887, 33891, 115815, 9320, 50283, 91245, 99437, 33904, 9330, 107635, 132216, 91257, 58490, 91265, 115843, 42118, 83078, 115855, 58516, 25751, 9368, 33946, 115870, 132266, 107692, 25778, 9408, 66754, 107715, 99533, 83155, 124121, 25823, 50401, 66785, 34019, 17636, 9446, 66790, 25832, 132339, 50421, 42237, 83197, 9475, 107782, 50441, 17678, 115983, 115984, 83220, 50454, 99611, 83231, 75044, 34094, 91439, 1331, 9525, 83254, 75064, 25914, 34108, 9537, 42308, 50502, 34126, 50511, 83279, 75089, 124242, 58714, 34140, 66908, 66909, 99678, 42338, 17765, 17767, 42344, 116071, 124264, 132460, 50544, 75121, 75127, 132475, 34175, 42370, 83336, 17804, 91533, 116114, 124307, 75156, 99744, 58791, 34217, 99753, 42411, 107946, 42417, 99764, 42421, 107958, 42432, 132549, 132553, 50635, 26060, 116171, 1486, 116179, 17877, 107991, 9689, 1499, 75229, 67044, 124388, 67046, 26087, 9709, 132589, 50677, 67065, 91643, 132603, 91648, 67074, 17923, 58883, 99843, 83462, 108039, 75272, 83468, 83469, 108044, 124430, 42520, 42521, 75290, 75291, 91690, 91692, 9775, 42544, 91695, 108080, 26164, 26165, 50746, 42557, 67143, 124488, 34378, 34380, 58958, 58963, 34388, 42588, 42589, 108124, 91745, 132705, 50791, 58983, 83563, 108141, 34414, 34417, 108146, 124531, 58996, 18039, 18041, 116347, 116348, 75389, 67198, 18048, 83586, 132746, 67214, 116368, 83601, 116371, 1689, 99998, 18079, 18080, 50848, 91811, 42668, 116399, 91826, 50867, 18105, 91835, 108223, 100032, 9924, 67270, 116426, 1739, 9933, 108239, 18128, 50897, 1746, 108246, 18136, 59099, 1767, 91879, 42731, 75499, 83691, 75512, 18171, 75516, 100091, 124670, 75520, 132866, 67331, 108292, 1798, 26375, 83724, 100108, 59152, 59157, 42781, 91936, 132896, 34597, 10023, 108327, 75562, 50992, 75571, 18230, 91960, 34618, 100156, 18238, 132926, 132929, 51011, 91976, 132937, 91978, 10063, 75605, 83801, 91999, 92004, 124773, 18279, 132969, 132979, 1909, 26486, 18296, 67449, 124796, 51070, 51075, 10119, 67463, 133009, 116628, 75671, 42905, 34722, 67496, 51113, 1965, 124851, 83893, 92085, 42937, 18362, 100283, 34748, 133050, 34750, 51134, 92094, 34758, 116681, 116683, 51148, 34766, 1999, 75726, 92112, 133073, 59351, 133082, 18397, 51173, 92133, 59368, 83945, 10222, 18420, 116724, 133112, 18424, 10240, 2053, 18440, 18441, 51210, 75784, 83977, 26637, 100364, 59407, 59408, 2065, 92183, 116770, 18467, 84007, 59433, 116777, 2091, 116779, 124974, 2096, 108592, 10290, 59443, 10292, 100404, 10295, 133175, 10305, 92226, 116803, 67652, 75847, 116812, 59471, 84054, 2139, 75868, 34911, 59487, 26722, 116836, 92265, 116842, 51307, 59504, 133233, 92277, 116854, 108665, 75899, 133247, 2176, 67715, 51332, 100484, 108679, 133257, 75914, 116875, 18572, 43150, 26767, 43151, 67729, 84110, 116885, 116886, 75927, 75936, 67748, 51368, 116904, 133292, 26797, 51374, 108717, 2225, 26801, 34995, 100531, 34999, 133304, 51385, 116923, 75965, 18626, 26823, 92359, 125136, 108753, 108758, 2263, 133334, 92379, 125148, 35038, 43231, 116962, 76005, 84203, 84210, 10485, 84223, 125185, 100615, 59656, 59657, 125192, 10510, 18705, 92434, 125202, 51480, 108824, 43292, 43304, 76081, 125235, 92472, 26940, 18749, 35132, 108862, 133438, 43329, 117058, 133439, 84293, 10570, 133450, 10576, 125266, 18771, 76115, 76116, 92507, 108894, 18783, 2400, 100708, 92525, 117101, 108919, 76152, 2430, 27008, 27009, 10626, 125313, 2438, 84358, 92573, 59816, 18857, 125355, 10671, 59823, 27057, 117168, 51635, 68020, 68021, 92599, 43448, 76216, 76217, 117176, 108989, 117181, 51650, 125380, 35273, 100810, 27084, 125389, 92624, 117208, 10713, 2525, 109022, 18912, 51687, 59881, 43499, 2549, 125429, 133623, 92666, 109052, 27133, 59902, 100871, 76297, 27148, 76303, 10769, 59922, 117271, 18970, 68123, 59936, 18983, 125479, 59948, 117292, 125487, 133683, 92732, 133694, 51776, 27203, 59972, 92741, 109134, 133715, 100948, 125524, 117336, 100955, 2652, 51806, 109151, 109153, 10850, 27234, 84584, 117353, 19054, 2674, 27252, 27253, 2678, 92788, 125561, 10875, 92808, 27275, 19084, 35472, 117394, 10900, 10903, 51865, 109215, 133794, 19110, 51878, 60079, 92848, 101040, 27316, 51896, 60088, 43706, 117434, 125628, 133820, 92863, 125633, 51910, 125644, 109267, 117461, 35542, 92888, 68315, 60124, 19165, 19166, 68321, 117474, 27366, 27367, 2797, 117491, 43764, 60152, 84729, 19198, 43778, 11011, 2820, 117512, 84747, 68366, 84752, 27410, 76563, 117522, 133908, 51990, 27415, 133914, 43807, 133920, 68386, 43815, 117543, 125739, 27438, 84783, 92977, 84788, 92980, 101172, 43832, 117560, 43846, 93009, 43859, 43861, 11097, 84825, 84826, 84827, 93018, 93019, 101210, 60261, 60263, 52074, 35691, 2929, 52082, 43897, 101245, 27520, 11138, 60293, 101253, 125833, 93067, 101263, 109456, 43925, 11160, 60325, 11174, 93095, 117671, 60329, 125866, 35759, 19376, 11186, 19379, 52147, 101308, 43965, 68542, 27583, 68544, 76735, 11207, 35783, 125896, 134090, 93132, 68560, 27606, 3031, 35800, 52189, 125922, 60387, 44005, 3054, 68592, 109552, 44021, 52215, 93176, 93179, 44035, 3076, 134152, 117771, 19479, 109601, 134190, 60469, 3128, 27704, 76856, 35907, 76867, 76881, 93269, 134229, 3159, 134231, 85088, 134242, 3172, 19560, 117866, 3187, 35955, 76917, 109683, 27770, 44159, 101505, 44167, 11401, 44172, 85132, 35982, 11407, 44177, 117910, 68760, 52378, 52386, 11427, 126122, 93355, 68782, 93361, 27830, 93370, 52412, 101564, 11454, 101567, 134338, 93379, 27846, 52422, 101575, 11466, 19659, 3277, 52429, 27856, 68821, 11478, 27862, 126168, 126173, 93411, 93413, 134377, 44272, 60660, 77047, 118015, 68875, 93454, 3343, 27922, 109845, 118038, 68890, 85278, 19744, 36129, 93481, 134442, 36142, 19765, 126264, 93501, 52542, 60737, 27974, 68934, 68936, 68937, 93515, 27981, 109903, 126288, 109913, 109914, 44382, 52575, 28003, 68964, 60780, 52589, 28014, 11631, 85357, 52594, 126324, 93557, 77174, 109945, 11647, 44415, 101766, 60809, 36238, 93582, 77200, 19860, 69012, 60822, 36247, 77204, 85401, 134549, 3485, 134558, 101799, 28072, 44456, 28076, 11693, 77241, 85433, 60861, 44478, 11715, 3524, 19909, 69067, 134604, 77271, 28120, 28121, 69081, 11741, 69086, 134623, 134625, 77284, 134630, 101868, 3572, 60916, 118260, 118262, 134645, 52732, 36355, 36359, 110091, 134672, 69139, 11797, 60949, 110105, 36379, 118304, 134692, 93734, 52776, 60969, 44586, 110121, 20012, 36396, 69166, 126506, 60976, 134700, 110134, 93754, 77375, 118335, 11842, 69188, 11845, 110149, 44616, 3657, 28233, 110159, 77394, 101972, 11862, 61015, 69207, 69216, 77413, 61030, 44647, 44654, 77425, 36467, 69238, 77430, 134774, 44668, 110210, 77443, 11908, 85637, 126594, 85642, 118410, 126602, 3730, 77459, 52884, 61077, 102036, 61079, 52888, 110230, 134804, 134813, 20129, 102052, 36518, 20136, 36521, 77480, 77481, 93866, 52915, 126647, 52922, 102076, 102082, 36547, 77508, 20167, 11976, 69321, 93903, 110287, 102101, 69336, 36570, 77531, 77532, 28391, 102120, 134887, 93930, 44785, 134897, 93939, 118521, 134911, 12035, 93961, 61195, 3853, 36625, 102164, 118556, 53022, 118562, 102184, 36650, 110379, 126765, 85806, 85808, 85821, 110397, 20288, 12098, 77635, 3909, 85831, 28492, 134991, 126800, 126803, 36692, 94036, 28503, 94040, 110432, 94052, 85865, 110441, 135024, 53106, 85874, 135037, 135038, 44927, 85893, 110472, 28554, 53131, 94092, 94093, 135050, 12178, 20370, 85906, 118676, 20374, 102297, 94107, 69533, 3998, 12193, 53153, 126882, 126885, 61354, 135087, 36784, 77750, 94138, 94139, 12221, 118718, 126919, 85960, 45001, 77769, 28619, 20428, 69581, 110537, 110539, 85971, 77782, 20444, 126940, 135133, 4063, 53219, 85990, 86002, 77812, 36853, 69637, 45071, 135184, 110610, 4115, 4118, 36888, 45083, 53280, 94241, 28706, 53284, 61481, 77866, 77868, 69684, 4161, 110660, 135237, 102470, 86089, 127049, 36940, 110671, 28752, 61521, 135252, 135262, 102496, 86119, 36968, 28777, 53352, 110699, 45165, 77933, 118893, 45168, 135277, 127092, 12406, 45180, 61565, 45184, 36993, 135301, 61576, 127113, 37003, 37005, 127122, 86163, 20629, 45205, 102553, 135328, 118946, 53411, 118950, 102568, 28841, 86189, 94381, 4271, 69808, 127151, 69810, 102579, 127154, 53431, 20665, 127164, 20674, 127178, 37067, 86220, 110796, 135378, 127188, 37077, 86229, 37081, 12506, 135391, 12515, 69860, 53485, 20726, 127225, 135420, 102655, 119044, 135441, 78098, 28947, 110868, 94487, 45336, 4379, 28959, 127270, 45359, 20785, 61746, 94529, 37188, 53572, 86342, 110928, 29010, 37203, 119122, 53591, 94551, 4441, 61785, 61788, 37214, 29023, 45420, 86382, 53615, 37233, 110961, 37236, 110964, 127353, 86395, 119163, 53629, 29059, 53637, 61830, 45447, 86409, 4490, 4496, 4497, 135570, 53660, 94622, 29089, 37282, 12708, 29092, 94631, 102825, 86442, 61869, 45489, 86452, 29111, 61880, 102843, 4547, 70089, 20939, 53707, 86475, 37326, 70094, 135630, 94680, 12761, 78297, 86494, 86498, 70115, 94691, 135653, 12774, 135662, 53746, 70141, 94720, 20993, 37379, 61955, 53766, 111111, 53768, 102925, 70158, 119313, 94738, 102930, 86559, 21035, 61997, 94766, 127535, 70195, 45623, 102968, 111159, 111167, 127551, 102978, 111174, 45643, 78411, 37454, 78422, 21080, 135768, 70235, 12897, 127594, 119405, 21106, 45688, 127609, 62074, 103036, 70270, 70271, 21123, 70275, 53893, 45702, 111239, 127629, 86681, 21148, 70305, 119457, 21155, 135847, 53928, 53938, 111285, 4790, 37566, 12991, 94911, 127681, 103106, 21187, 4804, 53955, 94917, 119497, 53964, 94926, 111310, 111311, 135887, 103126, 13026, 78562, 94948, 62181, 127729, 135923, 94964, 86773, 127733, 127735, 4860, 29436, 13055, 21248, 94975, 29443, 78595, 135939, 29446, 21258, 70410, 86796, 13069, 21263, 135957, 13078, 37654, 45855, 78623, 127775, 13093, 45861, 37677, 78644, 78647, 95032, 62269, 95037, 4927, 45888, 135997, 103237, 86854, 78663, 78664, 4937, 62284, 45903, 136017, 54098, 119635, 111448, 70492, 136029, 86880, 136033, 103269, 13159, 78696, 4970, 54133, 70517, 111479, 29560, 127861, 4987, 127868, 29566, 54149, 45958, 13191, 37768, 119685, 21392, 86929, 45976, 95135, 111534, 111538, 78779, 119739, 70601, 136139, 119759, 5073, 5083, 111588, 78825, 95214, 54258, 78840, 78843, 54268, 5116, 21500, 21501, 46080, 54270, 128003, 128004, 78854, 37896, 37902, 87054, 46096, 87055, 103445, 5145, 5153, 46113, 103457, 46119, 62505, 46122, 136234, 136236, 111661, 95284, 54325, 78901, 95290, 21566, 54336, 29761, 54339, 136262, 111688, 54358, 128087, 103515, 103517, 111710, 29793, 37987, 29797, 87148, 111727, 5232, 103545, 38010, 78970, 128124, 54397, 87165, 29826, 46215, 128135, 21643, 13452, 111758, 13457, 62609, 111769, 136350, 5284, 136359, 79018, 29867, 21678, 38063, 70830, 54449, 70831, 54451, 95410, 103605, 29879, 87235, 111814, 87242, 87249, 21716, 70874, 120027, 87266, 111845, 38118, 79079, 38126, 38127, 5360, 46318, 136433, 29940, 38133, 87286, 13561, 95481, 5373, 87296, 87298, 111875, 103685, 5388, 13581, 120078, 87312, 46355, 46359, 95517, 38174, 13603, 111912, 29994, 95537, 21810, 70967, 30008, 79162, 120124, 62781, 128318, 95557, 5450, 87375, 95567, 136530, 70995, 30038, 70998, 13659, 54628, 71012, 79207, 120169, 111982, 13686, 46454, 87414, 103799, 120196, 136580, 71047, 120201, 103818, 5516, 13714, 38291, 38292, 128407, 13722, 30107, 62875, 95643, 5534, 54686, 13728, 95645, 79270, 103846, 62889, 112043, 87470, 62897, 120241, 21946, 5565, 95680, 120256, 112069, 21961, 87497, 103882, 136651, 103886, 13775, 30164, 79317, 38360, 87512, 30181, 112112, 103935, 38416, 22034, 62994, 136722, 120341, 112152, 112155, 103967, 112160, 54819, 30248, 46634, 38445, 71215, 103983, 112177, 22066, 13879, 87608, 95802, 136769, 71239, 128583, 22097, 104027, 54879, 63074, 5732, 22118, 38503, 120424, 128616, 63082, 136808, 63087, 30320, 87668, 112251, 38524, 104061, 95870, 128640, 71297, 63107, 22149, 46728, 54921, 104072, 87692, 79508, 63125, 71318, 54942, 79520, 13986, 5799, 104103, 30381, 120494, 5808, 14001, 22193, 112305, 38581, 22199, 120507, 79549, 128703, 136897, 54979, 54982, 63175, 46792, 63176, 22221, 46799, 87766, 63200, 30434, 120551, 87786, 30443, 87788, 55025, 38647, 112376, 120567, 38665, 63244, 22287, 5910, 112421, 5935, 120625, 5939, 46901, 120630, 14137, 63293, 22336, 71493, 71494, 46923, 79692, 55117, 120655, 128850, 22357, 30549, 120664, 5982, 22367, 22368, 46946, 5991, 55143, 55149, 96117, 22390, 87927, 22392, 112505, 46970, 6020, 38790, 87943, 137096, 6025, 137097, 128907, 14221, 46990, 104334, 14224, 87952, 120717, 46995, 137103, 71573, 6039, 46999, 87962, 14245, 96167, 120747, 30636, 87980, 128939, 137133, 22460, 79804, 87997, 6081, 55233, 55239, 137162, 30667, 47056, 128977, 47058, 22484, 55255, 55259, 128988, 137179, 47073, 38883, 38885, 71654, 137191, 96235, 22510, 6128, 63472, 112631, 14328, 129020, 6146, 71682, 88071, 71702, 104471, 6168, 112665, 120854, 55324, 88092, 14367, 88100, 79909, 137257, 22571, 88108, 14387, 104510, 6210, 71746, 137285, 14407, 112711, 38986, 129098, 79949, 129101, 96337, 104535, 6234, 30811, 71771, 55399, 129128, 112745, 30826, 30830, 129137, 30834, 120946, 112756, 129140, 129143, 63608, 63612, 55427, 47240, 47242, 104590, 120986, 39067, 6300, 112795, 104607, 71840, 47268, 6310, 96428, 129202, 96435, 14516, 137398, 112825, 30912, 112833, 71875, 6340, 55492, 104645, 22727, 112847, 121040, 47319, 129239, 14557, 96477, 14559, 80097, 96481, 137443, 112868, 14569, 6379, 104695, 30968, 63742, 6401, 6405, 80136, 14608, 47376, 80148, 80151, 96536, 129303, 121121, 88358, 47400, 63784, 39210, 129321, 63789, 55604, 47413, 112952, 47419, 47420, 39229, 71995, 22847, 63807, 104769, 55618, 39235, 47430, 129353, 63820, 55634, 129364, 6485, 63831, 47448, 47451, 63839, 104799, 6497, 112999, 129384, 113002, 47468, 14701, 14703, 104819, 129398, 47483, 80251, 113023, 14725, 88453, 55694, 39323, 137631, 31136, 88480, 113056, 63907, 121248, 113066, 80299, 88492, 96686, 121268, 121276, 31166, 22982, 47559, 113095, 72137, 39371, 6604, 63949, 63950, 113102, 121294, 104914, 63956, 96726, 6616, 14808, 137688, 80347, 23005, 80350, 129503, 137704, 137705, 31212, 113133, 129524, 88565, 63990, 63996, 23037, 64003, 80390, 129542, 23051, 96781, 129551, 14865, 47640, 137762, 14883, 23076, 14885, 137763, 55848, 121385, 88620, 31280, 96820, 14908, 14909, 64060, 105021, 47682, 105028, 129605, 6728, 6729, 88659, 55893, 137813, 47708, 55901, 14942, 105055, 6752, 31329, 55906, 31331, 72288, 72292, 47721, 72297, 39536, 64116, 72312, 6779, 23165, 121470, 137854, 14976, 113281, 96899, 129671, 31368, 121482, 6795, 121489, 31381, 129688, 88730, 39580, 80545, 64169, 55978, 113323, 6830, 72369, 96954, 96957, 96959, 121542, 47815, 31432, 15051, 39627, 96971, 88784, 137939, 39636, 64212, 31447, 6872, 31448, 137943, 72411, 137946, 31453, 15072, 72418, 6887, 129772, 97005, 23280, 47858, 31479, 31482, 47866, 121598, 97024, 39684, 97029, 105223, 56073, 47885, 121616, 47892, 56084, 88852, 47898, 138010, 138011, 47904, 39713, 47909, 64296, 72488, 88879, 47920, 47921, 72498, 113457, 105270, 138038, 138048, 80714, 64337, 47954, 56148, 97109, 88918, 15195, 7008, 80738, 15205, 7015, 31595, 56177, 72562, 105342, 23423, 105346, 48007, 97159, 129930, 56203, 64397, 121741, 64405, 31638, 80793, 15260, 56222, 64415, 129951, 80802, 105385, 15277, 89014, 89015, 113593, 121786, 15299, 15301, 80839, 7112, 31697, 48084, 105430, 105432, 113624, 72669, 72670, 7138, 15336, 72680, 113641, 97262, 39919, 7152, 72688, 89072, 23542, 23543, 23547, 97276, 113663, 56323, 15365, 7183, 105487, 121874, 80917, 39958, 31777, 113705, 121897, 15403, 23596, 64558, 15411, 105524, 64567, 64569, 80956, 105534, 23616, 130116, 121937, 23634, 7251, 31826, 64595, 113748, 72793, 121947, 113759, 7270, 113767, 130152, 56429, 64621, 72817, 113782, 113784, 48249, 81023, 23681, 121988, 89223, 7313, 56466, 64657, 7316, 130195, 130204, 130207, 23719, 40104, 81068, 130222, 64688, 97457, 23733, 89269, 31927, 97462, 64698, 113850, 7358, 31937, 105665, 105670, 89287, 113865, 72910, 48335, 15569, 89297, 31955, 130261, 72918, 81110, 31960, 81113, 130264, 48349, 122078, 7392, 23779, 31973, 113898, 64750, 15602, 48371, 113911, 23800, 105735, 7435, 23820, 48406, 122143, 48419, 105766, 15663, 73009, 32052, 105782, 15677, 48445, 97601, 56643, 105797, 122183, 15693, 32081, 7506, 114001, 48470, 7515, 15707, 56669, 7517, 23899, 48481, 81250, 97634, 64875, 130411, 81261, 97647, 130415, 64883, 23924, 89461, 114040, 23935, 32133, 32137, 48522, 114066, 122258, 23962, 40348, 130461, 15774, 114080, 23972, 32164, 89509, 56743, 114085, 32175, 23984, 40368, 81330, 105908, 89525, 23990, 130484, 48569, 40378, 64954, 81338, 122299, 64958, 89543, 15816, 7626, 56782, 81360, 73171, 89561, 89567, 32227, 48615, 15851, 7661, 97777, 24050, 89587, 114170, 24060, 40445, 40450, 105987, 114178, 105998, 130580, 130581, 65046, 40471, 73241, 89625, 89630, 81439, 130592, 130593, 106020, 24102, 32296, 106027, 32300, 106028, 65071, 97843, 114227, 15925, 73270, 65084, 7742, 106046, 130624, 48705, 15938, 56900, 89671, 114247, 89677, 114253, 32335, 32345, 24154, 40537, 56936, 24173, 130673, 89714, 24179, 15990, 32377, 130683, 56961, 24198, 89736, 7819, 32401, 65169, 81565, 81567, 16036, 73383, 48814, 65204, 24245, 65217, 106179, 16077, 24269, 57042, 89811, 89812, 32475, 122587, 57061, 122601, 40685, 114413, 81647, 130801, 106227, 24312, 106237, 89858, 73482, 65294, 7956, 81688, 65312, 81698, 130854, 98089, 89898, 40748, 73517, 98094, 81713, 24371, 106294, 81721, 106297, 57150, 130878, 8005, 16203, 89938, 8026, 81758, 57187, 57189, 114534, 65383, 73575, 89959, 114540, 49005, 65395, 8058, 40829, 24449, 122754, 130949, 73606, 122761, 81803, 49036, 8077, 32653, 24463, 8080, 98188, 24471, 106392, 57247, 32673, 73633, 122787, 98215, 130984, 24489, 40885, 49077, 90038, 24507, 90044, 106427, 106429, 24513, 73669, 98248, 16333, 73678, 49103, 98257, 8146, 32724, 57303, 114648, 114651, 16356, 16361, 81900, 40941, 49133, 90092, 122861, 90097, 114674, 49139, 122871, 73721, 131066, 57339, 49149}\n"
     ]
    }
   ],
   "source": [
    "wpred = Test_Graph.edata['Edge_indx'][wrong_preds]\n",
    "wpred_ab = Test_Graph_ab.edata['Edge_indx'][wrong_preds_ab]\n",
    "\n",
    "print(wpred)\n",
    "print(wpred_ab)\n",
    "\n",
    "edges_to_explain = set(wpred_ab.numpy()) - set(wpred.numpy())\n",
    "\n",
    "print(len(edges_to_explain))\n",
    "print(edges_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "passing-strap",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Edge_indx  label\n",
      "2866      98607      0\n",
      "1024      39625      0\n",
      "1023       8457      0\n",
      "1022     112820      0\n",
      "1021      66589      0\n",
      "...         ...    ...\n",
      "2582      10636      1\n",
      "2581      61213      1\n",
      "1748      27567      1\n",
      "2036      55686      1\n",
      "1521     106883      1\n",
      "\n",
      "[2867 rows x 2 columns]\n",
      "nb attacks : 308\n",
      "nb benign : 2559\n"
     ]
    }
   ],
   "source": [
    "indx_to_explain = []\n",
    "\n",
    "for x in edges_to_explain:\n",
    "    indx_to_explain.append((Test_Graph.edata['Edge_indx'] == x).nonzero(as_tuple=True)[0].item())\n",
    "\n",
    "# print(indx_to_explain)\n",
    "\n",
    "df_indx = pd.DataFrame(columns = ['Edge_indx', 'label'])\n",
    "\n",
    "for x in indx_to_explain:\n",
    "    df_indx.loc[-1] = [x, Test_Graph.edata['label'][x].item()]  # adding a row\n",
    "    df_indx.index = df_indx.index + 1  # shifting index\n",
    "\n",
    "    \n",
    "df_indx = df_indx.sort_values('label')\n",
    "print(df_indx)\n",
    "\n",
    "print('nb attacks :', len(df_indx.loc[df_indx['label'] == 1]))\n",
    "print('nb benign :', len(df_indx.loc[df_indx['label'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "liked-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edge_indx  label  in_out_degrees\n",
      "94       8457      0             120\n",
      "93       8477      0             120\n",
      "92       7491      0             155\n",
      "91       4970      0             110\n",
      "90       5031      0             127\n",
      "..        ...    ...             ...\n",
      "4        7893      1             180\n",
      "3        7887      1             180\n",
      "2        7892      1             180\n",
      "1        7855      1             180\n",
      "0        7890      1             180\n",
      "\n",
      "[95 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2_indx = pd.DataFrame(columns = ['Edge_indx', 'label', 'in_out_degrees'])\n",
    "\n",
    "for x in df_indx['label'].unique():\n",
    "    # select the edges having a neighborhood subgraph with 100 <= nb_edges =< 200\n",
    "    list1 = df_indx.loc[df_indx['label'] == x]['Edge_indx']\n",
    "    for y in list1:\n",
    "        source_node = th.Tensor.cpu(Test_Graph.edges()[0][int(y)]).detach().numpy()\n",
    "        in_out_degrees = Test_Graph.in_degrees(source_node) + Test_Graph.out_degrees(source_node)\n",
    "        \n",
    "        if (100 <= in_out_degrees.item() <= 200) :\n",
    "            df2_indx.loc[-1] = [int(y), x, in_out_degrees.item()]  # adding a row\n",
    "            df2_indx.index = df2_indx.index + 1  # shifting index\n",
    "\n",
    "print(df2_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "instructional-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(Test_Graph.edata['label'][4970])\n",
    "print(Test_Graph.edata['label'][7892])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "actual-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_indx.to_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Edges_to_explain_DetailedLabel.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-knight",
   "metadata": {},
   "source": [
    "### GNN-Edge-Explainer (Local Explanation for each one of the 3% edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-reliance",
   "metadata": {},
   "source": [
    "### Edge feature explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noble-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Explanation ***********************************************************************\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from dgl import EID, NID, khop_out_subgraph, khop_in_subgraph\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import dgl\n",
    "\n",
    "\n",
    "# init mask\n",
    "def init_efeat_masks(graph, efeat):\n",
    "    # efeat.size() = torch.Size([nb_edges, 1, 76])\n",
    "    efeat_size = efeat.size()[2]\n",
    "    num_edges = graph.num_edges()\n",
    "    num_nodes = graph.num_nodes()\n",
    "    device = efeat.device\n",
    "    std = 0.1\n",
    "    # feat_mask = [[f1, f2, .... fn]] / n = nb_features\n",
    "    efeat_mask = nn.Parameter(th.randn(1, efeat_size, device=device) * std)\n",
    "    std = nn.init.calculate_gain(\"relu\") * sqrt(2.0 / (2 * num_edges))\n",
    "    # edge_mask = [e1, e2, .... em] / m = nb_edges\n",
    "    # edge_mask = nn.Parameter(th.randn(num_edges, device=device) * std)\n",
    "    return efeat_mask\n",
    "\n",
    "\n",
    "# Regularization loss\n",
    "def loss_regularize_efeat(loss, feat_mask):\n",
    "    # epsilon for numerical stability\n",
    "    eps = 1e-15\n",
    "    # From self GNNExplainer self\n",
    "    alpha1 = 0.005,\n",
    "    alpha2 = 1.0\n",
    "    beta1 = 1.0\n",
    "    beta2 = 0.1\n",
    "\n",
    "    #edge_mask = edge_mask.sigmoid()\n",
    "    # Edge mask sparsity regularization\n",
    "    #loss = loss + th.from_numpy(alpha1 * th.Tensor.cpu(th.sum(edge_mask)).detach().numpy()).cuda()\n",
    "    # Edge mask entropy regularization\n",
    "    #ent = -edge_mask * th.log(edge_mask + eps) - (1 - edge_mask) * th.log(1 - edge_mask + eps)\n",
    "    #loss = loss + alpha2 * ent.mean()\n",
    "\n",
    "    feat_mask = feat_mask.sigmoid()\n",
    "    # Feature mask sparsity regularization\n",
    "    loss = loss + beta1 * th.mean(feat_mask)\n",
    "    # Feature mask entropy regularization\n",
    "    ent = -feat_mask * th.log(feat_mask + eps) - (\n",
    "        1 - feat_mask\n",
    "    ) * th.log(1 - feat_mask + eps)\n",
    "    loss = loss + beta2 * ent.mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# Edge mask\n",
    "def explain_edge_features(model, edge_id, graph, node_feat, edge_feat, **kwargs):\n",
    "    model = model.to(graph.device)\n",
    "    model.eval()\n",
    "\n",
    "    # Extract source node-centered k-hop subgraph from the edge_id and its associated node and edge features.\n",
    "    num_hops = 3\n",
    "    source_node = th.Tensor.cpu(graph.edges()[0][edge_id]).detach().numpy()\n",
    "    dest_node = th.Tensor.cpu(graph.edges()[1][edge_id]).detach().numpy()\n",
    "    edge_h = graph.edata['h'][edge_id]\n",
    "    sg, inverse_indices = khop_in_subgraph(graph, source_node, num_hops)\n",
    "    \n",
    "    # The edge is added in last position\n",
    "    sg = dgl.add_edges(sg, inverse_indices.item(), dest_node)\n",
    "    # So we can add its features in last position\n",
    "    sg.edata['DetailedLabel'][-1] = graph.edata['DetailedLabel'][edge_id]\n",
    "    sg.edata['Edge_indx'][-1] = graph.edata['Edge_indx'][edge_id]\n",
    "    sg.edata['label'][-1] = graph.edata['label'][edge_id]\n",
    "    sg.edata['h'][-1][0] = graph.edata['h'][edge_id]\n",
    "\n",
    "    # edge_indice using edge_feature\n",
    "    #for indx, nd_id in enumerate(sg.edges()[0]):\n",
    "    #    if inverse_indices == nd_id :\n",
    "    #        if (sg.edata['h'][indx][0] == edge_h[0]).all() :\n",
    "    #            edge_indice = indx\n",
    "    #            break\n",
    "    \n",
    "    # edge_indice using Edge_indx\n",
    "    for indx, edge_indx in enumerate(sg.edata[\"Edge_indx\"]):\n",
    "        if (edge_indx == graph.edata[\"Edge_indx\"][edge_id]).all() :\n",
    "                edge_indice = indx\n",
    "                break\n",
    "\n",
    "    # EID = NID = _ID\n",
    "    # tensor([0, 1, 2, 4]) : nodes and edges ids\n",
    "    sg_edges = sg.edata[EID].long()\n",
    "    sg_nodes = sg.ndata[NID].long()\n",
    "\n",
    "    #print()\n",
    "    edge_feat = edge_feat[sg_edges]\n",
    "    node_feat = node_feat[sg_nodes]\n",
    "    \n",
    "    \n",
    "    # Get the initial prediction.\n",
    "    #with th.no_grad():\n",
    "    #    # logits = model(g = sg, nfeats = node_feat, efeats = edge_feat, **kwargs)\n",
    "    #    logits = model(g = sg, nfeats = node_feat, efeats = edge_feat)\n",
    "    #    pred_label = logits.argmax(dim=-1)\n",
    "    \n",
    "    edge_label_1 = sg.edata[\"label\"][edge_indice]\n",
    "\n",
    "    # edge_mask\n",
    "    efeat_mask = init_efeat_masks(sg, edge_feat)\n",
    "    params = [efeat_mask]\n",
    "    optimizer = th.optim.Adam(params, lr = 0.01)\n",
    "    \n",
    "    from sklearn.utils import class_weight\n",
    "    # class_weights2 = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(sg.edata['label'].cpu().numpy()), y = sg.edata['label'].cpu().numpy())\n",
    "    # class_weights2 = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.array([0, 1]), y = sg.edata['label'].cpu().numpy())\n",
    "    # class_weights2 = th.FloatTensor(class_weights2).cuda()\n",
    "    # criterion2 = nn.CrossEntropyLoss(weight = class_weights2)\n",
    "    criterion2 = nn.CrossEntropyLoss()\n",
    "    train_mask2 = th.ones(len(sg.edata['h']), dtype=th.bool)\n",
    "    import datetime\n",
    "    \n",
    "    #print(f'explanation starts at {datetime.datetime.now()}')\n",
    "    #print(\"nb edges : \", sg.num_edges())\n",
    "    #print(\"nb nodes : \", sg.num_nodes())\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, 1000):\n",
    "        optimizer.zero_grad()\n",
    "        # Apply edge feature mask\n",
    "        h = edge_feat * efeat_mask.sigmoid()\n",
    "        # Edge mask\n",
    "        logits = model(g = sg, nfeats = node_feat, efeats = h).cuda()\n",
    "        # logits = model(g = sg, nfeats = node_feat, efeats = h)\n",
    "        # pred_label = tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0')\n",
    "        # logits = tensor([[ 0.0059,  0.0517], [-0.0075,  0.0101], ..., device='cuda:0', grad_fn=<IndexBackward0>)\n",
    "        # log_probs = logits.log_softmax(dim=-1)\n",
    "        # loss = -log_probs[edge_indice, pred_label[edge_indice]]\n",
    "        # loss11 = criterion2(logits[train_mask2], pred_label[train_mask2])\n",
    "        loss = criterion2(logits[edge_indice], edge_label_1)\n",
    "        # loss = loss_regularize_efeat(loss11, edge_mask)\n",
    "        # loss = loss_regularize(loss, efeat_mask, edge_mask)\n",
    "        \n",
    "        #if epoch % 100 == 0:\n",
    "            #print(\"+++++++++++++++\")\n",
    "            #print(f'epoch number {epoch}, CrossEntropy_Loss = {loss11}, final_loss = {loss}, time = {datetime.datetime.now()}')\n",
    "            #print(\"edge_mask : \", edge_mask.detach().sigmoid())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    efeat_mask = efeat_mask.detach().sigmoid().squeeze()\n",
    "    return edge_indice, sg, efeat_mask, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foreign-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final results : \n",
      "efeat_mask :  tensor([0.7393, 0.1131, 0.3008, 0.9576, 0.7406, 0.7901, 0.0945, 0.1025, 0.4467,\n",
      "        0.4568, 0.4682, 0.4651, 0.5199, 0.1051, 0.0908, 0.1000, 0.1227, 0.8637,\n",
      "        0.7001, 0.3191, 0.0909, 0.5284, 0.0451, 0.8932, 0.7835, 0.0952, 0.0629,\n",
      "        0.1032, 0.8911, 0.0495, 0.0609, 0.0911, 0.7754, 0.7283, 0.9467, 0.8582,\n",
      "        0.7914, 0.7736, 0.4878, 0.3749, 0.9526, 0.7633, 0.5007, 0.2812, 0.5196,\n",
      "        0.0838, 0.1844, 0.0367, 0.3369, 0.9572, 0.0719, 0.3592, 0.4096, 0.3712,\n",
      "        0.0693, 0.2220, 0.0792, 0.4681, 0.5832, 0.1230, 0.7852, 0.7834, 0.9361,\n",
      "        0.0930, 0.9714, 0.5586, 0.0883, 0.7608, 0.9114, 0.9450, 0.1228, 0.4393,\n",
      "        0.0703, 0.0927, 0.4615, 0.4929], device='cuda:0')\n",
      "sub_graph :  Graph(num_nodes=36586, num_edges=2805,\n",
      "      ndata_schemes={'feature': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'DetailedLabel': Scheme(shape=(), dtype=torch.int64), 'Edge_indx': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)})\n",
      "edge_indice :  2804\n",
      "loss :  1.1141315698623657\n"
     ]
    }
   ],
   "source": [
    "#Test_Graph1 = Test_Graph.to('cuda:0')\n",
    "#node_features_test1 = Test_Graph1.ndata['feature']\n",
    "#edge_features_test1 = Test_Graph1.edata['h']\n",
    "\n",
    "edge_indice, sub_graph, efeat_mask, loss = explain_edge_features(model1_test, 7855, Test_Graph1, node_features_test1, edge_features_test1)\n",
    "\n",
    "print(\"final results : \")\n",
    "print(\"efeat_mask : \", efeat_mask)\n",
    "print(\"sub_graph : \", sub_graph)\n",
    "print(\"edge_indice : \", edge_indice)\n",
    "print(\"loss : \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-incident",
   "metadata": {},
   "source": [
    "### Results (Final_results_DetailedLabel_Final.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exposed-executive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edge_indx label in_out_degrees                loss\n",
      "0     8457.0   0.0          120.0   0.660783760547638\n",
      "1     8477.0   0.0          120.0  0.6234775650501252\n",
      "2     7491.0   0.0          155.0  1.7774477297067643\n",
      "3     4970.0   0.0          110.0   1.306601631641388\n",
      "4     5031.0   0.0          127.0  1.1317549550533295\n",
      "..       ...   ...            ...                 ...\n",
      "90    7893.0   1.0          180.0  234.10380819439888\n",
      "91    7887.0   1.0          180.0   234.0758547180891\n",
      "92    7892.0   1.0          180.0  234.00118369698524\n",
      "93    7855.0   1.0          180.0  233.96855336725713\n",
      "94    7890.0   1.0          180.0   7.371409423321275\n",
      "\n",
      "[95 rows x 4 columns]\n",
      "Edge_indx         float64\n",
      "label             float64\n",
      "in_out_degrees    float64\n",
      "loss              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_dff = pd.read_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/Models/Final_results_DetailedLabel_Final.csv', encoding=\"ISO-88591\", dtype = str)\n",
    "print(results_dff)\n",
    "\n",
    "results_dff = results_dff.apply(pd.to_numeric)\n",
    "\n",
    "print(results_dff.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greatest-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min loss value : \n",
      "    Edge_indx  label  in_out_degrees      loss\n",
      "24    22530.0    0.0           132.0  0.389771\n",
      "51     7853.0    1.0           180.0  7.030831\n",
      "\n",
      "max loss value : \n",
      "    Edge_indx  label  in_out_degrees        loss\n",
      "7      7519.0    0.0           155.0    1.903420\n",
      "58     7874.0    1.0           180.0  234.208979\n"
     ]
    }
   ],
   "source": [
    "min_mutual_info = results_dff.loc[results_dff.groupby('label').loss.idxmin()]\n",
    "max_mutual_info = results_dff.loc[results_dff.groupby('label').loss.idxmax()]\n",
    "\n",
    "print('min loss value : ')\n",
    "print(min_mutual_info)\n",
    "print()\n",
    "print('max loss value : ')\n",
    "print(max_mutual_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-adelaide",
   "metadata": {},
   "source": [
    "### Explain the two selected edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-happiness",
   "metadata": {},
   "source": [
    "### Feature Results (Final_results_DetailedLabel_Final.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "animated-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Total Backward Packets', ' Idle Min', ' Subflow Bwd Bytes', ' Fwd Packet Length Min', ' Subflow Bwd Packets', ' Avg Fwd Segment Size', ' Fwd IAT Max', 'Fwd IAT Total', ' Idle Max', 'Total Length of Fwd Packets', 'Bwd Packet Length Max', ' Bwd PSH Flags', 'Bwd Avg Bulk Rate', ' Packet Length Mean', 'Bwd IAT Total', ' Flow IAT Mean', ' Avg Bwd Segment Size', ' Down/Up Ratio', ' Fwd URG Flags', ' Total Length of Bwd Packets', ' URG Flag Count', ' Bwd URG Flags', ' SYN Flag Count', ' Packet Length Variance', ' Active Max', ' Flow IAT Max', ' Bwd IAT Mean', ' Bwd Packet Length Mean', ' Active Std', ' Idle Std', 'Fwd PSH Flags', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Flow IAT Min', ' PSH Flag Count', ' ACK Flag Count', ' act_data_pkt_fwd', ' Init_Win_bytes_backward', ' Bwd Avg Packets/Bulk', 'Subflow Fwd Packets', ' Min Packet Length', ' Bwd Packets/s', ' Fwd Avg Packets/Bulk', ' Fwd Packet Length Std', ' Fwd Avg Bulk Rate', ' Fwd IAT Min', ' Packet Length Std', 'Init_Win_bytes_forward', 'FIN Flag Count', ' Max Packet Length', 'Fwd Packets/s', ' Total Fwd Packets', ' Fwd Header Length', 'Idle Mean', ' Bwd IAT Std', ' Bwd Header Length', ' Bwd IAT Max', ' Subflow Fwd Bytes', ' Fwd Packet Length Max', ' Bwd Packet Length Std', 'Active Mean', ' CWE Flag Count', ' ECE Flag Count', ' Flow Duration', ' Protocol', ' Average Packet Size', ' Fwd IAT Mean', ' Active Min', ' RST Flag Count', ' Bwd Packet Length Min', ' Bwd IAT Min', ' Fwd Header Length.1', ' min_seg_size_forward', ' Fwd IAT Std', 'Fwd Avg Bytes/Bulk', ' Bwd Avg Bytes/Bulk']\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_testt = pd.read_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/input/Dataset/XAI/X_test4.csv', encoding=\"ISO-88591\", dtype = str)\n",
    "colss = x_testt.columns\n",
    "\n",
    "cols_to_norm1 = list(set(list(x_testt.iloc[:, :].columns )) - set(list(['label', ' Source IP', ' Destination IP', 'DetailedLabel'])))\n",
    "print(cols_to_norm1)\n",
    "print(len(cols_to_norm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-georgia",
   "metadata": {},
   "source": [
    "#### Attack edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dependent-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final results : \n",
      "edge explained :  7855\n",
      "efeat_mask :  tensor([0.7384, 0.1171, 0.3134, 0.9632, 0.7514, 0.7976, 0.0794, 0.0925, 0.4483,\n",
      "        0.4441, 0.4421, 0.5424, 0.5137, 0.1006, 0.0956, 0.1093, 0.1474, 0.8502,\n",
      "        0.7578, 0.2739, 0.0895, 0.5556, 0.0487, 0.8784, 0.7746, 0.0941, 0.0603,\n",
      "        0.1171, 0.9048, 0.0485, 0.0583, 0.0948, 0.8063, 0.7377, 0.9445, 0.8701,\n",
      "        0.8101, 0.8189, 0.5504, 0.3423, 0.9532, 0.7831, 0.5009, 0.2832, 0.4967,\n",
      "        0.0931, 0.1952, 0.0387, 0.3278, 0.9602, 0.0697, 0.4087, 0.4827, 0.3617,\n",
      "        0.0681, 0.2120, 0.0773, 0.4601, 0.5566, 0.1307, 0.7796, 0.7941, 0.9358,\n",
      "        0.0986, 0.9698, 0.4915, 0.0793, 0.7207, 0.9099, 0.9543, 0.1134, 0.3557,\n",
      "        0.0713, 0.0939, 0.5113, 0.4833], device='cuda:0')\n",
      "sub_graph :  Graph(num_nodes=36586, num_edges=2805,\n",
      "      ndata_schemes={'feature': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'DetailedLabel': Scheme(shape=(), dtype=torch.int64), 'Edge_indx': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)})\n",
      "edge_indice :  2804\n",
      "loss :  1.1021372079849243\n"
     ]
    }
   ],
   "source": [
    "ef_edge_indice_1, ef_sub_graph_1, efeat_mask_1, ef_loss_1 = explain_edge_features(model1_test, 7855, Test_Graph1, node_features_test1, edge_features_test1)\n",
    "\n",
    "print(\"final results : \")\n",
    "print(\"edge explained : \", 7855)\n",
    "print(\"efeat_mask : \", efeat_mask_1)\n",
    "print(\"sub_graph : \", ef_sub_graph_1)\n",
    "print(\"edge_indice : \", ef_edge_indice_1)\n",
    "print(\"loss : \", ef_loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sitting-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(Test_Graph1.edata['DetailedLabel'][7855])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "assigned-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature_name  Importance_weight\n",
      "75   Total Backward Packets           0.738429\n",
      "74                 Idle Min           0.117057\n",
      "73        Subflow Bwd Bytes           0.313384\n",
      "72    Fwd Packet Length Min           0.963157\n",
      "71      Subflow Bwd Packets           0.751413\n",
      "..                      ...                ...\n",
      "4       Fwd Header Length.1           0.355730\n",
      "3      min_seg_size_forward           0.071259\n",
      "2               Fwd IAT Std           0.093869\n",
      "1        Fwd Avg Bytes/Bulk           0.511335\n",
      "0        Bwd Avg Bytes/Bulk           0.483261\n",
      "\n",
      "[76 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_weights_final = pd.DataFrame(columns = ['Feature_name', 'Importance_weight'])\n",
    "\n",
    "for indx, x in enumerate(cols_to_norm1):\n",
    "    feature_weights_final.loc[-1] = [x, efeat_mask_1.cpu().detach()[indx].item()]  # adding a row\n",
    "    feature_weights_final.index = feature_weights_final.index + 1  # shifting index\n",
    "\n",
    "print(feature_weights_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "postal-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Feature_name  Importance_weight\n",
      "11                Protocol           0.969751\n",
      "72   Fwd Packet Length Min           0.963157\n",
      "26       Max Packet Length           0.960226\n",
      "6    Bwd Packet Length Min           0.954250\n",
      "35       Min Packet Length           0.953229\n",
      "..                     ...                ...\n",
      "49            Bwd IAT Mean           0.060296\n",
      "45           Fwd PSH Flags           0.058340\n",
      "53          SYN Flag Count           0.048655\n",
      "46                Idle Std           0.048487\n",
      "28  Init_Win_bytes_forward           0.038663\n",
      "\n",
      "[76 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_weights_final = feature_weights_final.sort_values(by = 'Importance_weight', ascending = False)\n",
    "print(feature_weights_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "approximate-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature_name  Importance_weight\n",
      "11                 Protocol           0.969751\n",
      "72    Fwd Packet Length Min           0.963157\n",
      "26        Max Packet Length           0.960226\n",
      "6     Bwd Packet Length Min           0.954250\n",
      "35        Min Packet Length           0.953229\n",
      "41           PSH Flag Count           0.944505\n",
      "13           ECE Flag Count           0.935783\n",
      "7            RST Flag Count           0.909857\n",
      "47               Active Std           0.904808\n",
      "52   Packet Length Variance           0.878375\n",
      "40           ACK Flag Count           0.870101\n"
     ]
    }
   ],
   "source": [
    "print(feature_weights_final.iloc[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "apart-engine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_14e2f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_14e2f_level0_col0\" class=\"col_heading level0 col0\" >Feature_name</th>\n",
       "      <th id=\"T_14e2f_level0_col1\" class=\"col_heading level0 col1\" >Importance_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row0\" class=\"row_heading level0 row0\" >11</th>\n",
       "      <td id=\"T_14e2f_row0_col0\" class=\"data row0 col0\" > Protocol</td>\n",
       "      <td id=\"T_14e2f_row0_col1\" class=\"data row0 col1\" >0.969751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row1\" class=\"row_heading level0 row1\" >72</th>\n",
       "      <td id=\"T_14e2f_row1_col0\" class=\"data row1 col0\" > Fwd Packet Length Min</td>\n",
       "      <td id=\"T_14e2f_row1_col1\" class=\"data row1 col1\" >0.963157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row2\" class=\"row_heading level0 row2\" >26</th>\n",
       "      <td id=\"T_14e2f_row2_col0\" class=\"data row2 col0\" > Max Packet Length</td>\n",
       "      <td id=\"T_14e2f_row2_col1\" class=\"data row2 col1\" >0.960226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "      <td id=\"T_14e2f_row3_col0\" class=\"data row3 col0\" > Bwd Packet Length Min</td>\n",
       "      <td id=\"T_14e2f_row3_col1\" class=\"data row3 col1\" >0.954250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row4\" class=\"row_heading level0 row4\" >35</th>\n",
       "      <td id=\"T_14e2f_row4_col0\" class=\"data row4 col0\" > Min Packet Length</td>\n",
       "      <td id=\"T_14e2f_row4_col1\" class=\"data row4 col1\" >0.953229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row5\" class=\"row_heading level0 row5\" >41</th>\n",
       "      <td id=\"T_14e2f_row5_col0\" class=\"data row5 col0\" > PSH Flag Count</td>\n",
       "      <td id=\"T_14e2f_row5_col1\" class=\"data row5 col1\" >0.944505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row6\" class=\"row_heading level0 row6\" >13</th>\n",
       "      <td id=\"T_14e2f_row6_col0\" class=\"data row6 col0\" > ECE Flag Count</td>\n",
       "      <td id=\"T_14e2f_row6_col1\" class=\"data row6 col1\" >0.935783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_14e2f_row7_col0\" class=\"data row7 col0\" > RST Flag Count</td>\n",
       "      <td id=\"T_14e2f_row7_col1\" class=\"data row7 col1\" >0.909857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row8\" class=\"row_heading level0 row8\" >47</th>\n",
       "      <td id=\"T_14e2f_row8_col0\" class=\"data row8 col0\" > Active Std</td>\n",
       "      <td id=\"T_14e2f_row8_col1\" class=\"data row8 col1\" >0.904808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row9\" class=\"row_heading level0 row9\" >52</th>\n",
       "      <td id=\"T_14e2f_row9_col0\" class=\"data row9 col0\" > Packet Length Variance</td>\n",
       "      <td id=\"T_14e2f_row9_col1\" class=\"data row9 col1\" >0.878375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row10\" class=\"row_heading level0 row10\" >40</th>\n",
       "      <td id=\"T_14e2f_row10_col0\" class=\"data row10 col0\" > ACK Flag Count</td>\n",
       "      <td id=\"T_14e2f_row10_col1\" class=\"data row10 col1\" >0.870101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row11\" class=\"row_heading level0 row11\" >58</th>\n",
       "      <td id=\"T_14e2f_row11_col0\" class=\"data row11 col0\" > Down/Up Ratio</td>\n",
       "      <td id=\"T_14e2f_row11_col1\" class=\"data row11 col1\" >0.850216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row12\" class=\"row_heading level0 row12\" >38</th>\n",
       "      <td id=\"T_14e2f_row12_col0\" class=\"data row12 col0\" > Init_Win_bytes_backward</td>\n",
       "      <td id=\"T_14e2f_row12_col1\" class=\"data row12 col1\" >0.818927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row13\" class=\"row_heading level0 row13\" >39</th>\n",
       "      <td id=\"T_14e2f_row13_col0\" class=\"data row13 col0\" > act_data_pkt_fwd</td>\n",
       "      <td id=\"T_14e2f_row13_col1\" class=\"data row13 col1\" >0.810061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row14\" class=\"row_heading level0 row14\" >43</th>\n",
       "      <td id=\"T_14e2f_row14_col0\" class=\"data row14 col0\" > Fwd Packet Length Mean</td>\n",
       "      <td id=\"T_14e2f_row14_col1\" class=\"data row14 col1\" >0.806316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row15\" class=\"row_heading level0 row15\" >70</th>\n",
       "      <td id=\"T_14e2f_row15_col0\" class=\"data row15 col0\" > Avg Fwd Segment Size</td>\n",
       "      <td id=\"T_14e2f_row15_col1\" class=\"data row15 col1\" >0.797610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row16\" class=\"row_heading level0 row16\" >14</th>\n",
       "      <td id=\"T_14e2f_row16_col0\" class=\"data row16 col0\" > CWE Flag Count</td>\n",
       "      <td id=\"T_14e2f_row16_col1\" class=\"data row16 col1\" >0.794078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row17\" class=\"row_heading level0 row17\" >34</th>\n",
       "      <td id=\"T_14e2f_row17_col0\" class=\"data row17 col0\" > Bwd Packets/s</td>\n",
       "      <td id=\"T_14e2f_row17_col1\" class=\"data row17 col1\" >0.783066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row18\" class=\"row_heading level0 row18\" >15</th>\n",
       "      <td id=\"T_14e2f_row18_col0\" class=\"data row18 col0\" >Active Mean</td>\n",
       "      <td id=\"T_14e2f_row18_col1\" class=\"data row18 col1\" >0.779554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row19\" class=\"row_heading level0 row19\" >51</th>\n",
       "      <td id=\"T_14e2f_row19_col0\" class=\"data row19 col0\" > Active Max</td>\n",
       "      <td id=\"T_14e2f_row19_col1\" class=\"data row19 col1\" >0.774595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row20\" class=\"row_heading level0 row20\" >57</th>\n",
       "      <td id=\"T_14e2f_row20_col0\" class=\"data row20 col0\" > Fwd URG Flags</td>\n",
       "      <td id=\"T_14e2f_row20_col1\" class=\"data row20 col1\" >0.757786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row21\" class=\"row_heading level0 row21\" >71</th>\n",
       "      <td id=\"T_14e2f_row21_col0\" class=\"data row21 col0\" > Subflow Bwd Packets</td>\n",
       "      <td id=\"T_14e2f_row21_col1\" class=\"data row21 col1\" >0.751413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row22\" class=\"row_heading level0 row22\" >75</th>\n",
       "      <td id=\"T_14e2f_row22_col0\" class=\"data row22 col0\" > Total Backward Packets</td>\n",
       "      <td id=\"T_14e2f_row22_col1\" class=\"data row22 col1\" >0.738429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row23\" class=\"row_heading level0 row23\" >42</th>\n",
       "      <td id=\"T_14e2f_row23_col0\" class=\"data row23 col0\" > Flow IAT Min</td>\n",
       "      <td id=\"T_14e2f_row23_col1\" class=\"data row23 col1\" >0.737747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row24\" class=\"row_heading level0 row24\" >8</th>\n",
       "      <td id=\"T_14e2f_row24_col0\" class=\"data row24 col0\" > Active Min</td>\n",
       "      <td id=\"T_14e2f_row24_col1\" class=\"data row24 col1\" >0.720704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row25\" class=\"row_heading level0 row25\" >17</th>\n",
       "      <td id=\"T_14e2f_row25_col0\" class=\"data row25 col0\" > Fwd Packet Length Max</td>\n",
       "      <td id=\"T_14e2f_row25_col1\" class=\"data row25 col1\" >0.556645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row26\" class=\"row_heading level0 row26\" >54</th>\n",
       "      <td id=\"T_14e2f_row26_col0\" class=\"data row26 col0\" > Bwd URG Flags</td>\n",
       "      <td id=\"T_14e2f_row26_col1\" class=\"data row26 col1\" >0.555600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row27\" class=\"row_heading level0 row27\" >37</th>\n",
       "      <td id=\"T_14e2f_row27_col0\" class=\"data row27 col0\" > Bwd Avg Packets/Bulk</td>\n",
       "      <td id=\"T_14e2f_row27_col1\" class=\"data row27 col1\" >0.550387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row28\" class=\"row_heading level0 row28\" >64</th>\n",
       "      <td id=\"T_14e2f_row28_col0\" class=\"data row28 col0\" > Bwd PSH Flags</td>\n",
       "      <td id=\"T_14e2f_row28_col1\" class=\"data row28 col1\" >0.542399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row29\" class=\"row_heading level0 row29\" >63</th>\n",
       "      <td id=\"T_14e2f_row29_col0\" class=\"data row29 col0\" >Bwd Avg Bulk Rate</td>\n",
       "      <td id=\"T_14e2f_row29_col1\" class=\"data row29 col1\" >0.513735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row30\" class=\"row_heading level0 row30\" >1</th>\n",
       "      <td id=\"T_14e2f_row30_col0\" class=\"data row30 col0\" >Fwd Avg Bytes/Bulk</td>\n",
       "      <td id=\"T_14e2f_row30_col1\" class=\"data row30 col1\" >0.511335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row31\" class=\"row_heading level0 row31\" >33</th>\n",
       "      <td id=\"T_14e2f_row31_col0\" class=\"data row31 col0\" > Fwd Avg Packets/Bulk</td>\n",
       "      <td id=\"T_14e2f_row31_col1\" class=\"data row31 col1\" >0.500852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row32\" class=\"row_heading level0 row32\" >31</th>\n",
       "      <td id=\"T_14e2f_row32_col0\" class=\"data row32 col0\" > Fwd Avg Bulk Rate</td>\n",
       "      <td id=\"T_14e2f_row32_col1\" class=\"data row32 col1\" >0.496679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row33\" class=\"row_heading level0 row33\" >10</th>\n",
       "      <td id=\"T_14e2f_row33_col0\" class=\"data row33 col0\" > Average Packet Size</td>\n",
       "      <td id=\"T_14e2f_row33_col1\" class=\"data row33 col1\" >0.491478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row34\" class=\"row_heading level0 row34\" >0</th>\n",
       "      <td id=\"T_14e2f_row34_col0\" class=\"data row34 col0\" > Bwd Avg Bytes/Bulk</td>\n",
       "      <td id=\"T_14e2f_row34_col1\" class=\"data row34 col1\" >0.483261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row35\" class=\"row_heading level0 row35\" >23</th>\n",
       "      <td id=\"T_14e2f_row35_col0\" class=\"data row35 col0\" > Fwd Header Length</td>\n",
       "      <td id=\"T_14e2f_row35_col1\" class=\"data row35 col1\" >0.482660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row36\" class=\"row_heading level0 row36\" >18</th>\n",
       "      <td id=\"T_14e2f_row36_col0\" class=\"data row36 col0\" > Subflow Fwd Bytes</td>\n",
       "      <td id=\"T_14e2f_row36_col1\" class=\"data row36 col1\" >0.460105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row37\" class=\"row_heading level0 row37\" >67</th>\n",
       "      <td id=\"T_14e2f_row37_col0\" class=\"data row37 col0\" > Idle Max</td>\n",
       "      <td id=\"T_14e2f_row37_col1\" class=\"data row37 col1\" >0.448287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row38\" class=\"row_heading level0 row38\" >66</th>\n",
       "      <td id=\"T_14e2f_row38_col0\" class=\"data row38 col0\" >Total Length of Fwd Packets</td>\n",
       "      <td id=\"T_14e2f_row38_col1\" class=\"data row38 col1\" >0.444122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row39\" class=\"row_heading level0 row39\" >65</th>\n",
       "      <td id=\"T_14e2f_row39_col0\" class=\"data row39 col0\" >Bwd Packet Length Max</td>\n",
       "      <td id=\"T_14e2f_row39_col1\" class=\"data row39 col1\" >0.442076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row40\" class=\"row_heading level0 row40\" >24</th>\n",
       "      <td id=\"T_14e2f_row40_col0\" class=\"data row40 col0\" > Total Fwd Packets</td>\n",
       "      <td id=\"T_14e2f_row40_col1\" class=\"data row40 col1\" >0.408651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row41\" class=\"row_heading level0 row41\" >22</th>\n",
       "      <td id=\"T_14e2f_row41_col0\" class=\"data row41 col0\" >Idle Mean</td>\n",
       "      <td id=\"T_14e2f_row41_col1\" class=\"data row41 col1\" >0.361701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row42\" class=\"row_heading level0 row42\" >4</th>\n",
       "      <td id=\"T_14e2f_row42_col0\" class=\"data row42 col0\" > Fwd Header Length.1</td>\n",
       "      <td id=\"T_14e2f_row42_col1\" class=\"data row42 col1\" >0.355730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row43\" class=\"row_heading level0 row43\" >36</th>\n",
       "      <td id=\"T_14e2f_row43_col0\" class=\"data row43 col0\" >Subflow Fwd Packets</td>\n",
       "      <td id=\"T_14e2f_row43_col1\" class=\"data row43 col1\" >0.342262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row44\" class=\"row_heading level0 row44\" >27</th>\n",
       "      <td id=\"T_14e2f_row44_col0\" class=\"data row44 col0\" >FIN Flag Count</td>\n",
       "      <td id=\"T_14e2f_row44_col1\" class=\"data row44 col1\" >0.327787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row45\" class=\"row_heading level0 row45\" >73</th>\n",
       "      <td id=\"T_14e2f_row45_col0\" class=\"data row45 col0\" > Subflow Bwd Bytes</td>\n",
       "      <td id=\"T_14e2f_row45_col1\" class=\"data row45 col1\" >0.313384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row46\" class=\"row_heading level0 row46\" >32</th>\n",
       "      <td id=\"T_14e2f_row46_col0\" class=\"data row46 col0\" > Fwd Packet Length Std</td>\n",
       "      <td id=\"T_14e2f_row46_col1\" class=\"data row46 col1\" >0.283219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row47\" class=\"row_heading level0 row47\" >56</th>\n",
       "      <td id=\"T_14e2f_row47_col0\" class=\"data row47 col0\" > Total Length of Bwd Packets</td>\n",
       "      <td id=\"T_14e2f_row47_col1\" class=\"data row47 col1\" >0.273947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row48\" class=\"row_heading level0 row48\" >20</th>\n",
       "      <td id=\"T_14e2f_row48_col0\" class=\"data row48 col0\" > Bwd Header Length</td>\n",
       "      <td id=\"T_14e2f_row48_col1\" class=\"data row48 col1\" >0.212012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row49\" class=\"row_heading level0 row49\" >29</th>\n",
       "      <td id=\"T_14e2f_row49_col0\" class=\"data row49 col0\" > Packet Length Std</td>\n",
       "      <td id=\"T_14e2f_row49_col1\" class=\"data row49 col1\" >0.195159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row50\" class=\"row_heading level0 row50\" >59</th>\n",
       "      <td id=\"T_14e2f_row50_col0\" class=\"data row50 col0\" > Avg Bwd Segment Size</td>\n",
       "      <td id=\"T_14e2f_row50_col1\" class=\"data row50 col1\" >0.147411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row51\" class=\"row_heading level0 row51\" >16</th>\n",
       "      <td id=\"T_14e2f_row51_col0\" class=\"data row51 col0\" > Bwd Packet Length Std</td>\n",
       "      <td id=\"T_14e2f_row51_col1\" class=\"data row51 col1\" >0.130651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row52\" class=\"row_heading level0 row52\" >48</th>\n",
       "      <td id=\"T_14e2f_row52_col0\" class=\"data row52 col0\" > Bwd Packet Length Mean</td>\n",
       "      <td id=\"T_14e2f_row52_col1\" class=\"data row52 col1\" >0.117062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row53\" class=\"row_heading level0 row53\" >74</th>\n",
       "      <td id=\"T_14e2f_row53_col0\" class=\"data row53 col0\" > Idle Min</td>\n",
       "      <td id=\"T_14e2f_row53_col1\" class=\"data row53 col1\" >0.117057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row54\" class=\"row_heading level0 row54\" >5</th>\n",
       "      <td id=\"T_14e2f_row54_col0\" class=\"data row54 col0\" > Bwd IAT Min</td>\n",
       "      <td id=\"T_14e2f_row54_col1\" class=\"data row54 col1\" >0.113384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row55\" class=\"row_heading level0 row55\" >60</th>\n",
       "      <td id=\"T_14e2f_row55_col0\" class=\"data row55 col0\" > Flow IAT Mean</td>\n",
       "      <td id=\"T_14e2f_row55_col1\" class=\"data row55 col1\" >0.109341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row56\" class=\"row_heading level0 row56\" >62</th>\n",
       "      <td id=\"T_14e2f_row56_col0\" class=\"data row56 col0\" > Packet Length Mean</td>\n",
       "      <td id=\"T_14e2f_row56_col1\" class=\"data row56 col1\" >0.100584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row57\" class=\"row_heading level0 row57\" >12</th>\n",
       "      <td id=\"T_14e2f_row57_col0\" class=\"data row57 col0\" > Flow Duration</td>\n",
       "      <td id=\"T_14e2f_row57_col1\" class=\"data row57 col1\" >0.098595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row58\" class=\"row_heading level0 row58\" >61</th>\n",
       "      <td id=\"T_14e2f_row58_col0\" class=\"data row58 col0\" >Bwd IAT Total</td>\n",
       "      <td id=\"T_14e2f_row58_col1\" class=\"data row58 col1\" >0.095602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row59\" class=\"row_heading level0 row59\" >44</th>\n",
       "      <td id=\"T_14e2f_row59_col0\" class=\"data row59 col0\" > Flow IAT Std</td>\n",
       "      <td id=\"T_14e2f_row59_col1\" class=\"data row59 col1\" >0.094828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row60\" class=\"row_heading level0 row60\" >50</th>\n",
       "      <td id=\"T_14e2f_row60_col0\" class=\"data row60 col0\" > Flow IAT Max</td>\n",
       "      <td id=\"T_14e2f_row60_col1\" class=\"data row60 col1\" >0.094056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row61\" class=\"row_heading level0 row61\" >2</th>\n",
       "      <td id=\"T_14e2f_row61_col0\" class=\"data row61 col0\" > Fwd IAT Std</td>\n",
       "      <td id=\"T_14e2f_row61_col1\" class=\"data row61 col1\" >0.093869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row62\" class=\"row_heading level0 row62\" >30</th>\n",
       "      <td id=\"T_14e2f_row62_col0\" class=\"data row62 col0\" > Fwd IAT Min</td>\n",
       "      <td id=\"T_14e2f_row62_col1\" class=\"data row62 col1\" >0.093078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row63\" class=\"row_heading level0 row63\" >68</th>\n",
       "      <td id=\"T_14e2f_row63_col0\" class=\"data row63 col0\" >Fwd IAT Total</td>\n",
       "      <td id=\"T_14e2f_row63_col1\" class=\"data row63 col1\" >0.092478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row64\" class=\"row_heading level0 row64\" >55</th>\n",
       "      <td id=\"T_14e2f_row64_col0\" class=\"data row64 col0\" > URG Flag Count</td>\n",
       "      <td id=\"T_14e2f_row64_col1\" class=\"data row64 col1\" >0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row65\" class=\"row_heading level0 row65\" >69</th>\n",
       "      <td id=\"T_14e2f_row65_col0\" class=\"data row65 col0\" > Fwd IAT Max</td>\n",
       "      <td id=\"T_14e2f_row65_col1\" class=\"data row65 col1\" >0.079412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row66\" class=\"row_heading level0 row66\" >9</th>\n",
       "      <td id=\"T_14e2f_row66_col0\" class=\"data row66 col0\" > Fwd IAT Mean</td>\n",
       "      <td id=\"T_14e2f_row66_col1\" class=\"data row66 col1\" >0.079325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row67\" class=\"row_heading level0 row67\" >19</th>\n",
       "      <td id=\"T_14e2f_row67_col0\" class=\"data row67 col0\" > Bwd IAT Max</td>\n",
       "      <td id=\"T_14e2f_row67_col1\" class=\"data row67 col1\" >0.077335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row68\" class=\"row_heading level0 row68\" >3</th>\n",
       "      <td id=\"T_14e2f_row68_col0\" class=\"data row68 col0\" > min_seg_size_forward</td>\n",
       "      <td id=\"T_14e2f_row68_col1\" class=\"data row68 col1\" >0.071259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row69\" class=\"row_heading level0 row69\" >25</th>\n",
       "      <td id=\"T_14e2f_row69_col0\" class=\"data row69 col0\" >Fwd Packets/s</td>\n",
       "      <td id=\"T_14e2f_row69_col1\" class=\"data row69 col1\" >0.069668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row70\" class=\"row_heading level0 row70\" >21</th>\n",
       "      <td id=\"T_14e2f_row70_col0\" class=\"data row70 col0\" > Bwd IAT Std</td>\n",
       "      <td id=\"T_14e2f_row70_col1\" class=\"data row70 col1\" >0.068094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row71\" class=\"row_heading level0 row71\" >49</th>\n",
       "      <td id=\"T_14e2f_row71_col0\" class=\"data row71 col0\" > Bwd IAT Mean</td>\n",
       "      <td id=\"T_14e2f_row71_col1\" class=\"data row71 col1\" >0.060296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row72\" class=\"row_heading level0 row72\" >45</th>\n",
       "      <td id=\"T_14e2f_row72_col0\" class=\"data row72 col0\" >Fwd PSH Flags</td>\n",
       "      <td id=\"T_14e2f_row72_col1\" class=\"data row72 col1\" >0.058340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row73\" class=\"row_heading level0 row73\" >53</th>\n",
       "      <td id=\"T_14e2f_row73_col0\" class=\"data row73 col0\" > SYN Flag Count</td>\n",
       "      <td id=\"T_14e2f_row73_col1\" class=\"data row73 col1\" >0.048655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row74\" class=\"row_heading level0 row74\" >46</th>\n",
       "      <td id=\"T_14e2f_row74_col0\" class=\"data row74 col0\" > Idle Std</td>\n",
       "      <td id=\"T_14e2f_row74_col1\" class=\"data row74 col1\" >0.048487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14e2f_level0_row75\" class=\"row_heading level0 row75\" >28</th>\n",
       "      <td id=\"T_14e2f_row75_col0\" class=\"data row75 col0\" >Init_Win_bytes_forward</td>\n",
       "      <td id=\"T_14e2f_row75_col1\" class=\"data row75 col1\" >0.038663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6864dfadf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights_final.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dangerous-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights_final.to_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/feature_weights_final.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-machine",
   "metadata": {},
   "source": [
    "#### Benign edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adaptive-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final results : \n",
      "edge explained :  22530\n",
      "efeat_mask :  tensor([0.4816, 0.5007, 0.5767, 0.4624, 0.5317, 0.5124, 0.4637, 0.5070, 0.4908,\n",
      "        0.4866, 0.5307, 0.5152, 0.4660, 0.4570, 0.4952, 0.4999, 0.5416, 0.4782,\n",
      "        0.4473, 0.5205, 0.5140, 0.5164, 0.5035, 0.5348, 0.4845, 0.4859, 0.5197,\n",
      "        0.4830, 0.5335, 0.5089, 0.5073, 0.4968, 0.4962, 0.4495, 0.4737, 0.5159,\n",
      "        0.4977, 0.5107, 0.4599, 0.5157, 0.4920, 0.4773, 0.5218, 0.4812, 0.5048,\n",
      "        0.4795, 0.5145, 0.4613, 0.4425, 0.5076, 0.4758, 0.5187, 0.5253, 0.5489,\n",
      "        0.4970, 0.4762, 0.4831, 0.4581, 0.5355, 0.4910, 0.4610, 0.4704, 0.5118,\n",
      "        0.4939, 0.4662, 0.5314, 0.4949, 0.4747, 0.4962, 0.5629, 0.5096, 0.5165,\n",
      "        0.4841, 0.4758, 0.4823, 0.5317], device='cuda:0')\n",
      "sub_graph :  Graph(num_nodes=54770, num_edges=87,\n",
      "      ndata_schemes={'feature': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'DetailedLabel': Scheme(shape=(), dtype=torch.int64), 'Edge_indx': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1, 76), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)})\n",
      "edge_indice :  58\n",
      "loss :  -0.0\n"
     ]
    }
   ],
   "source": [
    "Test_Graph1 = Test_Graph.to('cuda:0')\n",
    "node_features_test1 = Test_Graph1.ndata['feature']\n",
    "edge_features_test1 = Test_Graph1.edata['h']\n",
    "\n",
    "ef_edge_indice_0, ef_sub_graph_0, efeat_mask_0, ef_loss_0 = explain_edge_features(model1_test, 22530, Test_Graph1, node_features_test1, edge_features_test1)\n",
    "\n",
    "print(\"final results : \")\n",
    "print(\"edge explained : \", 22530)\n",
    "print(\"efeat_mask : \", efeat_mask_0)\n",
    "print(\"sub_graph : \", ef_sub_graph_0)\n",
    "print(\"edge_indice : \", ef_edge_indice_0)\n",
    "print(\"loss : \", ef_loss_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "grave-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature_name  Importance_weight\n",
      "75   Total Backward Packets           0.481578\n",
      "74                 Idle Min           0.500717\n",
      "73        Subflow Bwd Bytes           0.576703\n",
      "72    Fwd Packet Length Min           0.462423\n",
      "71      Subflow Bwd Packets           0.531668\n",
      "..                      ...                ...\n",
      "4       Fwd Header Length.1           0.516547\n",
      "3      min_seg_size_forward           0.484059\n",
      "2               Fwd IAT Std           0.475823\n",
      "1        Fwd Avg Bytes/Bulk           0.482264\n",
      "0        Bwd Avg Bytes/Bulk           0.531683\n",
      "\n",
      "[76 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_weights_final_benign = pd.DataFrame(columns = ['Feature_name', 'Importance_weight'])\n",
    "\n",
    "for indx, x in enumerate(cols_to_norm1):\n",
    "    feature_weights_final_benign.loc[-1] = [x, efeat_mask_0.cpu().detach()[indx].item()]  # adding a row\n",
    "    feature_weights_final_benign.index = feature_weights_final_benign.index + 1  # shifting index\n",
    "\n",
    "print(feature_weights_final_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "expensive-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature_name  Importance_weight\n",
      "73        Subflow Bwd Bytes           0.576703\n",
      "6     Bwd Packet Length Min           0.562913\n",
      "22                Idle Mean           0.548867\n",
      "59     Avg Bwd Segment Size           0.541600\n",
      "17    Fwd Packet Length Max           0.535543\n",
      "52   Packet Length Variance           0.534765\n",
      "47               Active Std           0.533494\n",
      "0        Bwd Avg Bytes/Bulk           0.531683\n",
      "71      Subflow Bwd Packets           0.531668\n",
      "10      Average Packet Size           0.531412\n",
      "65    Bwd Packet Length Max           0.530688\n"
     ]
    }
   ],
   "source": [
    "feature_weights_final_benign = feature_weights_final_benign.sort_values(by = 'Importance_weight', ascending = False)\n",
    "print(feature_weights_final_benign.iloc[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "meaningful-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bbf93\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bbf93_level0_col0\" class=\"col_heading level0 col0\" >Feature_name</th>\n",
       "      <th id=\"T_bbf93_level0_col1\" class=\"col_heading level0 col1\" >Importance_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row0\" class=\"row_heading level0 row0\" >73</th>\n",
       "      <td id=\"T_bbf93_row0_col0\" class=\"data row0 col0\" > Subflow Bwd Bytes</td>\n",
       "      <td id=\"T_bbf93_row0_col1\" class=\"data row0 col1\" >0.576703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row1\" class=\"row_heading level0 row1\" >6</th>\n",
       "      <td id=\"T_bbf93_row1_col0\" class=\"data row1 col0\" > Bwd Packet Length Min</td>\n",
       "      <td id=\"T_bbf93_row1_col1\" class=\"data row1 col1\" >0.562913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row2\" class=\"row_heading level0 row2\" >22</th>\n",
       "      <td id=\"T_bbf93_row2_col0\" class=\"data row2 col0\" >Idle Mean</td>\n",
       "      <td id=\"T_bbf93_row2_col1\" class=\"data row2 col1\" >0.548867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row3\" class=\"row_heading level0 row3\" >59</th>\n",
       "      <td id=\"T_bbf93_row3_col0\" class=\"data row3 col0\" > Avg Bwd Segment Size</td>\n",
       "      <td id=\"T_bbf93_row3_col1\" class=\"data row3 col1\" >0.541600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row4\" class=\"row_heading level0 row4\" >17</th>\n",
       "      <td id=\"T_bbf93_row4_col0\" class=\"data row4 col0\" > Fwd Packet Length Max</td>\n",
       "      <td id=\"T_bbf93_row4_col1\" class=\"data row4 col1\" >0.535543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row5\" class=\"row_heading level0 row5\" >52</th>\n",
       "      <td id=\"T_bbf93_row5_col0\" class=\"data row5 col0\" > Packet Length Variance</td>\n",
       "      <td id=\"T_bbf93_row5_col1\" class=\"data row5 col1\" >0.534765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row6\" class=\"row_heading level0 row6\" >47</th>\n",
       "      <td id=\"T_bbf93_row6_col0\" class=\"data row6 col0\" > Active Std</td>\n",
       "      <td id=\"T_bbf93_row6_col1\" class=\"data row6 col1\" >0.533494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row7\" class=\"row_heading level0 row7\" >0</th>\n",
       "      <td id=\"T_bbf93_row7_col0\" class=\"data row7 col0\" > Bwd Avg Bytes/Bulk</td>\n",
       "      <td id=\"T_bbf93_row7_col1\" class=\"data row7 col1\" >0.531683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row8\" class=\"row_heading level0 row8\" >71</th>\n",
       "      <td id=\"T_bbf93_row8_col0\" class=\"data row8 col0\" > Subflow Bwd Packets</td>\n",
       "      <td id=\"T_bbf93_row8_col1\" class=\"data row8 col1\" >0.531668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_bbf93_row9_col0\" class=\"data row9 col0\" > Average Packet Size</td>\n",
       "      <td id=\"T_bbf93_row9_col1\" class=\"data row9 col1\" >0.531412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row10\" class=\"row_heading level0 row10\" >65</th>\n",
       "      <td id=\"T_bbf93_row10_col0\" class=\"data row10 col0\" >Bwd Packet Length Max</td>\n",
       "      <td id=\"T_bbf93_row10_col1\" class=\"data row10 col1\" >0.530688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row11\" class=\"row_heading level0 row11\" >23</th>\n",
       "      <td id=\"T_bbf93_row11_col0\" class=\"data row11 col0\" > Fwd Header Length</td>\n",
       "      <td id=\"T_bbf93_row11_col1\" class=\"data row11 col1\" >0.525288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row12\" class=\"row_heading level0 row12\" >33</th>\n",
       "      <td id=\"T_bbf93_row12_col0\" class=\"data row12 col0\" > Fwd Avg Packets/Bulk</td>\n",
       "      <td id=\"T_bbf93_row12_col1\" class=\"data row12 col1\" >0.521778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row13\" class=\"row_heading level0 row13\" >56</th>\n",
       "      <td id=\"T_bbf93_row13_col0\" class=\"data row13 col0\" > Total Length of Bwd Packets</td>\n",
       "      <td id=\"T_bbf93_row13_col1\" class=\"data row13 col1\" >0.520494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row14\" class=\"row_heading level0 row14\" >49</th>\n",
       "      <td id=\"T_bbf93_row14_col0\" class=\"data row14 col0\" > Bwd IAT Mean</td>\n",
       "      <td id=\"T_bbf93_row14_col1\" class=\"data row14 col1\" >0.519701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row15\" class=\"row_heading level0 row15\" >24</th>\n",
       "      <td id=\"T_bbf93_row15_col0\" class=\"data row15 col0\" > Total Fwd Packets</td>\n",
       "      <td id=\"T_bbf93_row15_col1\" class=\"data row15 col1\" >0.518685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row16\" class=\"row_heading level0 row16\" >4</th>\n",
       "      <td id=\"T_bbf93_row16_col0\" class=\"data row16 col0\" > Fwd Header Length.1</td>\n",
       "      <td id=\"T_bbf93_row16_col1\" class=\"data row16 col1\" >0.516547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row17\" class=\"row_heading level0 row17\" >54</th>\n",
       "      <td id=\"T_bbf93_row17_col0\" class=\"data row17 col0\" > Bwd URG Flags</td>\n",
       "      <td id=\"T_bbf93_row17_col1\" class=\"data row17 col1\" >0.516384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row18\" class=\"row_heading level0 row18\" >40</th>\n",
       "      <td id=\"T_bbf93_row18_col0\" class=\"data row18 col0\" > ACK Flag Count</td>\n",
       "      <td id=\"T_bbf93_row18_col1\" class=\"data row18 col1\" >0.515865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row19\" class=\"row_heading level0 row19\" >36</th>\n",
       "      <td id=\"T_bbf93_row19_col0\" class=\"data row19 col0\" >Subflow Fwd Packets</td>\n",
       "      <td id=\"T_bbf93_row19_col1\" class=\"data row19 col1\" >0.515697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row20\" class=\"row_heading level0 row20\" >64</th>\n",
       "      <td id=\"T_bbf93_row20_col0\" class=\"data row20 col0\" > Bwd PSH Flags</td>\n",
       "      <td id=\"T_bbf93_row20_col1\" class=\"data row20 col1\" >0.515170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row21\" class=\"row_heading level0 row21\" >29</th>\n",
       "      <td id=\"T_bbf93_row21_col0\" class=\"data row21 col0\" > Packet Length Std</td>\n",
       "      <td id=\"T_bbf93_row21_col1\" class=\"data row21 col1\" >0.514489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row22\" class=\"row_heading level0 row22\" >55</th>\n",
       "      <td id=\"T_bbf93_row22_col0\" class=\"data row22 col0\" > URG Flag Count</td>\n",
       "      <td id=\"T_bbf93_row22_col1\" class=\"data row22 col1\" >0.514034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row23\" class=\"row_heading level0 row23\" >70</th>\n",
       "      <td id=\"T_bbf93_row23_col0\" class=\"data row23 col0\" > Avg Fwd Segment Size</td>\n",
       "      <td id=\"T_bbf93_row23_col1\" class=\"data row23 col1\" >0.512417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row24\" class=\"row_heading level0 row24\" >13</th>\n",
       "      <td id=\"T_bbf93_row24_col0\" class=\"data row24 col0\" > ECE Flag Count</td>\n",
       "      <td id=\"T_bbf93_row24_col1\" class=\"data row24 col1\" >0.511816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row25\" class=\"row_heading level0 row25\" >38</th>\n",
       "      <td id=\"T_bbf93_row25_col0\" class=\"data row25 col0\" > Init_Win_bytes_backward</td>\n",
       "      <td id=\"T_bbf93_row25_col1\" class=\"data row25 col1\" >0.510705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row26\" class=\"row_heading level0 row26\" >5</th>\n",
       "      <td id=\"T_bbf93_row26_col0\" class=\"data row26 col0\" > Bwd IAT Min</td>\n",
       "      <td id=\"T_bbf93_row26_col1\" class=\"data row26 col1\" >0.509594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row27\" class=\"row_heading level0 row27\" >46</th>\n",
       "      <td id=\"T_bbf93_row27_col0\" class=\"data row27 col0\" > Idle Std</td>\n",
       "      <td id=\"T_bbf93_row27_col1\" class=\"data row27 col1\" >0.508863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row28\" class=\"row_heading level0 row28\" >26</th>\n",
       "      <td id=\"T_bbf93_row28_col0\" class=\"data row28 col0\" > Max Packet Length</td>\n",
       "      <td id=\"T_bbf93_row28_col1\" class=\"data row28 col1\" >0.507643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row29\" class=\"row_heading level0 row29\" >45</th>\n",
       "      <td id=\"T_bbf93_row29_col0\" class=\"data row29 col0\" >Fwd PSH Flags</td>\n",
       "      <td id=\"T_bbf93_row29_col1\" class=\"data row29 col1\" >0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row30\" class=\"row_heading level0 row30\" >68</th>\n",
       "      <td id=\"T_bbf93_row30_col0\" class=\"data row30 col0\" >Fwd IAT Total</td>\n",
       "      <td id=\"T_bbf93_row30_col1\" class=\"data row30 col1\" >0.507045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_bbf93_row31_col0\" class=\"data row31 col0\" > Fwd Avg Bulk Rate</td>\n",
       "      <td id=\"T_bbf93_row31_col1\" class=\"data row31 col1\" >0.504792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row32\" class=\"row_heading level0 row32\" >53</th>\n",
       "      <td id=\"T_bbf93_row32_col0\" class=\"data row32 col0\" > SYN Flag Count</td>\n",
       "      <td id=\"T_bbf93_row32_col1\" class=\"data row32 col1\" >0.503482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row33\" class=\"row_heading level0 row33\" >74</th>\n",
       "      <td id=\"T_bbf93_row33_col0\" class=\"data row33 col0\" > Idle Min</td>\n",
       "      <td id=\"T_bbf93_row33_col1\" class=\"data row33 col1\" >0.500717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row34\" class=\"row_heading level0 row34\" >60</th>\n",
       "      <td id=\"T_bbf93_row34_col0\" class=\"data row34 col0\" > Flow IAT Mean</td>\n",
       "      <td id=\"T_bbf93_row34_col1\" class=\"data row34 col1\" >0.499910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row35\" class=\"row_heading level0 row35\" >39</th>\n",
       "      <td id=\"T_bbf93_row35_col0\" class=\"data row35 col0\" > act_data_pkt_fwd</td>\n",
       "      <td id=\"T_bbf93_row35_col1\" class=\"data row35 col1\" >0.497680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row36\" class=\"row_heading level0 row36\" >21</th>\n",
       "      <td id=\"T_bbf93_row36_col0\" class=\"data row36 col0\" > Bwd IAT Std</td>\n",
       "      <td id=\"T_bbf93_row36_col1\" class=\"data row36 col1\" >0.497032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row37\" class=\"row_heading level0 row37\" >44</th>\n",
       "      <td id=\"T_bbf93_row37_col0\" class=\"data row37 col0\" > Flow IAT Std</td>\n",
       "      <td id=\"T_bbf93_row37_col1\" class=\"data row37 col1\" >0.496778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row38\" class=\"row_heading level0 row38\" >7</th>\n",
       "      <td id=\"T_bbf93_row38_col0\" class=\"data row38 col0\" > RST Flag Count</td>\n",
       "      <td id=\"T_bbf93_row38_col1\" class=\"data row38 col1\" >0.496190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row39\" class=\"row_heading level0 row39\" >43</th>\n",
       "      <td id=\"T_bbf93_row39_col0\" class=\"data row39 col0\" > Fwd Packet Length Mean</td>\n",
       "      <td id=\"T_bbf93_row39_col1\" class=\"data row39 col1\" >0.496168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row40\" class=\"row_heading level0 row40\" >61</th>\n",
       "      <td id=\"T_bbf93_row40_col0\" class=\"data row40 col0\" >Bwd IAT Total</td>\n",
       "      <td id=\"T_bbf93_row40_col1\" class=\"data row40 col1\" >0.495244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row41\" class=\"row_heading level0 row41\" >9</th>\n",
       "      <td id=\"T_bbf93_row41_col0\" class=\"data row41 col0\" > Fwd IAT Mean</td>\n",
       "      <td id=\"T_bbf93_row41_col1\" class=\"data row41 col1\" >0.494916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row42\" class=\"row_heading level0 row42\" >12</th>\n",
       "      <td id=\"T_bbf93_row42_col0\" class=\"data row42 col0\" > Flow Duration</td>\n",
       "      <td id=\"T_bbf93_row42_col1\" class=\"data row42 col1\" >0.493939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row43\" class=\"row_heading level0 row43\" >35</th>\n",
       "      <td id=\"T_bbf93_row43_col0\" class=\"data row43 col0\" > Min Packet Length</td>\n",
       "      <td id=\"T_bbf93_row43_col1\" class=\"data row43 col1\" >0.491952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row44\" class=\"row_heading level0 row44\" >16</th>\n",
       "      <td id=\"T_bbf93_row44_col0\" class=\"data row44 col0\" > Bwd Packet Length Std</td>\n",
       "      <td id=\"T_bbf93_row44_col1\" class=\"data row44 col1\" >0.491019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row45\" class=\"row_heading level0 row45\" >67</th>\n",
       "      <td id=\"T_bbf93_row45_col0\" class=\"data row45 col0\" > Idle Max</td>\n",
       "      <td id=\"T_bbf93_row45_col1\" class=\"data row45 col1\" >0.490784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row46\" class=\"row_heading level0 row46\" >66</th>\n",
       "      <td id=\"T_bbf93_row46_col0\" class=\"data row46 col0\" >Total Length of Fwd Packets</td>\n",
       "      <td id=\"T_bbf93_row46_col1\" class=\"data row46 col1\" >0.486641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row47\" class=\"row_heading level0 row47\" >50</th>\n",
       "      <td id=\"T_bbf93_row47_col0\" class=\"data row47 col0\" > Flow IAT Max</td>\n",
       "      <td id=\"T_bbf93_row47_col1\" class=\"data row47 col1\" >0.485890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row48\" class=\"row_heading level0 row48\" >51</th>\n",
       "      <td id=\"T_bbf93_row48_col0\" class=\"data row48 col0\" > Active Max</td>\n",
       "      <td id=\"T_bbf93_row48_col1\" class=\"data row48 col1\" >0.484513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row49\" class=\"row_heading level0 row49\" >3</th>\n",
       "      <td id=\"T_bbf93_row49_col0\" class=\"data row49 col0\" > min_seg_size_forward</td>\n",
       "      <td id=\"T_bbf93_row49_col1\" class=\"data row49 col1\" >0.484059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row50\" class=\"row_heading level0 row50\" >19</th>\n",
       "      <td id=\"T_bbf93_row50_col0\" class=\"data row50 col0\" > Bwd IAT Max</td>\n",
       "      <td id=\"T_bbf93_row50_col1\" class=\"data row50 col1\" >0.483126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row51\" class=\"row_heading level0 row51\" >48</th>\n",
       "      <td id=\"T_bbf93_row51_col0\" class=\"data row51 col0\" > Bwd Packet Length Mean</td>\n",
       "      <td id=\"T_bbf93_row51_col1\" class=\"data row51 col1\" >0.482980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row52\" class=\"row_heading level0 row52\" >1</th>\n",
       "      <td id=\"T_bbf93_row52_col0\" class=\"data row52 col0\" >Fwd Avg Bytes/Bulk</td>\n",
       "      <td id=\"T_bbf93_row52_col1\" class=\"data row52 col1\" >0.482264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row53\" class=\"row_heading level0 row53\" >75</th>\n",
       "      <td id=\"T_bbf93_row53_col0\" class=\"data row53 col0\" > Total Backward Packets</td>\n",
       "      <td id=\"T_bbf93_row53_col1\" class=\"data row53 col1\" >0.481578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row54\" class=\"row_heading level0 row54\" >32</th>\n",
       "      <td id=\"T_bbf93_row54_col0\" class=\"data row54 col0\" > Fwd Packet Length Std</td>\n",
       "      <td id=\"T_bbf93_row54_col1\" class=\"data row54 col1\" >0.481204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row55\" class=\"row_heading level0 row55\" >30</th>\n",
       "      <td id=\"T_bbf93_row55_col0\" class=\"data row55 col0\" > Fwd IAT Min</td>\n",
       "      <td id=\"T_bbf93_row55_col1\" class=\"data row55 col1\" >0.479488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row56\" class=\"row_heading level0 row56\" >58</th>\n",
       "      <td id=\"T_bbf93_row56_col0\" class=\"data row56 col0\" > Down/Up Ratio</td>\n",
       "      <td id=\"T_bbf93_row56_col1\" class=\"data row56 col1\" >0.478190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row57\" class=\"row_heading level0 row57\" >34</th>\n",
       "      <td id=\"T_bbf93_row57_col0\" class=\"data row57 col0\" > Bwd Packets/s</td>\n",
       "      <td id=\"T_bbf93_row57_col1\" class=\"data row57 col1\" >0.477282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row58\" class=\"row_heading level0 row58\" >20</th>\n",
       "      <td id=\"T_bbf93_row58_col0\" class=\"data row58 col0\" > Bwd Header Length</td>\n",
       "      <td id=\"T_bbf93_row58_col1\" class=\"data row58 col1\" >0.476181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row59\" class=\"row_heading level0 row59\" >2</th>\n",
       "      <td id=\"T_bbf93_row59_col0\" class=\"data row59 col0\" > Fwd IAT Std</td>\n",
       "      <td id=\"T_bbf93_row59_col1\" class=\"data row59 col1\" >0.475823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row60\" class=\"row_heading level0 row60\" >25</th>\n",
       "      <td id=\"T_bbf93_row60_col0\" class=\"data row60 col0\" >Fwd Packets/s</td>\n",
       "      <td id=\"T_bbf93_row60_col1\" class=\"data row60 col1\" >0.475778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row61\" class=\"row_heading level0 row61\" >8</th>\n",
       "      <td id=\"T_bbf93_row61_col0\" class=\"data row61 col0\" > Active Min</td>\n",
       "      <td id=\"T_bbf93_row61_col1\" class=\"data row61 col1\" >0.474706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row62\" class=\"row_heading level0 row62\" >41</th>\n",
       "      <td id=\"T_bbf93_row62_col0\" class=\"data row62 col0\" > PSH Flag Count</td>\n",
       "      <td id=\"T_bbf93_row62_col1\" class=\"data row62 col1\" >0.473662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row63\" class=\"row_heading level0 row63\" >14</th>\n",
       "      <td id=\"T_bbf93_row63_col0\" class=\"data row63 col0\" > CWE Flag Count</td>\n",
       "      <td id=\"T_bbf93_row63_col1\" class=\"data row63 col1\" >0.470360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row64\" class=\"row_heading level0 row64\" >11</th>\n",
       "      <td id=\"T_bbf93_row64_col0\" class=\"data row64 col0\" > Protocol</td>\n",
       "      <td id=\"T_bbf93_row64_col1\" class=\"data row64 col1\" >0.466213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row65\" class=\"row_heading level0 row65\" >63</th>\n",
       "      <td id=\"T_bbf93_row65_col0\" class=\"data row65 col0\" >Bwd Avg Bulk Rate</td>\n",
       "      <td id=\"T_bbf93_row65_col1\" class=\"data row65 col1\" >0.466018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row66\" class=\"row_heading level0 row66\" >69</th>\n",
       "      <td id=\"T_bbf93_row66_col0\" class=\"data row66 col0\" > Fwd IAT Max</td>\n",
       "      <td id=\"T_bbf93_row66_col1\" class=\"data row66 col1\" >0.463725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row67\" class=\"row_heading level0 row67\" >72</th>\n",
       "      <td id=\"T_bbf93_row67_col0\" class=\"data row67 col0\" > Fwd Packet Length Min</td>\n",
       "      <td id=\"T_bbf93_row67_col1\" class=\"data row67 col1\" >0.462423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row68\" class=\"row_heading level0 row68\" >28</th>\n",
       "      <td id=\"T_bbf93_row68_col0\" class=\"data row68 col0\" >Init_Win_bytes_forward</td>\n",
       "      <td id=\"T_bbf93_row68_col1\" class=\"data row68 col1\" >0.461321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row69\" class=\"row_heading level0 row69\" >15</th>\n",
       "      <td id=\"T_bbf93_row69_col0\" class=\"data row69 col0\" >Active Mean</td>\n",
       "      <td id=\"T_bbf93_row69_col1\" class=\"data row69 col1\" >0.461023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row70\" class=\"row_heading level0 row70\" >37</th>\n",
       "      <td id=\"T_bbf93_row70_col0\" class=\"data row70 col0\" > Bwd Avg Packets/Bulk</td>\n",
       "      <td id=\"T_bbf93_row70_col1\" class=\"data row70 col1\" >0.459920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row71\" class=\"row_heading level0 row71\" >18</th>\n",
       "      <td id=\"T_bbf93_row71_col0\" class=\"data row71 col0\" > Subflow Fwd Bytes</td>\n",
       "      <td id=\"T_bbf93_row71_col1\" class=\"data row71 col1\" >0.458103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row72\" class=\"row_heading level0 row72\" >62</th>\n",
       "      <td id=\"T_bbf93_row72_col0\" class=\"data row72 col0\" > Packet Length Mean</td>\n",
       "      <td id=\"T_bbf93_row72_col1\" class=\"data row72 col1\" >0.456997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row73\" class=\"row_heading level0 row73\" >42</th>\n",
       "      <td id=\"T_bbf93_row73_col0\" class=\"data row73 col0\" > Flow IAT Min</td>\n",
       "      <td id=\"T_bbf93_row73_col1\" class=\"data row73 col1\" >0.449517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row74\" class=\"row_heading level0 row74\" >57</th>\n",
       "      <td id=\"T_bbf93_row74_col0\" class=\"data row74 col0\" > Fwd URG Flags</td>\n",
       "      <td id=\"T_bbf93_row74_col1\" class=\"data row74 col1\" >0.447299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbf93_level0_row75\" class=\"row_heading level0 row75\" >27</th>\n",
       "      <td id=\"T_bbf93_row75_col0\" class=\"data row75 col0\" >FIN Flag Count</td>\n",
       "      <td id=\"T_bbf93_row75_col1\" class=\"data row75 col1\" >0.442453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6865eb66a0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights_final_benign.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "breathing-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights_final_benign.to_csv(f'/home/ahmed/GNN-Based-ANIDS/GNN-Based-ANIDS/jupyter_notebooks/XAI/GNNExplainer/DetailedLabel/feature_weights_final_benign.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-intermediate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
