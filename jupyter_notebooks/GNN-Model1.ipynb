{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf79b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import dgl.nn as dglnn\n",
    "from dgl import from_networkx\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea6ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07ca4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constante\n",
    "size_embedding = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64df3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        self.W_msg = nn.Linear(ndim_in + edims, ndim_out)\n",
    "        ### apply weight\n",
    "        self.W_apply = nn.Linear(ndim_in + ndim_out, ndim_out)\n",
    "        self.activation = activation\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        x = th.cat([edges.src['h'], edges.data['h']], 2)\n",
    "        y = self.W_msg(x)\n",
    "        return {'m': y}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = nfeats\n",
    "            g.edata['h'] = efeats\n",
    "            # Eq4\n",
    "            g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "            # Eq5                   \n",
    "            g.ndata['h'] = F.relu(self.W_apply(th.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "            return g.ndata['h']\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGELayer(ndim_in, edim, size_embedding, activation))\n",
    "        self.layers.append(SAGELayer(size_embedding, edim, size_embedding, activation)) ##\n",
    "        self.layers.append(SAGELayer(size_embedding, edim, ndim_out, activation))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            #nf = 'weights'+str(i)+'.txt'\n",
    "            #sourceFile = open(nf, 'w')\n",
    "            if i != 0:\n",
    "                nfeats = self.dropout(nfeats)\n",
    "            nfeats = layer(g, nfeats, efeats)\n",
    "        return nfeats.sum(1)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        v = th.cat([h_u, h_v], 1)\n",
    "        if(pr == True):\n",
    "            sourceFile = open(filename, 'w')\n",
    "            if pr:\n",
    "                print(v, file = sourceFile)\n",
    "            sourceFile.close()\n",
    "        score = self.W(v)\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.gnn = SAGE(ndim_in, ndim_out, edim, activation, dropout)\n",
    "        self.pred = MLPPredictor(ndim_out, nbclasses)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        h = self.gnn(g, nfeats, efeats)\n",
    "        return self.pred(g, h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88d7a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN          288566\n",
      "Infiltration        36\n",
      "Name:  Label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celine/miniconda3/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/celine/miniconda3/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "nbclasses =  2\n",
    "\n",
    "#data = dataset[0]\n",
    "p = ''#data/cicids/TrafficLabelling/'\n",
    "#data1 = pd.read_csv(p + 'Wednesday-workingHours.pcap_ISCX.csv')\n",
    "#data1 = pd.read_csv('Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "data1 = pd.read_csv('Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
    "###data1 = pd.read_csv('Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
    "#data1 = pd.read_csv('Monday-WorkingHours.pcap_ISCX.csv') -> benin\n",
    "#data1 = pd.read_csv('Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
    "#data1 = pd.read_csv('Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
    "\n",
    "cols = list(set(list(data1.columns )) - set(list(['Flow Bytes/s',' Flow Packets/s'])) )\n",
    "data1 = data1[cols]\n",
    "\n",
    "##mise en forme des noeuds\n",
    "data1[' Source IP'] = data1[' Source IP'].apply(str)\n",
    "data1[' Source Port'] = data1[' Source Port'].apply(str)\n",
    "data1[' Destination IP'] = data1[' Destination IP'].apply(str)\n",
    "data1[' Destination Port'] = data1[' Destination Port'].apply(str)\n",
    "data1[' Source IP'] = data1[' Source IP'] + ':' + data1[' Source Port']\n",
    "data1[' Destination IP'] = data1[' Destination IP'] + ':' + data1[' Destination Port']\n",
    "\n",
    "data1.drop(columns=['Flow ID',' Source Port',' Destination Port',' Timestamp'],inplace=True)\n",
    "\n",
    "# labels\n",
    "print(data1[' Label'].value_counts())\n",
    "nom = []\n",
    "nom = nom + [data1[' Label'].unique()[0]]\n",
    "for i in range(1,len(data1[' Label'].unique())):\n",
    "    nom = nom + [data1[' Label'].unique()[i]]\n",
    "data1[' Label'].replace(nom[0], 0,inplace = True)\n",
    "for i in range(1,len(data1[' Label'].unique())):\n",
    "    data1[' Label'].replace(nom[i], 1,inplace = True)\n",
    "data1.rename(columns={\" Label\": \"label\"},inplace = True)\n",
    "label1 = data1.label\n",
    "data1.drop(columns=['label'],inplace = True)\n",
    "\n",
    "#split train and co\n",
    "data1 =  pd.concat([data1, label1], axis=1)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "     data1, label1, test_size=0.3, random_state=123, stratify= label1)\n",
    "\n",
    "# for non numerical attributes\n",
    "encoder1 = ce.TargetEncoder(cols=[' Protocol',  'Fwd PSH Flags', ' Fwd URG Flags', ' Bwd PSH Flags', ' Bwd URG Flags'])\n",
    "encoder1.fit(X1_train, y1_train)\n",
    "X1_train = encoder1.transform(X1_train)\n",
    "\n",
    "# scaler\n",
    "scaler1 = StandardScaler()\n",
    "cols_to_norm1 = list(set(list(X1_train.iloc[:, :].columns )) - set(list(['label', ' Source IP', ' Destination IP'])) )\n",
    "\n",
    "X1_train[cols_to_norm1] = scaler1.fit_transform(X1_train[cols_to_norm1])\n",
    "\n",
    "## Create a multigraph with h and label on edges\n",
    "X1_train['h'] = X1_train[ cols_to_norm1 ].values.tolist()\n",
    "X1_train.columns\n",
    "\n",
    "sizeh = len(cols_to_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747be791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "sizeh = 3\n",
    "nbclasses =  2\n",
    "\n",
    "columns=[\" Source IP\", \" Destination IP\", 'h','label']\n",
    "data = [[1,2,[1,2,3],0], [2,3,[1,20,3],1],[1,3,[2,2,3],0],[3,4,[3,2,3],0],[1,2,[1,2,4],0]]\n",
    "X1_train = pd.DataFrame(data,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a154bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.from_pandas_edgelist(X1_train, \" Source IP\", \" Destination IP\", ['h','label'],create_using=nx.MultiGraph())\n",
    "\n",
    "## directed\n",
    "G1 = G1.to_directed()\n",
    "\n",
    "G1 = from_networkx(G1,edge_attrs=['h','label'] )\n",
    "G1.ndata['h'] = th.ones(G1.num_nodes(), G1.edata['h'].shape[1])\n",
    "G1.edata['train_mask'] = th.ones(len(G1.edata['h']), dtype=th.bool)\n",
    "\n",
    "G1.ndata['h'] = th.reshape(G1.ndata['h'], (G1.ndata['h'].shape[0], 1, G1.ndata['h'].shape[1]))\n",
    "G1.edata['h'] = th.reshape(G1.edata['h'], (G1.edata['h'].shape[0], 1, G1.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea32604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.9997673630714417 tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998737573623657 tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998737573623657 tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.999886155128479 tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998911023139954 tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998911023139954 tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998911023139954 tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998911023139954 tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Training acc: 0.9998911023139954 tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "[[201974     22]\n",
      " [     0     25]]\n"
     ]
    }
   ],
   "source": [
    "## use of model\n",
    "from sklearn.utils import class_weight\n",
    "class_weights1 = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                  classes = np.unique(G1.edata['label'].cpu().numpy()),\n",
    "                                                  y = G1.edata['label'].cpu().numpy())\n",
    "class_weights1 = th.FloatTensor(class_weights1).cuda()\n",
    "criterion1 = nn.CrossEntropyLoss(weight=class_weights1)\n",
    "G1 = G1.to('cuda:0')\n",
    "G1.device\n",
    "G1.ndata['h'].device\n",
    "G1.edata['h'].device\n",
    "\n",
    "# the loop\n",
    "\n",
    "node_features1 = G1.ndata['h']\n",
    "edge_features1 = G1.edata['h']\n",
    "\n",
    "edge_label1 = G1.edata['label']\n",
    "train_mask1 = G1.edata['train_mask']\n",
    "\n",
    "model1 = Model(G1.ndata['h'].shape[2], size_embedding, G1.ndata['h'].shape[2], F.relu, 0.2).cuda()\n",
    "opt = th.optim.Adam(model1.parameters())\n",
    "\n",
    "for epoch in range(1,1000):\n",
    "    pred = model1(G1, node_features1, edge_features1).cuda()\n",
    "    loss = criterion1(pred[train_mask1], edge_label1[train_mask1])\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print('Training acc:', compute_accuracy(pred[train_mask1], edge_label1[train_mask1]), loss)\n",
    "pred1 = model1(G1, node_features1, edge_features1).cuda()\n",
    "pred1 = pred1.argmax(1)\n",
    "pred1 = th.Tensor.cpu(pred1).detach().numpy()\n",
    "edge_label1 = th.Tensor.cpu(edge_label1).detach().numpy()\n",
    "\n",
    "\n",
    "c = confusion_matrix(edge_label1, pred1)\n",
    "c[0][0]= c[0][0]/2\n",
    "c[1][0]= c[1][0]/2\n",
    "c[0][1]= c[0][1]/2\n",
    "c[1][1]= c[1][1]/2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444386a9",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba0295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = encoder1.transform(X1_test)\n",
    "X1_test[cols_to_norm1] = scaler1.transform(X1_test[cols_to_norm1])\n",
    "X1_test['h'] = X1_test[ cols_to_norm1 ].values.tolist()\n",
    "\n",
    "G1_test = nx.from_pandas_edgelist(X1_test, \" Source IP\", \" Destination IP\", ['h','label'],create_using=nx.MultiGraph())\n",
    "G1_test = G1_test.to_directed()\n",
    "G1_test = from_networkx(G1_test,edge_attrs=['h','label'] )\n",
    "actual1 = G1_test.edata.pop('label')\n",
    "G1_test.ndata['feature'] = th.ones(G1_test.num_nodes(), G1.ndata['h'].shape[2])\n",
    "\n",
    "G1_test.ndata['feature'] = th.reshape(G1_test.ndata['feature'], (G1_test.ndata['feature'].shape[0], 1, G1_test.ndata['feature'].shape[1]))\n",
    "G1_test.edata['h'] = th.reshape(G1_test.edata['h'], (G1_test.edata['h'].shape[0], 1, G1_test.edata['h'].shape[1]))\n",
    "G1_test = G1_test.to('cuda:0')\n",
    "\n",
    "node_features_test1 = G1_test.ndata['feature']\n",
    "edge_features_test1 = G1_test.edata['h']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print\n",
    "pr = True\n",
    "# True if you want to print the embedding vectors\n",
    "# the name of the file where the vectors are printed\n",
    "filename = 'M1_weights.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb750be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   11     0]\n",
      " [   14 86556]]\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1(G1_test, node_features_test1, edge_features_test1).cuda()\n",
    "\n",
    "\n",
    "test_pred1 = test_pred1.argmax(1)\n",
    "test_pred1 = th.Tensor.cpu(test_pred1).detach().numpy()\n",
    "\n",
    "actual11 = [\"Normal\" if i == 0 else \"Attack\" for i in actual1]\n",
    "test_pred11 = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred1]\n",
    "c = confusion_matrix(actual11, test_pred11)\n",
    "c[0][0]= c[0][0]/2\n",
    "c[1][0]= c[1][0]/2\n",
    "c[0][1]= c[0][1]/2\n",
    "c[1][1]= c[1][1]/2\n",
    "print(c)\n",
    "#plot_confusion_matrix(cm = c, #confusion_matrix(actual11, test_pred11), \n",
    "#                      normalize    = False,\n",
    "#                      target_names = np.unique(actual1),\n",
    "#                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9da7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23338a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79479f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
